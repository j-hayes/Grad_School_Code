
Stochastic and Economic Optimal Control
Donald J. Chmielewski
and
Jin Zhang
Illinois Institute of Technology
Copyright (2019)
2
Contents
Preface v
I Preliminaries 1
1 Motivation and Overview 3
1.1 Level Control Example: Impact of Constraints . . . . . . . . . . . . . . 5
1.1.1 Open-loop Operation . . . . . . . . . . . . . . . . . . . . . . 5
1.1.2 Closed-loop Operation . . . . . . . . . . . . . . . . . . . . . 6
1.1.3 Operating Point Selection . . . . . . . . . . . . . . . . . . . . 9
1.2 Reactor Control Example: Considering Profit . . . . . . . . . . . . . . . 9
1.2.1 CSTR Profit and the Expected Dynamic Operating Region . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.2.2 CSTR Constraints and Backed-off Operating Point Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.2.3 CSTR Profit with Equipment Modifications . . . . . . . 15
1.3 Impact of Disturbance Characteristics . . . . . . . . . . . . . . . . . . . . 18
1.4 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
1.4.1 Review of Literature on Economic Based Controller
Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
2 Modeling of Dynamic Systems 23
2.1 Nonlinear State-Space Models . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.2 Deviation Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.3 Linearization of Nonlinear Models . . . . . . . . . . . . . . . . . . . . . . 31
2.4 Analytic Solution of a Linear State Space Model . . . . . . . . . . . . . 39
2.5 Discrete-time Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
2.5.1 The Explicit Euler Method . . . . . . . . . . . . . . . . . . . 43
2.5.2 The Sample and Hold Method . . . . . . . . . . . . . . . . . 45
2.6 Case Study Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
2.6.1 Furnace Reactor Process . . . . . . . . . . . . . . . . . . . . . 50
2.6.2 System of Three Masses . . . . . . . . . . . . . . . . . . . . . 52
2.6.3 Endothermic Reactor . . . . . . . . . . . . . . . . . . . . . . 53
2.6.4 Manufacturing Process . . . . . . . . . . . . . . . . . . . . . . 53
2.6.5 Building HVAC System . . . . . . . . . . . . . . . . . . . . . 54
2.6.6 Vapor Product Reactor . . . . . . . . . . . . . . . . . . . . . 55
2.6.7 Two CSTR Process . . . . . . . . . . . . . . . . . . . . . . . . 56
2.7 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
i
ii Contents
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
3 Review of Linear Algebra 67
3.1 Sets, Subsets and Linear Vector Spaces . . . . . . . . . . . . . . . . . . . . 67
3.2 Inner Products and Orthogonality . . . . . . . . . . . . . . . . . . . . . . 69
3.3 Linear Transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
3.4 Linear Independence and Orthogonalization . . . . . . . . . . . . . . . . 76
3.5 Matrix Inverse and the Determinant . . . . . . . . . . . . . . . . . . . . . 82
3.6 Eigenvector Decomposition and Diagonalization . . . . . . . . . . . . . 85
3.7 Non-Square Systems of Equations . . . . . . . . . . . . . . . . . . . . . . . 90
3.7.1 Least Squares Solutions and the Pseudo-Inverse . . . . . . 91
3.7.2 Non-uniqueness and the Minimum Norm Solution . . . 94
3.7.3 Singular Value Decomposition and Solutions to Mx = b 97
3.8 Positive Definite Transformations . . . . . . . . . . . . . . . . . . . . . . . 101
3.9 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
II Modern Control Theory 111
4 Linear System Theory 113
4.1 Stability of a Linear Dynamic System . . . . . . . . . . . . . . . . . . . . 113
4.1.1 Stability in the Discrete-time Framework . . . . . . . . . . 113
4.1.2 Stability in the Continuous-time Framework . . . . . . . 116
4.1.3 Stability in the Sense of Lyapunov . . . . . . . . . . . . . . 117
4.2 Linear Feedback and State Observers . . . . . . . . . . . . . . . . . . . . . 119
4.3 Controllability and Stabilizability . . . . . . . . . . . . . . . . . . . . . . . 121
4.3.1 Complete Controllability . . . . . . . . . . . . . . . . . . . . 121
4.3.2 The Controllable Subspace . . . . . . . . . . . . . . . . . . . 124
4.3.3 Necessary and Sufficient Conditions for Stabilizability . 126
4.4 Observability and Detectability . . . . . . . . . . . . . . . . . . . . . . . . 128
4.4.1 Observability and the Unobservable Subspace . . . . . . 128
4.4.2 First Experience with Duality . . . . . . . . . . . . . . . . . 130
4.4.3 Necessary and Sufficient Conditions for Detectability . 131
4.5 Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
5 Stochastic Processes 143
6 Linear Estimation 145
7 Linear Quadratic Optimal Control 147
8 Stochastic LQOC 149
9 Model Predictive Control 151
III Economic Based Controller Design 153
10 Matrix Inequalities 155
Contents iii
11 Constrained Minimum Variance Control 157
12 Hardware Selection and the GBD 159
13 Economic Linear Optimal Control 161
14 Economic MPC 163
15 Controller Integrated Process Design 165
Bibliography 167
iv Contents
Preface
A recent trend within the chemical engineering control community is to incorporate
process economics into the design of control systems. While such efforts are welcome,
the analysis of these economic based controllers requires a broad and fairly deep understanding of modern control theory. As such, this book has two broad objectives. The
first is to provide a succinct, but self-contained, development of modern control theory.
Then, given this foundation, the second objective is to provide a compilation of recent
results on the subject of economic based control system design.
In terms of prerequisite knowledge, the book assumes the reader to have a technical background in engineering or mathematics at the undergraduate level - in essence a
familiarity with ordinary differential equations. While a familiarity with the concept
of feedback will be helpful, the Laplace domain methods of classic control will not be
discussed, as nearly all developments will take place in the time domain.
There are two intended audiences - first-year graduate students and self-study practitioners. If used within a course, the text is constructed such that the instructor should
have a great deal of flexibility. The most basic option is to cover the material of Part II
in a one semester survey course. This first option assumes students have taken a graduate
level engineering mathematics course that has provided the modeling and linear algebra
foundation given in Part I. If a survey treatment of topics is the goal, a fair amount of
depth will need to be sacrificed if one would like to cover all 6 chapters of Part 2. To this
end each chapter begins with a very simple sketch of the main idea, usually in a scalar
context, with the goal of helping the student develop a bit of intuition about the more
detailed material to follow. Thus, it is feasible for lectures to focus on the derivation given
in first part of the chapter, and then skip to the results portion for the more general case.
This is the approach used at IIT. A second option, is to offer a two semester sequence
of courses, the first covering Chapters 2-5 and the second covering Chapters 6-9. In this
case, there should be sufficient time to work through the more detailed derivations. The
material of Part III is more appropriate for self-study practitioners and advanced graduate students. If offered as a course, a small group setting (such as that found in a special
problems course) is likely best. In either case, it will be essential to work though the
computational examples given within the chapters and reproduce the given results. In
nearly all examples, sample MATLAB code is provided to get one started.
Each chapter ends with a set of exercises. While many of these are theoretical in nature (usually simple extensions or special cases of results developed in the chapters), most
are numeric or computational based. These computational exercises are critical to developing an initial understanding of the theoretic material and are strongly encouraged,
especially for self-study practitioners. Once this initial understanding has been achieved,
the theoretic developments of the chapter should be revisited and the more theoretic exercises should be attempted, so as to develop a deeper understanding of the theory. In the
last section of Chapter 2, a number of moderately sized case study systems are introduced
v
vi Preface
- each containing 3-6 states, multiple inputs and several performance outputs. In the exercises of subsequent chapters, each of these case study systems is revisited with a focus
on the concepts of that chapter. While teaching the course at IIT, groups of 2-3 students
are assigned to each of these case study systems. Then, at the midpoint and end of the
semester, each group will present a summary of their individualized exercises to the rest
of the class. In addition to forcing each group to explain their results, the entire class
receives the benefit of seeing the theoretic notions within a variety of applications. For
the self-study practitioner, it is recommended to select two of these case study systems
and attempt the corresponding exercises of each chapter. It is highlighted that these case
study systems continue to be utilized within the chapters of Part III, and represent the
best way to learn how to implement the newly developed techniques of those chapters.
Chapter 1 begins by discussing the conceptual relationship between the design of a
process and the control of a process. This discussion will illustrate the need for more integration of these two activities. The connecting concept is that of process uncertainty and
the fact that a realization of this uncertainty cannot occur until after the process design
phase is complete. While the control system will mitigate the impact of this uncertainty,
the level to which this mitigation occurs depends upon the capabilities of the process,
which of course were engendered during the design phase. The remainder of Chapter
1 focuses on a couple of simple examples intended to illustrate the multifaceted relationships between uncertainty characteristics, mitigation capabilities, process constraints and
process economics. While the topic of process economics is reserved for Part III, these
examples provide motivation for many of the subjects discussed in Part II.
Chapter 2 introduces the state space modeling framework to be used throughout the
text. Of particular interest is the notion of a steady-state operating point and the deviation variables defined with respect to that operating point. While most texts on advanced
control will gloss over this rudimentary topic, such concepts will be an essential component of Part III. Specifically, the relationship between dynamic operation (in deviation
variables) and the steady-state operating point (used to define deviation variables) is used
to account for process economics. Procedures for model linearization and conversion of
continuous-time models to the discrete-time framework are also provided in Chapter 2.
Chapter 3 provides an introduction to linear algebra, and while not comprehensive,
an effort has been made to make this chapter self-contained in the sense that all developments are based on previous results. While the material of Chapter 3 will be useful
throughout the text, most will be employed in the linear system theory derivations of
Chapter 4. In addition to the usual topics of stability, controllability and observability,
Chapter 4 gives a fairly detailed development of the conditions for stabilizability and detectability. The need for these conditions is motivated by a rather intuitive introduction
to state feedback and state observer design. Looking ahead to Chapter 10, the conditions for stabilizability and detectability will be revisited and serve as the first examples of
using matrix inequalities to answer control theoretic questions. Chapter 4 will also introduce Lyapunov based stability conditions for linear systems, which will be central to
the proofs of Chapter 10.
In Chapter 5 the notion of a stochastic process is introduced and distinguished from
an arbitrary collection of random variables through the concept of autocorrelation. Then,
using the discrete-time framework an intuitive derivation of the covariance equation is presented. The chapter also emphasizes the difference between colored and white noise,
and illustrates that a colored noise disturbance model can be constructed by driving a
linear system with white noise. Chapter 5 concludes with a discussion of relationship
between the covariance equation and it associated Gramian, which again will be required
for the proofs of Chapter 10. Chapter 6 begins with a derivation of the optimal state
Preface vii
estimator (or Kalman filter) as a simple application of the continuous-time covariance
equation. The development of the discrete-time version, however, begins with a review
of the more general topic of estimation theory. This more involved derivation serves
to expose the deeper characteristics of the Kalman filter, specifically the orthogonality
principle and the whiteness of the innovations process. This discrete-time development also emphasizes the subtle difference between the estimator and the more commonly
found one-step predictor. Chapter 6 concludes with a short introduction to multi-step
prediction and smoothing, both of which will be of utility in Part III.
In Chapter 7, the deterministic linear quadratic optimal control (LQOC) problem
is introduced by first highlighting the fact that the finite-time version is just a quadratic
program that can be solved using standard optimization software. In addition to being
an intuitively attractive approach, this perspective sets a foundation for the development
of model predictive control, to be introduced in Chapter 9. To arrive at a deeper understanding of the LQOC problem, its solution is also derived using dynamic programming,
which give the solution in the form of a linear state feedback and provides the gateway
to solving the infinite-time version. Of course, this dynamic programming perspective
will serve as the foundation for solving the stochastic LQOC problem, to be discussed
in Chapter 8. The dynamic programming perspective also leads to the Riccati equation,
which is of course identified as the dual of the Riccati equation associate with the Kalman
filter of Chapter 6. The concept of model predictive control (MPC) is introduced in
Chapter 9 by simply advocating a receding horizon implementation of the deterministic
LQOC and highlighting the fact that a quadratic programming solution approach will
allow for a straightforward incorporation of inequality constraints. Chapter 9 concludes
with a discussion of MPC in the context of stochastic disturbances. The examples of that
section will highlight the need for more sophisticated tuning procedures and will serve
to motivate many of the developments of Part III.
Part III begins by laying a computational foundation for the remaining chapters.
Chapter 10 will show that many of the control related challenges of Part II can be expressed as feasibility questions in the context of a linear matrix inequality (LMI). The
advantage of this LMI form is that these conditions are convex and thus will result in a
significant reduction in computational effort and in the more advanced cases will provide the only viable path to obtaining a global solution. Building on the LMI results of
Chapter 10, Chapter 11 introduces a new perspective on control system design. In contrast to the LQOC, which relies on objective function weights for tuning, the proposed
constrained minimum variance (CMV) controller design scheme is enhanced by a set of
closed-loop variance bounds. Since these variance bounds have greater physical meaning,
as compared to the LQOC objective function weights, the CMV approach is expected to
be more attractive to the control engineer. While the controller generated by the CMV
approach cannot enforce point-wise-in-time constraints, Chapter 11 will illustrate how
this controller can be used for the tuning of an MPC controller. The basic idea is to show
that the variance constraints within CMV control serve to simply modify the quadratic
objective function weights of the LQOC. Once these modified weights are obtained -
using inverse optimality - they are used within a standard application of MPC.
The downside of the LMI form is that enforcement of these constraints requires the
use of specialized semi-definite programming (SDP) optimization routines, which in most
cases are incapable of enforcing general nonlinear constraints. Since this feature will be
require in later chapters, Chapter 12 provides an introduction to the generalized Bender’s
decomposition (GBD) algorithm. This algorithm serves to segregates the LMI portion
of the problem from the general nonlinear portion and allows each part to be addressed
using an optimization routine that is appropriate for that class of problems. In Chapter
viii Preface
12, the GBD approach is illustrated in the context of the fairly simple hardware selection
problem.
In Chapter 13, the CMV concept is extended to an economic framework. The first
step is to recognize that the steady-state operating condition (usually selected prior to the
controller design phase) dominates the economics of the process. Thus, the proposed
economic linear optimal control (ELOC) scheme advocates performing both tasks (operating point selection and controller design) simultaneously. While the controller design
part is nearly identical to the CMV problem, the operating point selection part requires
a steady-state (possibly nonlinear) process model. As such the solution to the ELOC
design problem will in most cases require use of the GBD algorithm. Once the ELOC
policy has been calculated, the method of inverse optimality can once again be used for
the tuning of an MPC controller to be denoted as constrained ELOC.
Chapter 14 turns to a recent extension of MPC known as economic MPC (EMPC).
EMPC is nearly identical to the original MPC algorithm, in that a receding horizon
framework is employed. The main difference is in the objective function, where the
usual quadratic objective (which has little physical meaning) is replaced by an economic
objective in the sense that the stage cost of each time step reflects actual operating costs
of the process during that time period. In the second half of Chapter 13, the relationship between EMPC and ELOC will be illustrated. It will be shown that controllers derived from the ELOC problem (the constrained ELOC policy of Chapter 13 and a newly
developed approximate infinite-horizon EMPC policy) overcome the shortcomings of
EMPC, specifically stability concerns and inventory creep. A particularly attractive feature of EMPC is the ability to address processes with time-varying economics, especially
those that vary on a timescale that is shorter than the characteristic time of the process.
Chapter 14 will illustrate how the ELOC problem can be extended to address this type
of situation and show how it and its derivatives compare to EMPC
Chapter 15 considers the question of controller integrated process design. Conceptually, the problem is simple in that the operating cost objective function of the ELOC is
augmented with the capital costs of equipment purchase or upgrade. However, the level
of complexity involved in calculating a global solution to such problems will depend on
the characteristics of the process dynamics - most notably how much the process design
variables influence the dynamics of the process? As such, the structure of the final chapter is such that various classes of problems are identified each with a solution scheme of
increasing complexity. It is finally highlighted that the approaches of this chapter will
be essential for the design of processes with time-varying economics, since these types
of situations require a consideration of process dynamics and a failure to do so would be
incongruent with the objectives of the process.
Part I
Preliminaries
Chapter 1
Motivation and Overview
The fundamental challenge of process design is to specify equipment (and operating conditions of that equipment) such that a physical task may be performed. In nearly all
cases, the design process is guided by economic motives in that the goal is to minimize
a combination of capital and operating costs. As one would imagine, the complexity
of these design questions can be immense and typically will result in the formulation of
a large scale, mixed integer, nonlinear, optimization problem. As such, enormous effort
has been put toward simplifying problem formulations and the development of computational tools. A point of particular relevance is the role of equipment models. Specifically,
a flawed equipment model will, necessarily, result in a sub-optimal (and possibility a nonviable) system design. The unfortunate fact, however, is that all equipment models are
flawed, regardless of complexity or perceived fidelity. This fact stems from the inevitable
deviations that will occur between the design phase and the construction of the physical
system. Consider, for example, the uncertainty associated with the physical characteristics of materials or the inconsistency of fabrication methods.
The primary task of a control system is to mitigate the impact of uncertainties. That
is, the controller is expected to drive key operating variables (the control variables) to the
values specified by the original design, and do so with virtually no model information.
Controllers are able to achieve this seemingly impossible task by simply implementing
the notion of feedback. In particular, the controller has the advantage of on-line measurements, which it uses to infer the impact of uncertainty. The feedback loop is closed
by endowing the controller with an ability to manipulate certain elements of the system,
which it does until the impact of uncertainty is canceled out. The important point being
that concerns about model uncertainty during the system design phase can be reduced
(and in many cases ignored) by assuming the existence of sufficient controllers during the
operational phase.
While the above paradigm has historic precedence, the term “sufficient controller”
should give one pause. What is a sufficient controller? One way to answer this question
is to focus on the manipulated variables or more appropriately the actuation equipment. Do the actuators have enough range to be able to drive the control variables back to
the design conditions? To answer this question, one would need additional information
about the expected uncertainty - the types one should expect as well as the set of possible values for each. Another way to view the sufficient controller question is to ask if
the set of measurements contain enough information to conclude that control variables
have been driven back to design conditions. To answer this question, an uncertainty
3
4 Chapter 1. Motivation and Overview
model will again be needed, but this time with respect to the accuracy and precision of
measurement equipment.
While the above questions seem like a natural extension of the traditional design challenge, they carry an implicit assumption: implementation of a sufficient controller will
have little or no impact on system economics. Though one could consider the cost of
measurement and actuation equipment, this aspect only scratches the surface. The more
fundamental concept is that actuation of manipulated variables will likely change the
system operating conditions, even if the control variables are driven back to design conditions. Thus, the deeper question concerns the impact manipulated variables will have
on system economics. Consider the simple example of using a furnace to manipulate
the temperature of a material flow. The action of increasing stream temperature will,
of course, result in greater fuel costs. Due to the nature of uncertainty, the conceptual
challenge during the design phase is that one cannot know where the manipulated variables will end up during system operation. At best an uncertainty model can be used to
determine the range of values one would expect. Based on this region, one could then
make design decisions based on average economics or alternatively based on worst case
economics. Notions similar to the about have been developed in the literature under
the subject titles of flexibility analysis and stochastic optimization. See Section 1.4 for
citations to those efforts.
Figure 1-1: Modern Control System Architecture.
Plant Measured Data
Regulatory
Controllers
Real-time
Optimization
Based Controllers
Uncertainty
Estimation
Set-points
Figure 1.1. Modern Control System Architecture
A broader perspective is to relinquish the notion of always driving control variables
back to the design conditions. The motivation being that for certain realizations of the
uncertainty, the economic penalty of moving a manipulated variable may be greater than
the penalty of allowing a control variable to be off-set from its design condition. The
modern control system architecture is, in fact, an implementation of such notions. Figure
1-1 illustrates the cascade structure typically used. The inner regulatory loops are seen as
actuators by the real-time optimization loop. These on-line optimization type controllers
choose set-point commands such that the economic performance of the system will be
maximized, given a current estimate of uncertainty. Thus, the model used within the
system design phase should attempt to capture the actions and performance of the realtime optimization loop. Clearly, the performance of this outer loop will depend on
the quality of the models used for optimization as well as those used for uncertainty
estimation.
One way to classify uncertainty models is with regard to time. The two extremes are
constant uncertainties and time-dependent uncertainties. For example, an aspect of the
original system model may be unknown during the design phase, but once the system
1.1. Level Control Example: Impact of Constraints 5
is constructed its value will be realized and remain unchanged for the life of the system.
On the other hand, an aspect of the system may be continually changing, and knowledge
about the uncertainty at a given time may be of limited utility at some future time. Understanding this distinction (and the gray area between the two extremes) is critical to the
construction and performance assessment of the real-time optimization layer.
In the following sections, the conceptual notions of the above paragraphs will be illustrated and expanded. Of particular interest will be how the controller and its prescribed
set-point interacts with the physical limitations of the system. This notion of inequality
constraints playing a fundamental role will be a recurring theme throughout the text.
Figure 1-2: Surge tank with flow controller
20
0 V
 !(sp)
FT
FC
in
V
Figure 1.2. Surge tank with flow controller
1.1 Level Control Example: Impact of Constraints
Consider the surge tank depicted in Figure 1.2. The flow controller (or servo-loop) is
intended to regulate flow from the pump. Specifically, this controller (FC) receives a
set-point command, v(s p), and then modifies valve position until the measured flow (FT)
is equal to the given set-point. These low level loops (typically mass flow controllers)
serve to simplify process modelling for the higher level controllers. That is, rather than
model valve and pump characteristics, the high level controller will simply give a set-point
command, which will be executed with a high degree of certainty. Thus, it is reasonable
to assume that v = v(s p) for all time, and that v can be selected as a manipulated variable
for the higher level controller. It is also noted that the actual manipulated variable, valve
position, is not expected to have any bearing on the economics of the process. However,
the manipulated variable of the higher level controller, flow from the tank, will have an
impact on economics; in that power to the pump will be a function of flow rate. However,
in many cases pumping power is small enough that it can be ignored as well.
1.1.1 Open-loop Operation
Before we consider the higher level controller, let us highlight some of the objectives of
our surge tank. Assume the inlet flow, vin, is from a reactor that varies its throughput
to achieve temperature regulation. Thus, a reasonable characterization is to assume an
average value and a range of variability for this inlet flow, say vin = 30 ± 3 m3/min.
Assume the exit flow, v, will be sent to a separation unit that demands its inlet flow is
less than 31 m3/min. Finally, the volume of liquid in the tank, V , should not exceed the
total tank volume (which would cause an overflow), and the tank should not be allowed
to run dry (which would damage the pump). If the maximum volume of the tank is 20
m3, then these specifications can be stated as 0 ≤ V ≤ 20m3. Thus, the objective of the
surge tank is to deliver a downstream flow less than 31 m3/min, in the face of upstream
variations, vin = 30 ± 3 m3/min, while avoiding tank faults 0 ≤ V ≤ 20 m3.
6 Chapter 1. Motivation and Overview
0 10 20 30 40
26
27
28
29
30
31
32
33
34
time (minutes)
Volumetric Flow (m3/min)
v
in
v
0 10 20 30 40
−5
5 0
10
15
20
25
30
time (minutes)
Tank Hold−up (m3)
Figure 1.3. Surge tank simulation under uncontrolled policy
We begin by assuming a constant exit flow (v = 30 m3/min for all time), and test the
system under an arbitrarily selected inlet flow scenario (depicted in the left plot of Figure
1.3). To determine the impact of this scenario, it is common to construct a model of the
surge tank. A simple volume balance yields:
V˙ = v
in − v (1.1)
The dot notation indicates the derivative with respect to time: V˙ = dV /d t. If v is
constant and v
in is a known function of time, then V (t) may be determined by simple
integration.
V (t) = V (0) + ∫0t vi n(τ)dτ − v t (1.2)
The right plot of Figure 1.3, shows the result of a constant exit flow policy and illustrates
that an over-flow of the tank is expected.
1.1.2 Closed-loop Operation
Now consider the installation of a level controller (Figure 1.4), where tank volume is the
control variable (CV) and the manipulated variable (MV) is exit flow v. In this cascade
configuration, the level (or volume) controller is at a higher level than the flow controller
(or equivalently LC is master to the slave FC).
For simplicity assume the level controller is of the Proportional Integral (PI) variety. As an aid to the tuning of a PI controller, it is common to convert our existing
time-domain plant model (Equation 1.1) to the Laplace domain to arrive at a transfer
function model. If the Steady-State Operating Point (SSOP) of the tank is assumed to
be V s s o p = V (s p) = 10 m3, vs s o p
in = 30 m3/min and vs s o p = 30 m3/min, then one can
define deviation variables as: x = V −V s s o p, w = vin − vin s s o p and u = v − vs s o p, which
results in the following deviation variable form of the original plant model:
x˙ = w − u (1.3)
Taking the Laplace transform yields the following:
s x(s) = w(s) − u(s) (1.4)
1.1. Level Control Example: Impact of Constraints 7
Figure 1-4: Surge tank with level controller
w u
 !(sp)
FT
FC
in
V(sp)
LT
LC
V
Figure 1.4. Surge tank with level controller
Then, the open-loop transfer function is:
x(s) = Gp(s)u(s) + Gd(s)w (1.5)
where the transfer function corresponding to the process is Gp(s) = −1/s and that of the
disturbance is G
p(s) = 1/s. The block diagram of the closed-loop system is depicted in
Figure 1.5, where the transfer function of the PI controller is:
G
c(s) = Kc 1 + τ1I s  (1.6)
Figure 1-5: Block diagram of level controller
+
-
u
Gp
Gc(s) (s) + +
w
Gd(s)
x(sp) x
Figure 1.5. Block diagram of level controller
Now employ a commonly recommended controller tuning from the literature (Table
12.1, entry E of Seborg et al., [1]):
Kc
= −2/τc and τI = 2τc (1.7)
where τ
c is the desired closed-loop time constant (to be selected by the user). As a point
of interest, the resulting closed-loop transfer functions are:
x(s)
w(s)
=
1 s
τcτsc+s 12 and wu((ss)) = s12 τcτsc+s 12 (1.8)
However, it should be noted that (1.8) was not used to generate the simulations below.
Subsequent chapters will illustrate alternative and more general methods to simulate a
system subject to such inputs.
8 Chapter 1. Motivation and Overview
0 10 20 30 40
26
27
28
29
30
31
32
33
34
time (minutes)
Volumetric Flow (m3/min)
v
in
v
0 10 20 30 40
−5
5 0
10
15
20
25
30
time (minutes)
Tank Hold−up (m3)
0 10 20 30 40
26
27
28
29
30
31
32
33
34
time (minutes)
Volumetric Flow (m3/min)
v
in
v
0 10 20 30 40
−5
5 0
10
15
20
25
30
time (minutes)
Tank Hold−up (m3)
0 10 20 30 40
26
27
28
29
30
31
32
33
34
time (minutes)
Volumetric Flow (m3/min)
v
in
v
0 10 20 30 40
−5
5 0
10
15
20
25
30
time (minutes)
Tank Hold−up (m3)
Figure 1.6. Surge tank simulations with PI control
Top plots - τc = 1, middle plots - τc = 10, bottom plots - τc = 50.
Given this tuning method, we can now consider the impact of different τc selections:
• If one selects τ
c = 1 min, then the top plots of Figure 1.6 illustrates tight regulation
with respect to tank volume. However, the objective of keeping v < 31 m3/min
is violated. It is highlighted that the top plots of Figure 1.6 are those one would
typically find in a classic control textbook - the selected CV (tank volume) is being
regulated at the expense of the MV (exit flow).
• If one selects τ
c = 10 min, then the middle plots of Figure 1.6 shows a similar
situation in that tank hold-up is within limits and exit flow is not. However, the
exit flow violations are less severe than in the previous case.
1.2. Reactor Control Example: Considering Profit 9
• If one selects τ
c = 50 min, then from the bottom plots it is seen that the exit
flow constraint of v < 31 m3/min is satisfied, but now the volume constraint is
violated.
1.1.3 Operating Point Selection
The result of our first example is not too promising. We have yet to find a controller
tuning that achieves all of our constraint satisfaction objectives. So, what is the solution?
Well, we must broaden the set of alternatives. In fact, there are many options available.
The first that come to mind is to install a larger tank. Certainly, the controller with
τ
c = 50 min would have been sufficient, if the tank was 30 m3 in size. A similar option
is to upgrade the downstream separation unit so that it can accept inlet flows larger than
31 m3/min. However, from a capital cost perspective, it will likely be much cheaper
to enlarge the surge tank. A third option is to change the average flow from the reactor
feeding the surge tank. For example, one could set vin = 29 ± 3 m3/min. While this
change may cause other problems with respect to reaction conversion or yield, such a
change is certainly plausible. In this case and with τc = 10 min, the volume curve of
Figure 1.7 would be unchanged. However, the v and vin in curves would be shifted down
by one unit, which would result in satisfaction of the constraint v < 31. To assess the
revenue impact of this change in nominal throughput, one could employ the following
simple relation:
R
act ual = Rd esi g n + K(vact ual s s o p − vd esi g n s s o p ) (1.9)
where K indicates the value of the product (per m3), vs s o p
d esi g n is the throughput designated
during the design phase and vact ual s s o p is the actual throughput specified by the operator.
Thus, if the actual throughput is equal to the design value, then there will be no change
in profit. If the actual throughput is different, then process revenue will change in the
expected way (i.e., increased throughput gives more revenue and decreased gives less).
To summarize the example, two extreme situations have been identified:
• The uncontrolled case of Figure 1.2 assumes the tank is sufficiently large that volume constraints can be ignored.
• The controller of the top plots of Figure 1.6 completely ignores the exit flow constraint of v < 31 to achieve tight volume regulation.
While many systems can be put into one of these categories, many others cannot. This
is especially true when the design of the plant is highly focused on economic concerns,
which tends to reduce equipment sizes and tighten constraint limits. Thus, an objective
of the text is to illustrate how to handle the gray areas of controller tuning. That is,
address the cases in which the constraints of both the MV and CV are of concern.
1.2 Reactor Control Example: Considering Profit
Let us now expand on the notion of profit by exploring the operational aspects of an
exothermic reactor; specifically, the interplay between operating point selection, controller tuning and the influence of constraints.
10 Chapter 1. Motivation and Overview
Table 1.1. Parameter values for CSTR example
Parameter Symbol Value Units
Reactor volume V 5 m3
Inlet concentration C
Ain 1 kmol e/m3
Pre-exponential factor k0 1010 1/s
Activation energy E/R 1006.5 1/K
Inlet temperature Tin 383 K
Heat of reaction / heat capacity ∆Hr /ρCp 10 K m3/kmol e
0 0.1 0.2 0.3 0.4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Volumetric Flow (m3/s)
Exit Concentration (kmole/m3)
0 0.1 0.2 0.3 0.4
386
387
388
389
390
391
392
393
Volumetric Flow (m3/s)
Reactor Temperature(K)
Figure 1-9: Feasible steady-state operating points for unconstrained CSTR
C
Figure 1.7. Feasible steady-state operating points for unconstrained CSTR
1.2.1 CSTR Profit and the Expected Dynamic Operating Region
Consider the following model of non-isothermal Continuous Stirred Tank Reactor (CSTR) intended to convert a species A to a species B:
0 =
v V
(CAin − CA) − k0e(−R/RT )CA
(1.10)
0 =
v V
(Tin − T ) −
∆H
r
ρCp !k0e(−E/RT )CA
where V is the volume of the reactor, v is the volumetric flow through the reactor, CAin
is the inlet concentration of species A, CA is exit concentration and Tin and T are the
inlet and exit temperatures. The parameters of the process are given in Table 1.1. One
approach to the selection of a steady-state operating point is to select a volumetric flow
rate, v, and then determine the resulting exit concentration and temperature as the solution of (1.10). The plots of Figure 1.7 illustrate this solution for a variety of volumetric
flow values.
While minimization of the exit concentration of A may seem like the objective, as
this would maximize the exit concentration of species B (defined as CAin − CA), one
should also consider the impact of volumetric flow. To this end, assume the instantaneous operating profit of the reactor is defined as the difference between product revenue
(proportional to molar flow of species B exiting the reactor) and feed costs (proportional
to molar flow of species A entering the reactor):
P = c
p r od v(CAin − CA) − cf eed vCAin (1.11)
1.2. Reactor Control Example: Considering Profit 11
The plot of Figure 1.8 shows this profit function, assuming cp r od = 10 $/mol e of
B and c
f eed = 6 $/mol e of A. The point of maximum profit is then found to be at
v = 0.09 m3/s. The corresponding exit temperature and concentration are 390.9K and
0.216 kmol e/m3, and are depicted in Figure 1.9. This operating point will be denoted as
the Optimal Steady-State Operating Point (OSSOP).
: Instantaneous profit of exothermic CSTR as a function of volumetric flow
0 0.1 0.2 0.3 0.4
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
Volumetric Flow (m3/s)
Profit ($/s)
Figure 1.8. Instantaneous profit of exothermic CSTR as a function of volumetric flow
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Exit Concentration (kmole/m3)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
386
387
388
389
390
391
392
393
Reactor Temperature(K)
Figure 1.9. Instantaneous profit of exothermic CSTR as a function of volumetric flow
Now consider the impact of a disturbance. Assume the inlet concentration, CAi n,
varies as in the top left plot of Figure 1.10. To respond to this disturbance (and others),
a PI controller is typically installed. In this case, the PI controller uses exit temperature
as the control variable and volumetric flow as the manipulated variable. The controller
tuning parameters were selected to be as follows: a gain Kc = −0.005 m3/s K, an integral
time-constant τ
I = 50 s and a temperature set-point Ts p = 390.9K. Then, simulation of
a dynamic version of the CSTR model with the above controller results in the remaining
plots of Figure 1.10 - subsequent chapters will illustrate how to determine this dynamic
model and implement this simulation. While the time-series plots of Figure 1.10 seem
to be the natural depiction of closed-loop behaviour, the phase-plane representation will
give additional insight. The bottom two plots of Figure 1.10 show that the reactor will
operate in a region surrounding the operating point. We will denote this region as the
Expected Dynamic Operating Region (EDOR). The utility of a EDOR is greatest in the
context of process constraints, as will be illustrated next.
12 Chapter 1. Motivation and Overview
0 50 100 150
0.5
1
1.5
time (min)
Inlet Concentration (kmole/m3)
0 50 100 150
389
390
391
392
393
time (min)
Reactor Temperature (K)
0 50 100 150
0.05
0.1
0.15
0.2
0.25
0.3
time (min)
Exit Concentration (kmole/m3)
0 50 100 150
0.02
0.04
0.06
0.08
0.1
0.12
time (min)
Volumetric Flow (m3/s)
0 0.1 0.2 0.3 0.4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Volumetric Flow (m3/s)
Exit Concentration (kmole/m3)
0 0.1 0.2 0.3 0.4
386
387
388
389
390
391
392
393
Volumetric Flow (m3/s)
Reactor Temperature(K)
Figure 1.10. Closed-loop response to inlet concentration disturbance.
Top and middle plots - time-series representation, bottom plots - phase-plane representation.
1.2.2 CSTR Constraints and Backed-off Operating Point Selection
Consider again the CSTR model of (1.10) and the profit function of (1.11), but now
require that the following operational constraints are observed:
T ≤ 390K and v ≤ 0.35 m3/s (1.12)
The temperature constraint could be due to protection of the catalysts or avoidance of
side reactions, while the flow constraint is likely due to a pumping limit. Examination
of the new set of feasible steady-state operating points (Figure 1.11) indicates that the
1.2. Reactor Control Example: Considering Profit 13
Figure 1-11: Feasible steady-state operating points for constrained CSTR
0 0.1 0.2 0.3 0.4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Volumetric Flow (m3/s)
Exit Concentration (kmole/m3)
< 0.35
0 0.1 0.2 0.3 0.4
386
387
388
389
390
391
392
Volumetric Flow (m3/s)
Reactor Temperature(K)
T < 390
< 0.35
Figure 1.11. Feasible steady-state operating points for constrained CSTR
operating point of the previous section, v = 0.09 m3/s, is no longer available, as the
temperature constraint would be violated at this flow. A re-examination of the profit
function plot indicates that a new OSSOP will need to be selected. Based on Figure 1.12,
this point corresponds to v = 0.1325 m3/s and T = 390K.
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
Profit ($/s)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
386
387
388
389
390
391
392
Reactor Temperature(K)
Figure 1.12. Optimal steady-state operating point of constrained CSTR
Now consider the impact of the inlet concentration disturbance of Figure 1.10. If
the PI controller used in Figure 1.10 is re-applied to the system (with the same tuning
parameters and the new temperature set-point of 390K), then the EDOR of the top plots of Figure 1.13 will result. Clearly, this type of operation has frequent violations of
the temperature constraint at 390. One way to address this concern is to select a lower
temperature set-point. The middle plots of Figure 1.13 use this approach by selecting a
set-point of 388.5K. The result is that the time-averaged operating point (the center of the
EDOR) will now be backed-off from the OSSOP. As one would expect this Backed-off
Operating Point (BOP) is still on the steady-state operating line (the solid line of the right
plot) and results in an average volumetric flow of 0.225. In this case, the EDOR is pretty
much in observance of the temperature constraint. However, the instantaneous profit is
significantly reduced. In fact, the average profit is negative = −0.1 $/s. Now consider a
retuning of the controller. The bottom plots of Figure 1.13 result from a controller gain
of −0.5 (the previous gain was −0.005) and a temperature set-point of 389.85K. In this
case, the size of the EDOR in the temperature direction is significantly reduced, which
14 Chapter 1. Motivation and Overview
is what allows the set-point to be selected so close the constraint. In this case the average
profit is just below that predicted by the OSSOP calculation.
It is highlighted that reducing EDOR size in the temperature direction came at the
cost of expanding the EDOR in the volumetric flow direction. Fortunately, the pump is
sufficiently large and the flow constraint does not become an issue. However, if the pump
was smaller, for example with a limit of 0.25, then a violation of this constraint would be
expected. In this case, one would want to reduce the controller gain magnitude, to make
the EDOR in the flow direction smaller. However, this would cause the temperature
direction of the EDOR to increase and require further back-off from the OSSOP.
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
Profit ($/s)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
386
387
388
389
390
391
392
Reactor Temperature(K)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
Profit ($/s)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
386
387
388
389
390
391
392
Reactor Temperature(K)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
-1
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
Profit ($/s)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
386
387
388
389
390
391
392
Reactor Temperature(K)
Figure 1.13. EDOR of constrained CSTR. Top plots - Ts p = 390 and Kc = −0.005, middle
plots - Ts p = 388.5 and Kc = −0.005, bottom plots - Ts p = 389.85 and Kc = −0.5
While this iteration between controller tuning (to observe constraints) and back-off
1.2. Reactor Control Example: Considering Profit 15
selection (to improve profit) is intuitive for this single-input single-out example, things
will become much less so for more complicated multi-input multi-output systems. In
these cases, the EDOR will expand from a flat region in a two dimensional space to a
multi-dimension volume in a multi-dimensional space. Furthermore, the set of feasible
steady-state operating points will expand from a single curve to a hyper-surface in the
multi-dimensional space. With these types of problems in mind, the goal of the text is
to develop computational methods that will automate the iterative decision process and
arrive at a method that simultaneously selects the controller tuning parameters along
with the BOP. The details of such a procedure will be given in Chapter 13.
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
0
0.1
0.2
0.3
0.4
0.5
0.6
Profit ($/s)
0 0.1 0.2 0.3 0.4
Feedrate (m3/s)
386
387
388
389
390
391
392
Reactor Temperature(K)
Figure 1.14. Optimal steady-state operating point of constrained CSTR with recovery
1.2.3 CSTR Profit with Equipment Modifications
While the previous CSTR shows an ability to observe constraints and be profitable, the
level of profitability seems a bit low. As such, one might ask if an equipment modification
will improve the situation. The profit function of (1.11) suggests that unconverted portions of the reactant (species A) in the exit stream will be lost with the product. However,
if one were to add a downstream separation unit to recover species A from the product
stream, then the profit function would change to
P = c
p r odv(CAin − CA) − cf eedv(CAin − RCA) (1.13)
where R is the recovery factor (the fraction of A in the exit stream that is recovered).
Figure 1.14 illustrates this new profit as a function of volumetric flow (with R = 0.95)
and indicates that the new OSSOP is located along the flow constraint (right plot). The
plots of Figures 1.15 illustrate various choices for the controller tuning and temperature
set-point. The top plots show significant violation of the flow constraint and as such this
set of tuning values are deemed unacceptable. The back-off of the middle plots shows little
constraint violation, but the back-off is such that a fair amount of profit will be lost. The
profit predicted by the OSSOP is 0.53 $/s, while the backed-off profit is 0.39 $/s - a loss
of 26%. The controller retuning of the bottom plots shows a reduction of the EDOR in
the volumetric flow direction, which allows the back-off to be very small and thus realize
most of the profit predicted by the OSSOP. The profit for this case is 0.493 $/s, a loss of
only 7.5% with respect to the OSSOP.
An interesting aspect of this last controller is that it is barely a controller. That is,
the gain of this controller is so small that it looks like the system is operating in openloop. However, this is the appropriate controller for the given economic situation. This
16 Chapter 1. Motivation and Overview
0 0.1 0.2 0.3 0.4 0.5
Volumetric Flow (m3/s)
-0.5
0
0.5
1
1.5
2
Profit ($/s)
0 0.1 0.2 0.3 0.4 0.5
Volumetric Flow (m3/s)
386
387
388
389
390
391
392
Reactor Temperature(K)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
-0.5
0
0.5
1
1.5
2
Profit ($/s)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
386
387
388
389
390
391
392
Reactor Temperature(K)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
-0.5
0
0.5
1
1.5
Profit ($/s)
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
385
386
387
388
389
390
391
392
Reactor Temperature(K)
Figure 1.15. EDOR of CSTR with recovery. Top plots: Ts p = 387.2 and Kc = −0.5, Middle
plots: Ts p = 389 and Kc = −0.5, Bottom plots: Ts p = 387.3 and Kc = −0.0005
non-intuitive result stems directly from the notion of using the profit function in the
context of operating constraints as the guide for controller design. In other words, no selfrespecting control engineer would suggest such a controller, unless there was an economic
incentive to do so. While the current case is a bit extreme, it illustrates that the process
of using BOP selection to tune a controller gives insight into the important operational
aspects of the system. In many cases, this insight will be more valuable to the control
engineer than the specific controller tuning parameters generated by the algorithm.
Let us now return to the controller of the top plots of Figure 1.15 and ask about
the validity of our analysis in the sense that the simulation made no effort to model the
equipment limitation. That is, if that controller was implemented on the real system
1.2. Reactor Control Example: Considering Profit 17
and the controller asked for a volumetric flow greater than 0.35, then the pump would
simply saturate and implement the limit. A simulation of this scenario is given in the
top plot of Figure 1.16 and results in a profit of 0.488$/s. With the exception of a few
exotic excursions - likely due to wind-up of the integral portion of the PI controller - the
response to this policy looks to be almost identical to that of the bottom plots of Figure
1.15. That is, a volumetric flow that is almost always at a value very close to 0.35. The
time series plots of Figure 1.16 highlight this fact.
0 0.1 0.2 0.3 0.4
Volumetric Flow (m3/s)
-1
-0.5
0
0.5
1
1.5
2
Profit ($/s)
0.1 0.15 0.2 0.25 0.3 0.35
Volumetric Flow (m3/s)
386
387
388
389
390
391
Reactor Temperature(K)
0 50 100 150
time (min)
385.5
386
386.5
387
387.5
388
388.5
389
389.5
Reactor Temperature (K)
0 50 100 150
time (min)
0.1
0.15
0.2
0.25
0.3
0.35
0.4
Volumetric Flow (m3/s)
Figure 1.16. EDOR (top) and time series (bottom) of constrained CSTR with recovery:
T
s p = 387.2 and Kc = −0.5 and volumetric flow saturation at 0.35 m3/s
The question at this point is why all the fuss? If a passive enforcement of the constraints will yield a nearly identical closed-loop response, then why bother with the EDOR analysis? One problem is that the only way to determine the response of a system
with hard constraints is through simulation. However, if we ignore the constraints initially, then techniques exist to determine the EDOR analytically. These analytic methods
can then be used for BOP selection and an unconstrained tuning procedure. Finally,
once the unconstrained tuning parameters have been determined, one can impose hard
constraints. However, if the tuning parameters of the unconstrained controller are such
that constraint violations are rare, then one can be fairly confident that the EDOR of
this controller with constraints imposed will be very close to that of the original. For
example, consider the impact of imposing the saturation on the controller of the bottom
plots of Figure 1.15. Clearly, one would expect the response to be almost identical for the
constrained and unconstrained case. This near equality between the constrained and unconstrained controller will be referred to as an alignment between the controller tuning
parameters and its constraints.
18 Chapter 1. Motivation and Overview
The above discussion could also be viewed of from the BOP selection perspective. If,
in the end, one will use a constrained controller, then the BOP selection procedure should
search over all constrained controllers. However, due to the computational complexity
of a constrained controller, one option is to use an unconstrained control as a surrogate
to reduce computational burden. However, the quality of the surrogate will depend on
how well its tuning is aligned with the constraints.
It should also be highlighted that the saturation simulation could not be performed
on the controller of the top plot of Figure 1.13, where the temperature constraint is
being violated. This is because a PI controller has no ability to enforce constraints on
control variables. To enforce such constraints (on any variable that is not a manipulated
variable) a Model Predictive Control (MPC) type controller will be required. Details on
the implementation of MPC will be given in Chapter 9, but suffice it to say that MPC
has an unconstrained formulation from which analytic methods exist to design the shape
of the EDOR. Then, similar to the above discussion, imposition of constraints onto an
unconstrained MPC that has tuning parameters aligned with the constraints will result
in an EDOR that is almost identical to the unconstrained EDOR.
1.3 Impact of Disturbance Characteristics
0 10 20 30 40
−5
5 0
10
15
20
25
30
35
time (minutes)
Tank Hold−up (m3) or Volumetric Flow (m3/min)
Vν
in
ν
0 10 20 30 40
−5
5 0
10
15
20
25
30
35
time (minutes)
Tank Hold−up (m3) or Volumetric Flow (m3/min)
Figure 1.17. Surge tank simulations under uncontrolled policy
In the opening comments of the chapter, it was suggested that the type of uncertainty
facing a process will influence expected performance. In this section, we return to the
level control example of Section 1.1 and explore how the characteristics of the disturbance
will impact performance and what recourse can be taken.
We begin by revisiting the simulation of Figure 1.3, where the exit flow from the
tank was held constant (at 30 m3/min ) and the inlet flow, vin, was in the range 30 ±
3 m3/min. The left plot of Figure 1.17, reiterates that the tank is expected to over-flow
under this scenario. However, the right plot of Figure 1.17, shows no over-flow, even
though the exit flow is still fixed at 30 m3/min and the inlet is 30±3 m3/min. The only
difference is that the time duration between inlet flow step changes is smaller in the right
plot than in the left. In subsequent chapters, this notion of duration will be denoted as
correlation time.
1.3. Impact of Disturbance Characteristics 19
0 10 20 30 40
−5
5 0
10
15
20
25
30
35
time (minutes)
Tank Hold−up (m3) or Volumetric Flow (m3/min)
Vν
in
ν
0 10 20 30 40
−5
5 0
10
15
20
25
30
35
time (minutes)
Tank Hold−up (m3) or Volumetric Flow (m3/min)
Figure 1.18. Surge tank simulations with PI control (τc = 10)
Figure 1-20: BOP selection for the scenario of Figure 1-18 (left).
V
*
29 31
0
New BOP
 !
*
V
EDOR
* *
29 31
0
 !
V
EDOR
* *
OSSOP
29 31
20
0
New BOP
 !
V
EDOR * *
OSSOP
29 31
20
0
Original Operating Point
Figure 1.19. BOP selection for the scenario of Figure 1.18 (left)
0 10 20 30 40
−5
5 0
10
15
20
25
30
35
time (minutes)
Tank Hold−up (m3) or Volumetric Flow (m3/min)
V
ν
in
ν
Figure 1.20. Surge tank simulations with PI control (τc = 50)
In the controlled case, Figure 1.18 illustrates that disturbance correlation time will
also have an impact on the manipulated variables. In Section 1.1, it was concluded that
a reduction in nominal throughput (by 1 m3/mi n) would be required to satisfy all the
constraints. However, when the disturbance has a smaller correlation time (the right
plot of Figure 1.18), all of the constraints seem to be satisfied and thus no change to the
20 Chapter 1. Motivation and Overview
Figure 1-21: BOP selection for the scenario of Figure 1-19.
V
EDOR
*
OSSOP
29 31
20
0
New BOP
 !
*
V
EDOR
* *
OSSOP
29 31
20
0
Original
Operating Point
 !
Figure 1.21. BOP selection for the scenario of Figure 1.20
nominal throughput will be required. In fact, one may even wish to de-tune the controller
further, as in Figure 1.20. In this case, on could increase the nominal throughput (by
0.75 m3/min) and generate revenue greater than the design condition.
Figures 1.19 and 1.21 illustrate these notions from the phase-plane perspective. Notice
the intuitive nature of the phase plane plots. Specifically, it is easily visualize moving the
BOP (the center of the EDOR) to be as close as possible to the OSSOP, but such that
EDOR does not violate the constraints. This sort of visualization will be central to the
developments of Chapter 13, but will occur within a multi-dimensional settling.
1.4 Chapter Summary
The objective of economic optimal control is to maintain the highest plant profitability
in the face of a changing environment. As discussed above, the definition of this changing
environment could be limited to the short term variations resulting from the influence
of disturbances. However, one could also define the changing environment to include
the longer term changes in the process as well as the characteristics of the disturbance
(mean, variance and correlation time). In response to this larger time scale evolution of
the environment, the desired recourse is to redesign (or retune) the controller. To enable
this retuning activity, two technologies will be required:
• A method to characterize the process (the plant and the disturbances).
• An economic based tuning method that can respond to a changing environment.
It should be highlighted that the proposed notion of disturbance characterization goes
beyond simply modeling the impact of measured disturbances on process outputs. The
models desired will need to make predictions about future disturbances based on measurements of the past. In this book we will begin by review existing methods for the first need
area (process characterization) and then propose new control system design methods that
make full use of the economic, plant and disturbance characterizations. The envisioned
economic based controller design scheme is one in which a changing environment can
be estimated on-line. Then, this updated environment is sent to an automated controller
retuning algorithm. The net result is a system that can adapt, not just to changing output
measurements, but to a changing scenario.
The notions outlined in this chapter indicate a destination for the text. Unfortunately, a significant amount of preliminary material will be required to arrive at this target.
That is, the development of a general methodology capable of addressing a wide class of
processes will require the use of significant background material. This background material will be provided in Part II. We will then return to the subject of plant economics
1.4. Chapter Summary 21
in Part III. Fortunately, much of the material of the background chapters is expected to
be of independent interest to the reader and can be thought of as a survey of the control
theory literature. It should be highlighted that these background chapters will focus on
presenting results rather than providing in-depth derivations of the results. However,
at the end of each chapter efforts have been made to guide the reader to the source and
documentation of the full derivation of the presented results.
1.4.1 Review of Literature on Economic Based Controller Design
It should be highlighted that the notion of profit guided control system design is not new
or novel. In fact, this question has been around for many decades and many researchers
have contributed significantly to answering such questions. The following is not intended
to be an exhaustive review, but merely an attempt to provide context.
We begin with the process design and optimization community. This community
is clearly focused on the topic of process economics. However, their attraction to controller design stems from an interest in mimicking how plant operations would deal with
process uncertainty. While many approaches have been proposed, two are of particular
interest; flexibility analysis and chance constrained optimization. Flexibility analysis uses
nominal values in the objective function, but enforces constraints based on the full range
of uncertain parameters. Deterministic versions include: Nishida et al. [2], Grossmann & Sargent [3], Polak & Sangiovanni-Vincentelli [4], Halemaane & Grossmann [5],
Lasserre & Roubellat [6], Saboo et al. [7], Swaney & Grossmann [8, 9], Grossmann &
Floudas [10], Raspantia et al. [11], Ostrovsky et al. [12], Chakraborty & Linninger
[13], Banerjee & Ierapetritou [14] and Malcolm et al. [15]. The stochastic extensions
include: Pistikopoulos & Grossmann [16], Pistikopoulos & Mazzuchi [17], Straub &
Grossmann [18], Pistikopoulos & Ierapetritou [19], Mohideen et al. [20], Ahmed &
Sahinidis [21], Rooney & Biegler, [22] and Bansal et al. [23]. Most of these methods
are primarily interested in a design based on a reasonable representation of the control
system. However, in some the cases a feedback element is specified. Chance constrained
optimization begins by calculating the probability density function of key process variables, and then seeks to ensure that constraint violations are below a pre-specified percentage. General descriptions can be found in Charnes & Cooper [24], Miller & Wagner
[25], Uryasev [26], Cooper et al. [27], Henrion & Romisch ¨ [28] and Nemirovski &
Shapiro [29]. Application to process systems type problems include: Petkov & Maranas
[30, 31], Schwarm & Nikolaou [32], Li et al. [33, 34, 35, 36] and Henrion & Moller ¨
[37]. A handful of these efforts focus on controller synthesis.
Another important (but very large) group is the control structure selection community. While process economics remains the motive, the objective changes to which MV’s
and CV’s should one use to mitigate uncertainty. Broad discussions on the motives and
high level procedures can be found in: Morari et al. [38], Fisher et al. [39], Stephanopoulos & Ng [40], Skogestad [41, 42], van de Wal & de Jager [43] and Ward et al. [44]. Measurement and CV selection efforts include: Mellefont & Sargent [45], Harris et al. [46],
Morari & O’Dowd [47], Morari & Stephanopoulos [48], Romagnoli et al. [49], Lee &
Morari [50], Hovd & Skogestad [51], Wisnewski & Doyle [52] and van de Wouwer et al.
[53], Antoniades & Christofides [54], Muske & Georgakis [55], Alonso et al. [56], Peng
& Chmielewski [57], Singh & Hahn [58] and Armaou & Demetriou [59]. Recognizing the computational challenge of investigating all possible MV/CV set combinations,
screening methods have been proposed: Lee et al. [60], Lewin [61], Cao & Rossiter [62],
Zheng & Mahajanam [63], Figueroa [64], Vinson & Georgakis [65], Seferlis & Grievink
[66], Chodavarapu & Zheng [67], Georgakis et al. [68], Hovd et al. [69], Biagiola et
22 Chapter 1. Motivation and Overview
al. [70] and Cao & Saha, [71]. Finally, Perkins and colleagues (Narraway et al., [72];
Narraway & Perkins, [73, 74]; Loeblein & Perkins, [75, 76, 77, 78]; Heath et al., [79];
Kookos & Perkins, [80]) have used Backed-off Operating Point (BOP) selection to provide economic bearing. While most schemes address only the structure question, many
generate good controllers as a by-product.
If the process design and control structure are given, then the next question is to
determine a BOP. BOP selection schemes based on flexibility analysis include: Bahri et
al. [81], Young et al. [82], Bahri et al. [83], Figueroa et al. [84], Contreras-Dordelly
& Marlin, [85], Zhang & Forbes, [86], Figueroa & Desages, [87], Rooney & Biegler
[88], Arbiza et al. [89], Young et al. [90] and Soliman et al. [91], Most of these assume
steady-state disturbances (the time characteristic of the disturbance is much larger than
the largest time constant of the process). Approaches based on chance constraints or
stochastic control include: Loeblein & Perkins [77, 78], van Hessem et al. [92], Muske,
[93], Peng et al., [94], Lee et al. [95], Akande et al. [96] and Zhao et al. [97]. Finally, we
arrive at the economic based controller synthesis community. Engell [98] and Rawlings
& Amrit [99] advocate an economic objective function within MPC. van Hessem et al.
[92], Peng et al., [94] and Zhao et al. [97] extend BOP selection to simultaneously arrive
at economically motivated controllers.
Finally, it is interesting to note that the relation between process control and process
economics is highlighted in many introductory text on process control, see for example
Seborg et al., [1], Riggs & Karim [100] and Romagnoli and Palazoglu [101]. For an
interesting historical perspective on the subject, see Edgar [102].
Chapter 2
Modeling of Dynamic
Systems
The process model will be the starting point for all of our controller design efforts. This
model should be of sufficient fidelity that the relationship between process inputs and
outputs can be understood. It should be emphasized that a dynamic model of extremely
high fidelity is not likely required and in many cases is not desired. This is due to the
fact that the dominant features of a dynamic process can usually be captured by a relatively simple model. Furthermore, use of an overly complicated model may needlessly
preclude utilization of some extremely powerful controller design methods. One should
also remember that the model used to design the controller (or in some cases used within
the controller) is not the actual process. Thus, in the absence of the actual process, the
controller should be tested on a model with the highest fidelity available. It is finally noted that this chapter on the modeling of processes is only half of the modeling challenge.
The second half - on the modeling of process disturbances - will be addressed in Chapter
5. Since disturbance attenuation is usually the objective of a control system, having a
sufficient disturbance model will be essential to the design of a successful controller.
Throughout the text we will employ a state variable perspective in process modeling.
For those unfamiliar with the state variable approach, the following high level description
should provide some perspective. The state of a system at a given time is the minimum
information required to completely specify the condition of the system. Said another
way, if given the system state and the future values of the input signals, all future outputs
can be predicted. This is significantly different from classic input-output models, which
require all of the past inputs to the system to predict the future outputs. In essence, the
system state contains all of the important information pertaining to the history of the
process. In the development of a state space model, the central task is to appropriately
select a set of process variables to be the state variables. Then, the value of these variables
at a given time will be the system state. While the choice of state variables is not unique,
they are usually chosen to correspond to physically meaningful quantities.
2.1 Nonlinear State-Space Models
A reasonably general class of dynamic models is that of a nonlinear finite-dimensional
state-space process. Such models will contain the following variables (or signals): a state
vector s, a vector of manipulated variables m, a vector of disturbance variables p, a vector
of performance outputs q and a vector of measured outputs θ, which are corrupted by
measurement noise n.
23
24 Chapter 2. Modeling of Dynamic Systems
Dynamic Process
with state vector s
Disturbance inputs: p
Vector of manipulated
variables: m
Physical measurements
corrupted by noise:
Performance outputs: q
Feedback
Controller
Figure 2-1: Block diagram of the inputs and outputs of a process model
Figure 2.1. Block diagram of the inputs and outputs of a process model
˙s = f (s, m, p) (2.1)
q = h(s, m, p) (2.2)
θ = l(s,n) (2.3)
where the dot above the s in equation (2.1) denotes the first derivative of s with respect to
time. The function f is usually due to the physical aspects of the process. The fact that a
first derivative term exists in (2.1) for each variable in the state vector, provides significant
guidance in the identification of state variables. The function h is a construct of the
process engineer intended to reflect the important variables of the process. The vector of
performance outputs, q, should not be confused with the set of measured outputs, θ. The
difference being that measured outputs, θ, are physically obtained signals available to the
controller for feedback purposes. In contrast, the performance outputs, q, may or may
not be physically measured and may contain any variable of interest. Similarly, the set of
manipulated variables, m, are those available to the controller to influence the process. In
contrast, the disturbance variables, p, will influence the process, but the controller will
have no influence over these signals. It is also noted that the disturbance variables and the
measurement noise vector, n, are usually distinct.
FA,in ,
NA , V
2A B rA FA,out ,
Figure 2-1: Continuous Stirred Tank Reactor of Example 2-1
Figure 2.2. Continuous Stirred Tank Reactor of Example 2.1
Example 2.1. Consider a Continuous Stirred Tank Reactor (CSTR) in which a second
order reaction 2A→ B is the only reaction taking place. More specifically, the kinetic expression for production of species Ais rA = −2kCA2, where CA is the molar concentration
2.1. Nonlinear State-Space Models 25
of species A in the reactor and k is the rate constant. (rA has units of moles of A/m3s.) A
mole balance over the reactor is:
Accumulation = Moles In - Moles Out + Moles Generated
which gives:
dN
A
d t
= F
A,in − FA,out +V rA (2.4)
where N
A is the number of moles of species A within the reactor of volume V , FA,in is the
molar flow of A into the reactor and F
A,out is the molar flow out. Noting that NA = V CA,
FA
,in = vCA,in and FA,out = vCA (where CA is the concentration of A within the reactor,
CA
,in is the concentration of the inlet flow and v is the volumetric flow through the
reactor, with units of mol es/m3 and m3/s, respectively) one arrives at the following
differential equation model of the reactor.
˙CA
=
v V
CA
,in −
v V
CA
− 2kC2
A (2.5)
From this expression it is clear that CA should be selected as the state variable. The
selection of manipulated and disturbance variables will be up to the control engineer.
Let us assume the volumetric flow rate through the reactor, v, can be manipulated and
the inlet concentration of A, CA,in, is outside the influence of the controller and is thus
classified as the disturbance (assume k and V are constant for all time). Based on these
definitions the function f of equation (2.1) is found to be
f (s, m, p) =
m V
p −
m V
s − 2k s2 (2.6)
Definition of the performance output is again up to the control engineer. If the only
variables of interest are the state and manipulated variables, then the definition of h of
equation (2.2) is
h(s, m, p) =  ms  (2.7)
The simplicity of the performance equation usually makes it somewhat difficult to determine. The procedure should become clearer when we address more complicated processes. The concept to note at this point is that since we are interested in two output signals
the function h will be a vector function.
Let us further assume there will be physical measurements available to the controller.
In particular, assume CA, concentration within the reactor, is measured and possesses
additive measurement noise. In this case, the definition of l of (2.3) would be:
l(s,n) = s + n (2.8)
If there is also a measurement of the inlet concentration, CA,in, then it would appear
that the structure of Equation (2.3) precludes inclusion of this measurement. However,
one may postulates a new state variable, Cm, to incorporate a small time constant, τm,
associated with the physical measurement: C˙m = (CA,in − Cm)/τm. In this case, the state
vector would have two elements
s =  s s((12) )  =  CCmA  (2.9)
26 Chapter 2. Modeling of Dynamic Systems
and the full nonlinear process model can be stated as:
f (s, m, p) =  Vm p −(pVm−s(s1()2−))/τ 2km(s(1))2  (2.10)
h(s, m, p) =  sm(1)  (2.11)
l(s,n) =  ss((12)) + + nn((12))  (2.12)
ia if
va
+ _
vf
+ _
Lf
Rf
La
Ra
B
J TL
Kv
if
+ _
Figure 2-3: DC motor of Example 2-2
Figure 2.3. DC motor of Example 2.2
Example 2.2. Consider the following system of differential equations describing the DC
motor of Figure 2.3.
L
f
di
f
d t
= −R
f if + vf
L
a
d i
a
d t
= −R
aia − Kvωif + va (2.13)
J
dω
d t
= −Bω + K
viaif + TL
where i
f and ia are the currents through the field and armature coils, respectively and ω
is the angular speed of the motor. In addition, vf and va are the voltage applied to the
field and armature circuits, respectively and TL is the torque applied to the motor. (If
TL
< 0, then the motor is applying the torque.) All of the other terms are assumed to be
constant parameters of the motor. Due to the derivative terms of (2.13) it is clear that the
state vector should is
s =

s(1)
s(2)
s(3)

=

i
f
i
aω

(2.14)
2.1. Nonlinear State-Space Models 27
where s(i) simply denotes the it h element of the vector s. Once again determination of
the manipulated and disturbance variables is application dependent. Assume the field and
armature voltages are at the service of the controller. In addition, assume the torque will
change over time, but the controller has no influence on the amount of torque applied to
the motor. These assumptions yield the following definitions.
m =  mm( (1 2))  =  vvaf  p = [TL] (2.15)
Then, the vector function f is expressed as
f (s, m, p) =

1Lf
−Rf s(1) + m(1)
1La
−Ras(2) − Kv s(3)s(1) + m(2)
1J
−Bs(3) + Kv s(2)s(1) + p

(2.16)
Assume there are two indicators of process performance; total electrical and mechanical
power sent to the motor. If the two power signals are defined as Pe = if vf + iava, and
P
m = TLω, then h should be defined as:
h(s, m, p) =  s(1)m(1ps ) +(3s)(2)m(2)  (2.17)
Mass
fa
r
max
r
rmin
fd
Figure 2.4. Figure 2-4: Mass-spring damper of Example 2-3 Mass-spring damper of Example 2.3
Example 2.3. Consider the following second order differential equation describing a
mass-spring damper system (depicted in Figure 2.4).
M
d2r
d t2 = −b
d r
d t
− k r + fa + fd + fg (2.18)
where r is the position of the mass, fa and fd are forces applied to the mass (where fa
is under the influence of the controller and fd is not) and M, b, k and fg are constant
parameters. In this system, the appearance of a second order derivative term seems to
preclude connection with equation (2.1). However, if we simply define a new variable
28 Chapter 2. Modeling of Dynamic Systems
v = d r /d t, then the following system of differential equations will arise:
d r
d t
= v (2.19)
d v
d t
=
1 M
−b v − k r + fa + fd + fg (2.20)
From this point it is clear that one should select the state, manipulated and disturbance
vectors as:
s =  s s((12) )  =  vr  m = [fa] p = [fd] (2.21)
Then, the vector function f should be expressed as:
f (s, m, p) =  M1 −b s(2) − k ss((12))+ m + p + fg  (2.22)
As indicated in Figure 2.4, the position of the mass is restricted, which may be expressed
as rmin ≤ r ≤ rmax. Assume similar restrictions will be enforced for the manipulated
variable (fa,min ≤ fa ≤ fa,max) as well as for mass acceleration (amin ≤ a ≤ amax) where a
is defined as:
a =
1 M
−b v − k r + fa + fd + fg (2.23)
In this case, we should define the performance vector, q, as:
q =

q(1)
q(2)
q(3)

=

rfaa

(2.24)
Then, the vector function h should be defined as:
h(s, m, p) =

s(1)
m
1M
−b s(2) − k s(1) + m + p + fg

(2.25)
We can now express the inequality restrictions in the following compact form
qmin ≤ q ≤ qmax (2.26)
where qmin and qmax are defined as:
qmin =

rmin
fa,min
amin

qmax =

r
max
fa,max
a
max

(2.27)
2.2. Deviation Variables 29
2.2 Deviation Variables
In many cases it will be desired to operate the process near a steady-state operating condition. In general, a steady-state operating point (SSOP) is defined by the nonlinear statespace model evaluated with the time derivative terms set equal to zero:
0 = f sSSOP, mSSOP, pSSOP (2.28)
q(SSOP) = h sSSOP, mSSOP, pSSOP (2.29)
θ(SSOP) = l sSSOP,nSSOP (2.30)
where the triple (sSSOP, mSSOP, pSSOP) is any set of vector values satisfying equation
(2.28). If the following deviation variables are defined:
x = s − sSSOP (2.31)
u = m − mSSOP (2.32)
w = p − pSSOP (2.33)
z = q − qSSOP (2.34)
y = θ − θSSOP (2.35)
v = n − nSSOP (2.36)
then, the following deviation variable model can be constructed:
x˙ = f x + sSSOP, u + mSSOP,w + pSSOP (2.37)
z = h x + sSSOP, u + mSSOP,w + pSSOP − qSSOP (2.38)
y = l x + sSSOP,v + nSSOP − θSSOP (2.39)
The advantage of the deviation variable form is that the desired condition of (s, m, p, q, θ,
n) = (sSSOP, mSSOP, pSSOP, qSSOP, θSSOP, nSSOP) is achieved when (x, u, w, z, y, v) =
(0, 0, 0, 0, 0, 0).
Example 2.4. Reconsider the mass-spring damper system of Example 2.3 and assume a
SSOP triple (sSSOP, mSSOP, pSSOP) has been identified. Specifically, if pSSOP is given and
mSSOP is arbitrarily selected, then by using the relations (2.28)-(2.29), sSSOP and qSSOP
are calculated to be
sSSOP =  k1 mSSOP +0pSSOP + fg  (2.40)
qSSOP =

1k
mSSOP + pSSOP + fg
mSSOP
0

(2.41)
If we now employ the definitions of (2.31)-(2.33) and apply (2.37), we arrive at the follow
30 Chapter 2. Modeling of Dynamic Systems
ing deviation variable model of the state equation:
x˙ =

x(2) + s(2)SSOP
1M
 − b(x(2) + s(2)SSOP) − k(x(1) + s(1)SSOP)
+ (u + mSSOP) + (w + pSSOP) + fg

=

x(2)
1M
 − b x(2) − k x(1) + u + w
− k s(1)SSOP + mSSOP + pSSOP + fg

(2.42)
=

x(2)
1M
 − b x(2) − k x(1) + u + w

where the equalities utilize the identities of (2.40). Application of the definitions of (2.31)-
(2.34) to (2.38) yields:
z =

x(1) + s(1)SSOP
u + mSSOP
1M

−b(x(2) + s(2)SSOP)
−k(x(1) + s(1)SSOP)
+(u + mSSOP)
+(w + pSSOP) + fg


−

s(1)SSOP
mSSOP
1M

−b s(2)SSOP
−k s(1)SSOP
+mSSOP
+pSSOP + fg


=

x(1)
u
1M
−b x(2) − k x(1) + u + w

(2.43)
Equations (2.42)-(2.43) can be further manipulated into the following form:
x˙ = Ax + B u + Gw (2.44)
z = D
x x + Du u + Dw w (2.45)
where the matrices A, B, G, Dx, Du, and Dw are defined as:
A=  −0 1 Mk −Mb  B =  M01  G =  M01  (2.46)
D
x =

1 0
0 0
−
kM
−
bM

D
u =

011M

D
w =

001M

(2.47)
The following two definitions indicate when a state-space model will be within the
special class of linear models.
Definition 2.1. A function f (s) is linear with respect to s, if the following conditions hold:
2.3. Linearization of Nonlinear Models 31
(i) f (0) = 0
(ii) f (αs) = α f (s) for all s and all scalars α
(iii) f (s1 + s2) = f (s1) + f (s2) for all s1 and s2
Definition 2.2. A state-space process model (2.1)-(2.3) is linear if f (s, m, p), h(s, m, p)
and l(s, n) are all linear with respect to all four variables s, m, p and n.
Example 2.5. Reconsider the deviation variable model of the mass-spring damper system
developed in Example 2.4. If Equations (2.44)-(2.45) are expressed as:
x˙ = f (x, u, w) (2.48)
z = h(x, u, w) (2.49)
then, f (x, u, w) = Ax +B u +Gw and h(x, u, w) = Dx x +Du u +Dww. Then, one can
easily verify that the functions f and h satisfy Definition 2.2. If one looks back to the
original mass-spring-damper model of Example 2.3, it is easily observed that the second
term of Equation (2.16) does not satisfy Definition 2.2 (due to the constant term fg).
Fortunately, the conversion to deviation variables yields a linear form.
2.3 Linearization of Nonlinear Models
In most cases the conversion to deviation variable form will not yield a linear model. In
these cases one will need to resort to linearization. The method of linearization is simply
an application of the Taylor series expansion. Specifically, a function f (s) is equal to the
following expression:
f (s) = f (so) +
∂ f
∂ s
s=s
o
(s − so) +
1 2
∂ 2 f
∂ s2
s=s
o
(s − so)2 + ··· (2.50)
The basic idea is that use of a finite number of terms will yield a “good” approximation of
f (s) for values of s that are “close” to so. The quotes around good and close are intended
to indicate the qualitative nature of this statement. In practice, it will be important to
validate this statement quantitatively. To arrive at a linear approximation of f (s) one
should retain only the first two terms of the expansion. In the vector case, one finds that
a function f (s, m, p) can be approximated by the following expression:
f (s, m, p) ∼ =f (so, mo, po) +
∂ f
∂ s s=so
m=m
o
p=po
(s − so)
+
∂ f
∂ m s=so
m=m
o
p=po
(m − mo) +
∂ f
∂ p s m==som
o
p=po
(p − po) (2.51)
If the triple (so, mo, po) is selected to be (sSSOP, mSSOP, pSSOP), then f (sSSOP, mSSOP,
pSSOP) = 0 can be applied along with the definitions of (2.31)-(2.33) to find:
f (s, m, p) ∼ =
∂ f
∂ s s=sSSOP
m=mSSOP
p=pSSOP
x +
∂ f
∂ m s=sSSOP
m=mSSOP
p=pSSOP
u +
∂ f
∂ p s=sSSOP
m=mSSOP
p=pSSOP
w (2.52)
32 Chapter 2. Modeling of Dynamic Systems
Since the partial derivatives are evaluated at the SSOP, each of these coefficients will be
constants. Then, recalling that the time derivative of s is equal to the time derivative of
x, yields x˙ = Ax + B u + Gw as linear deviation variable approximation of (2.1), where
A=
∂ f
∂ s s=sSSOP
m=mSSOP
p=pSSOP
B =
∂ f
∂ m s=sSSOP
m=mSSOP
p=pSSOP
G =
∂ f
∂ p s=sSSOP
m=mSSOP
p=pSSOP
Similar use of the Taylor expansion on the performance output q = h(s, m, p) gives
h(s, m, p) ∼ =h(so, mo, po) +
∂ h
∂ s s=so
m=m
o
p=po
(s − so)
+
∂ h
∂ m s=so
m=m
o
p=po
(m − mo) +
∂ h
∂ p s m==som
o
p=po
(p − po) (2.53)
If the triple (so, mo, po) is selected to be (sSSOP, mSSOP, pSSOP), then qSSOP = h(sSSOP,
mSSOP, pSSOP) can be applied along with the definitions of (2.31)-(2.33) to find:
q ∼ = qSSOP + ∂ h
∂ s s=sSSOP
m=mSSOP
p=pSSOP
x +
∂ h
∂ m s=sSSOP
m=mSSOP
p=pSSOP
u +
∂ h
∂ p s=sSSOP
m=mSSOP
p=pSSOP
w (2.54)
Thus, z = q − qSSOP ≈ Dx x + Du u + Dww where
D
x =
∂ h
∂ s s=sSSOP
m=mSSOP
p=pSSOP
D
u =
∂ h
∂ m s=sSSOP
m=mSSOP
p=pSSOP
D
w =
∂ h
∂ p s=sSSOP
m=mSSOP
p=pSSOP
(2.55)
If the physical measurements possess only additive disturbances, i.e., the measurement
equation is of the form θ = l(s)+n, then θSSOP = l(sSSOP)+nSSOP can be applied along
with (2.31), (2.35)-(2.36) to find y = θ − θSSOP ≈ C x + v where C = ∂∂ ls s=sSSOP.
Figure 2-5: Simulations of CSTR model of Example 2-6
0 50 100 150
0.18
0.2
0.22
0.24
0.26
0.28
0.3
0.32
0.34
Time (s)
Concentration of A
Nonlinear Solution
Linearized Solution
Figure 2.5. Simulations of CSTR model of Example 2.6
2.3. Linearization of Nonlinear Models 33
Example 2.6. Reconsider the CSTR process of Example 2.1. Assume the volume of
the reactor is 3 m3 and rate constant is 0.1 m3 per mol e per s ec. If the nominal inlet
concentration is 1 mol e per m3 and the exit concentration is desired to be 0.3 mol es
per m3, then (based on a steady-state version of Equation (2.5)) the volumetric flow
rate should be selected as 0.0771 m3 per sec. Thus, the SSOP triple is determined to
be (sSSOP, mSSOP, pSSOP) = (0.3, 0.0771, 1). If f (s, m, p) = Vm p − Vm s − 2k s2, then
A =
∂ f
∂ s s=sSSOP
m=mSSOP
p=pSSOP
= −Vm − 4k s s=0.3
m=0.0771
p=1
= −0.146 (2.56)
B =
∂ f
∂ m s=sSSOP
m=mSSOP
p=pSSOP
= Vp − Vs  s=0.3
m=0.0771
p=1
= 0.233 (2.57)
G =
∂ f
∂ p s=sSSOP
m=mSSOP
p=pSSOP
= Vm  s=0.3
m=0.0771
p=1
= 0.0257 (2.58)
Let us now compare the simulations of the CSTR process using the nonlinear model
and the linearized model. Assume the initial condition is C
A(0) = 0.2 mol e per m3.
Furthermore, assume CAin = 1 for t = [0 50], CAin = 0.5 for t = [50 150], v = 0.771
for t = [0 100], and v = 1.5 for t = [100 150]. Using the MATLAB code of Tables 2.1
and 2.2, the plot of Figure 2.5 was generated. While the two simulations are not identical,
they do possess a great deal of similarity. Notice that the largest discrepancy occurs at
the end of the simulation, which corresponds to operation furthest from the point of
linerization (the SSOP).
Table 2.1: MATLAB code used in calculations for Example 2.6
clear
V=3;k=0.1;CAinbar=1;CAbar=0.3;
nubar=2*k*CAbar^2*V/(CAinbar-CAbar); x0=0.2;
% Calculate solution with nonliner ODE
linearize='n';
[tt1,xxode1]=ode23(@(t,x) cstr(t,x,linearize,V,k,CAbar,nubar,CAinbar),...
[0 150],x0);
% Calculate solution with linearized ODE
linearize='y';
[tt2,xxode2]=ode23(@(t,x) cstr(t,x,linearize,V,k,CAbar,nubar,CAinbar),...
[0 150],x0);
%xxode=zzode(:,1); yyode=zzode(:,2);
plot(tt1,xxode1,'-*b',tt2,xxode2,'-^k','MarkerSize',8)
legend('Nonlinear Solution','Linearized Solution')
ylabel('Concentration of A'), xlabel('time')
Table 2.2: MATLAB code used in calculations for Example 2.6
function dsdt = cstr(t,s,linearize,V,k,CAbar,nubar,CAinbar)
% This function should be in a file named 'cstr.m'
CA=s(1); nu=nubar; CAin=CAinbar;
if t > 50 CAin = 0.5, end
if t > 100 nu=0.15, end
if linearize=='y'
A=-nubar/V-4*k*CAbar, B=(CAinbar-CAbar)/V, G=nubar/V,
x=CA-CAbar; u=nu-nubar; w=CAin-CAinbar;
dsdt=A*x+B*u+G*w;
else
34 Chapter 2. Modeling of Dynamic Systems
dsdt=CAin*nu/V-CA*nu/V-2*k*CA^2;
end
Example 2.7. Reconsider the DC motor model of Example 2.2. Assume a SSOP triple
(sSSOP, mSSOP, pSSOP) satisfying (2.28) has been determined and the deviation variable
definitions of (2.31)-(2.36) are to be used. Recall the nonlinear state-space model
L
f
di
f
d t
= −R
f if + vf
L
a
d i
a
d t
= −R
aia − Kvωif + va (2.59)
J
dω
d t
= −Bω + K
viaif + TL
Along with the performance outputs Pe = if vf + iava, and Pm = TLω. Then, a linear
state-space model approximating the original is found to be of the form:
x˙ = Ax + B u + Gw (2.60)
z = D
x x + Du u + Dww (2.61)
where
A =
∂ f
∂ s s=sSSOP
m=mSSOP
p=pSSOP
=

−
R
f
L
f
0 0
−
Kv
ωSSOP
L
a
−
R
a
L
a
−
Kv
iSSOP
fLa
Kv
iSSOP
aJ
Kv
iSSOP
fJ
−
BJ

(2.62)
B =
∂ f
∂ m s=sSSOP
m=mSSOP
p=pSSOP
=

1/Lf 0
0 1/La
0 0

G =
∂ f
∂ p s=sSSOP
m=mSSOP
p=pSSOP
=

001J

(2.63)
D
x =
∂ h
∂ s s=sSSOP
m=mSSOP
p=pSSOP
= vfSSOP 0 vaSSOP 0 TLSSOP 0  (2.64)
D
u =
∂ h
∂ m s=sSSOP
m=mSSOP
p=pSSOP
= ifSSOP 0 0 iaSSOP Dw = ∂∂ hp s=sSSOP
m=mSSOP
p=pSSOP
= ωSSOP 0  (2.65)
Example 2.8. Reconsider the DC motor model of Example 2.7. Assume the system
has the following parameters; Lf = 50H, Rf = 25Ω, La = 2H, Ra = 0.5Ω, Kv =
0.91V /(A rad/s), J = 5N m and B = 0.3N m/(rad/s).
(i) Assume the following nominal conditions are required: mSSOP = [36V 360V ]T
and pSSOP = [−280N m]. Determine sSSOP and qSSOP.
2.3. Linearization of Nonlinear Models 35
(ii) Linearize the nonlinear model around the SSOP of part (i).
(iii) Using a MATLAB ODE solver, compare the linearized model solution with that
of the original nonlinear model. Assume the initial condition is the SSOP and va
and T
L remain at their nominal values for all time and consider the following two
scenarios:
Case 1: v
f = 36V for t = [0, 10], 38V for t = [10 50] and 34V for t = [50 100].
Case 2: v
f = 36V for t = [0, 10], 56V for t = [10 50] and 26V for t = [50 100].
Solution: Solving the first steady state equation yields: ifSSOP = vfSSOP /Rf . Substitution
into the third yields: ω = (Kv iaSSOP vfSSOP /Rf +TLSSOP)/B. Substitution of both into the
second steady state equation yields:
iSSOP
a
=
vSSOP
a
− K
vTLSSOP vfSSOP /(Rf B)
R
a + Kv2(vfSSOP /Rf )2/B (2.66)
Using these formula one finds:
sSSOP =

iSSOP
f
iSSOP
a ω
SSOP

=

1.44 A
254 A
178 rad/s

qSSOP =  P PemSSOP SSOP  =  91 49..27 kW kW   (2.67)
Using Equations (2.62)-(2.65) one finds
A=
∂ f
∂ s s=sSSOP
m=mSSOP
p=pSSOP
=

−0.50 0 0
−80.8 −0.250 −0.655
46.3 0.262 −0.060

B =
∂ f
∂ m s=sSSOP
m=mSSOP
p=pSSOP
=

0.02 0
0 0.5
0 0

G =
∂ f
∂ p s=sSSOP
m=mSSOP
p=pSSOP
=

00
0.2

D
x =
∂ h
∂ s s=sSSOP
m=mSSOP
p=pSSOP
= 36 360 0 0 0 −280
D
u =
∂ h
∂ m s=sSSOP
m=mSSOP
p=pSSOP
= 1.0 0 44 254 Dw = ∂∂ hp s=sSSOP
m=mSSOP
p=pSSOP
= 177 0 
The plots of Figures 2.6 and 2.7 were made with the code of Tables 2.3, 2.4 and 2.5.
Notice that in case 1 the discrepancies are quite small, but are much larger in case 2. This
is due to the fact that in case 2 operation is much further from the point of linearization.
Also, note that since the first equation is liner, there is no discrepancy in either of the
field current plots.
36 Chapter 2. Modeling of Dynamic Systems
Figure 2-6: Simulations of the State Variables for DC-motor of Example 2-8
0 20 40 60 80 100
1.35
1.4
1.45
1.5
1.55
Case 1
Field Current (A)
Time (s)
Nonlinear
Linear
0 20 40 60 80 100
1
1.5
2
2.5
Case 2
Field Current (A)
Time (s)
Nonlinear
Linear
0 20 40 60 80 100
230
240
250
260
270
280
Case 1
Armature Current (A)
Time (s)
Nonlinear
Linear
0 20 40 60 80 100
50
100
150
200
250
300
350
400
450
Case 2
Armature Current (A)
Time (s)
Nonlinear
Linear
0 20 40 60 80 100
165
170
175
180
185
Case 1
Angular Speed (rad/s)
Time (s)
Nonlinear
Linear
0 20 40 60 80 100
80
100
120
140
160
180
200
220
240
Case 2
Angular Speed (rad/s)
Time (s)
Nonlinear
Linear
Figure 2.6. Simulations of the State Variables for DC-motor of Example 2.8
Table 2.3: Top level MATLAB code for Example 2.8
clear all
% Motor Parameters
Lf=50; %H
Rf=25; %ohms
La=2; %H
Ra=0.5; %ohms
Kv=0.91; %V/(A rad/s)
J=5; %Nm
B=0.3; %J/(rad/s)
%Inputs at Steady-State
Vf=36; %V
Va=360; %V

2.3. Linearization of Nonlinear Models 37
Figure 2-7: Simulations of the Output Variables for DC-motor of Example 2-8
0 20 40 60 80 100
80
85
90
95
100
105
Case 1
Power Electrical (kW)
Time (s)
Nonlinear
Linear
0 20 40 60 80 100
0
50
100
150
Case 2
Power Electrical (kW)
Time (s)
Nonlinear
Linear
0 20 40 60 80 100
-52
-51
-50
-49
-48
-47
Case 1
Power Mechanical (kW)
Time (s)
Nonlinear
Linear
0 20 40 60 80 100
-65
-60
-55
-50
-45
-40
-35
-30
-25
Case 2
Power Mechanical (kW)
Time (s)
Nonlinear
Linear
Figure 2.7. Simulations of the Output Variables for DC-motor of Example 2.8
TL=-280; %Nm=J
%Steady-state Calcs
if_ss= Vf/Rf;
linstate=inv([Ra Kv*if_ss;-Kv*if_ss B])*[Va;TL];
ia_ss=linstate(1); w_ss=linstate(2);
s_ss=[if_ss; ia_ss; w_ss]
q_ss=[if_ss*Vf+ia_ss*Va; w_ss*TL]
[t_nlin,s_nlin]=ode45('motor_mod_ode',[0 100],s_ss);
[t_lin,x_lin]=ode45('motor_mod_ode_lin',[0 100],s_ss-s_ss);
[NN,dumb]=size(t_nlin); q_nlin=zeros(NN,2);
for ii=1:NN
[dsdt,qout]=motor_mod_ode(t_nlin(ii),s_nlin(ii,:)'); q_nlin(ii,:)=qout';
end
[NN,dumb]=size(t_lin); z_lin=zeros(NN,2);
for ii=1:NN
[dxdt,zout]=motor_mod_ode_lin(t_lin(ii),x_lin(ii,:)'); z_lin(ii,:)=zout';
end
plot(t_nlin,s_nlin(:,1),'k',t_lin,x_lin(:,1)+s_ss(1),'k--');
title('Case 1','FontSize',14,'FontName','Times New Roman');
ylabel('Field Current (A)','FontSize',14,'FontName','Times New Roman');
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
legend('Nonlinear','Linear '); pause
plot(t_nlin,s_nlin(:,2),'k',t_lin,x_lin(:,2)+s_ss(2),'k--')
title('Case 1','FontSize',14,'FontName','Times New Roman');
ylabel('Armature Current (A)','FontSize',14,'FontName','Times New Roman');
38 Chapter 2. Modeling of Dynamic Systems
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
legend('Nonlinear','Linear '); pause
plot(t_nlin,s_nlin(:,3),'k',t_lin,x_lin(:,3)+s_ss(3),'k--')
title('Case 1','FontSize',14,'FontName','Times New Roman');
ylabel('Angular Speed (rad/s)','FontSize',14,'FontName','Times New Roman');
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
legend('Nonlinear','Linear '); pause
plot(t_nlin,q_nlin(:,1)/1000,'k',t_lin,(z_lin(:,1)+q_ss(1))/1000,'k--')
title('Case 1','FontSize',14,'FontName','Times New Roman');
ylabel('Power Electrical (kW)','FontSize',14,'FontName','Times New Roman');
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
legend('Nonlinear','Linear '); pause
plot(t_nlin,q_nlin(:,2)/1000,'k',t_lin,(z_lin(:,2)+q_ss(2))/1000,'k--')
title('Case 1','FontSize',14,'FontName','Times New Roman');
ylabel('Power Mechanical (kW)','FontSize',14,'FontName','Times New Roman');
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
legend('Nonlinear','Linear '); pause
Table 2.4: Nonlinear model for Example 2.8
function [dsdt,qout]= motor_mod_ode(t,s)
% Motor Parameters
Lf=50; %H
Rf=25; %ohms
La=2; %H
Ra=0.5; %ohms
Kv=0.91; %V/(A rad/s)
J=5; %Nm
B=0.3; %J/(rad/s)
%Inputs at Steady-State
m1=36; %V
m2=360; %V
p=-280; %Nm=J
Case=1;
if (Case == 1) %Case 1
if t > 10; m1=38; end
if t > 50; m1=34; end
else % %Case 2
if t > 10; m1=56; end
if t > 50; m1=26; end
end
ds1dt=( - Rf*s(1) + m1 )/Lf;
ds2dt=( - Ra*s(2) - Kv*s(3)*s(1) + m2 )/La;
ds3dt=( - B*s(3) + Kv*s(1)*s(2) + p )/J;
dsdt=[ds1dt;ds2dt;ds3dt];
qout=[s(1)*m1+s(2)*m2; s(3)*p];
Table 2.5: Linear model for Example 2.8
function [dxdt,zout]= motor_mod_ode_lin(t,x)
AA=[-0.5 0 0; ...
-80.8 -0.25 -0.655; ...
46.3 0.262 -0.06];
BB=[ 0.02 0; 0 0.5; 0 0];
GG=[ 0; 0; 0.2];
Dx=[36 360 0; 0 0 -280];
Du=[1.44 254; 0 0];
Dw=[177];
u=[0; 0];
w=0;
Case=1;
if (Case == 1) %Case 1
if t > 10; u=[2; 0]; end
if t > 50; u=[-2; 0]; end
2.4. Analytic Solution of a Linear State Space Model 39
else %Case 2
if t > 10; u=[20; 0]; end
if t > 50; u=[-10; 0]; end
end
dxdt=AA*x+ BB*u+GG*w;
zout=Dx*x+Du*u+Dw*w;
In summary, the linearization process results in the following linear process model:
x˙ = Ax + B u + Gw (2.68)
z = D
x x + Du u + Dw w (2.69)
y = C x + v (2.70)
Note that all of the system matrices (A, B, G, Dx, Du, Dw and C) will be constant.
The dimension of these system matrices will depend on the size of the vector signals.
Throughout the text the following notation will be used to indicate size of these vectors:
x (and s) ∼ nx × 1 (2.71)
u (and m) ∼ nu × 1 (2.72)
w (and p) ∼ nw × 1 (2.73)
z (and q) ∼ nz × 1 (2.74)
y (and θ) ∼ ny × 1 (2.75)
v (and n) ∼ nv × 1 (2.76)
Based on these definition the dimensions of the system matrices are as follows:
A ∼ n
x × nx (2.77)
B ∼ n
x × nu (2.78)
G ∼ n
x × nw (2.79)
D
x ∼ nz × nx (2.80)
D
u ∼ nz × nu (2.81)
D
w ∼ nz × nw (2.82)
C ∼ n
y × nx (2.83)
2.4 Analytic Solution of a Linear State Space Model
The primary benefit of the linear model approximation is the ability to apply analytic
methods in analyzing the process. The first example of these methods is in obtaining a
closed-form solution of a system of linear differential equations. Before giving the matrix
form of the solution, the following scalar case will illustrate the steps. Consider a first
order differential equation x˙ = ax + b u with initial condition x(to) = xo. Assuming a
and b are scalar constants, determine x(t) for any signal u(t). Begin by defining a new
signal x˘(t) such that x˘(t) = e−a(t−to)x(t). Then, substitution into the original differential
equation yields x˙ ˘(t) = e−a(t−to)b u, which can be solved by separation of variables to
yield:
x˘(t) − x˘(to) = ∫t t
o
e−a(τ−to)b u(τ)dτ (2.84)
40 Chapter 2. Modeling of Dynamic Systems
which is equivalent to e−a(t−to)x(t) − xo = ∫tt
o
e−a(τ−to)b u(τ)dτ and finally yields:
x(t) = ea(t−to)xo + ∫t t
o
ea(t−τ)b u(τ)dτ (2.85)
In the more general case of x˙ = Ax + B u + Gw where x, u, and w are vector functions
and A, B and G are constant matrices, the central challenge is to interpret the exponential
term when the scalar a is replaced by the matrix A.
Definition 2.3. Given a square matrix A, the exponential of that matrix is defined as
eAt = I + At + 1
2!
(At)2 + 1
3!
(At)3 + ···
Definition 2.4. If a matrix A has elements ai j at row i and column j , then the transpose of
A, denoted AT , has elements aj i at row i and column j .
Definition 2.5. If a matrix A has an inverse, denoted A−1, then A−1 is such that
AA−1 = A−1A = I
Corollary 2.1. The exponential of a matrix has the following properties (all of which are
easily verified from Definition 2.3).
d
d t
eAt = AeAt = eAt A eA(t1+t2) = eAt1 eAt2 (2.86)
eAt−1 = e−At and eAtT = eAT t (2.87)
Chapter 3 will provide a method for determining a closed form (non-series) expression for eAt. However, at this point it is sufficient to simply know that this term can be
evaluated for any finite value of t. In particular, the function ‘expm’ in MATLAB will
calculate this term with enough accuracy and speed for our purposes. Thus, if one follows the same steps as the scalar case, it is found that the solution to x˙ = Ax + B u + Gw
is:
x(t) = eA(t−to)xo + ∫t t
o
eA(t−τ)B u(τ)dτ + ∫t t
o
eA(t−τ)Gw(τ)dτ (2.88)
Then, the output signals are simply calculated as
z(t) = Dx x(t) + Du u(t) + Dw w(t) (2.89)
y(t) = C x(t) + v(t) (2.90)
where x(t) is from (2.88).
2.5. Discrete-time Models 41
2.5 Discrete-time Models
The discrete-time framework is one of convenience from a simulation standpoint and
will be of great utility from a practical implementation standpoint. Concerning dynamic
simulation, the recursive form of the discrete-time model will greatly simplify the coding effort - ode solvers can be replaced by simple loops. Concerning implementation,
all modern controllers are computer implemented and at some level must operate with
respect to sampled time intervals. As such, a discrete-time model is likely to be a more
accurate representation of the process under the influence of a time-sampled controller.
From a theoretical standpoint, nearly all results developed for the continuous-time case
will have a parallel relation in the discrete-time framework. Throughout the text, design formulas will be provided for both cases, however to illustrate the development of
these relations a single perspective will be employed, typically the one requiring the least
technical detail.
In general, a discrete-time model will be of the following recursive form:
sk+1 = fd(sk, mk, pk) (2.91)
qk = h(sk, mk, pk) (2.92)
θk = l(sk,nk) (2.93)
The term recursive is used to emphasize that the state at the next time-step, sk+1, can be
calculated if given the current state, sk, and the current input values, mk and pk.
Figure 2-8: Single-echelon inventory system of Example 2-9
Figure 2.8. Single-echelon inventory system of Example 2.9
Example 2.9. Consider the following model of product inventory at a retail location:
Ik
+1 = Ik + rk−kd − dk (2.94)
where Ik is the inventory at the end of day k, dk is the product sold during day k (denoted
as demand) and rk is the amount of product ordered at the end of day k (denoted as starts
or reorders). To capture delivery delay, rk−kd is the amount ordered kd days earlier and
arriving at the beginning of day k. This arrangement is depicted in Figure 2.8. Consider
the case of kd = 3. To put the system (2.94) into the form of (2.91) begin by defining state,
42 Chapter 2. Modeling of Dynamic Systems
manipulated and disturbance vectors as follows:
sk =

s
(1)
k
s
(2)
k
s
(3)
k
s
(4)
k

=

Ik
rk−3
rk−2
rk−1

mk = [rk] pk = [dk] (2.95)
then fd can be expressed as: fd(sk, mk, pk) = Ad sk + Bd mk + Gd pk where
A
d =

1 1 0 0
0 0 1 0
0 0 0 1
0 0 0 0

B
d =

0001

Gd =

−1
000

(2.96)
The inventory and reorders are both restricted to be positive and must be less than maximum values, Imax and rmax. As such, the performance output should be selected as
qk =

q
(1)
k
q
(2)
k

=

Ik rk

(2.97)
Then, the h can be expressed as: h(sk, mk, pk) = Dx sk + Du mk + Dw pk where
D
x =  1 0 0 0 0 0 0 0  Du =  0 1  Dw =  0 0  (2.98)
Given this performance equation the relations qmin ≤ q ≤ qmax can be used to define the
operating constraints, where qmin and qmax are defined as:
qmin =  0 0  qmax =  rImax max  (2.99)
The notion of deviation variables extends quite naturally to the discrete-time framework. In comparison to the continuous-time procedure, the main difference is with regard to the determination of the steady-state operating point (SSOP). Rather than the
relation of (2.28), the discrete-time definition of the SSOP is based on the following relation:
sSSOP = fd(sSSOP, mSSOP, pSSOP) (2.100)
Then, using definitions similar to those of Section 2.2 the following deviation variable
model can be constructed:
xk+1 = fd xk + sSSOP, uk + mSSOP,wk + pSSOP − sSSOP (2.101)
zk = h xk + sSSOP, uk + mSSOP,wk + pSSOP − qSSOP (2.102)
yk = l xk + sSSOP,vk + nSSOP − θSSOP (2.103)
2.5. Discrete-time Models 43
Example 2.10. Reconsider the inventory system of Example 2.9 and again assume kd =
3. Assume pSSOP is equal to the average product demand (denoted as dav). Then the
relations obtained by applying the steady-state equation (2.100) to (2.94) indicate that the
average reorder value must also be equal to dav, but no restriction is put on the average
inventory. As such, the SSOP can be defined as:
sSSOP =

s(1)SSOP
s(2)SSOP
s(3)SSOP
s(4)SSOP

=

I
amx
2
d
av
d
av
d
av

qSSOP =   q q((1 2))SSOP SSOP   =   dIamx 2av   (2.104)
mSSOP = [dav] pSSOP = [dav] (2.105)
where s(1)SSOP is arbitrarily selected to be half of the inventory maximum. Application
of this SSOP to equation (2.101) yields:
xk+1 = fd xk + sSSOP, uk + mSSOP,wk + pSSOP − sSSOP
= A
d xk + Bd uk + Gd wk + (Ad sSSOP + Bd mSSOP + Gd pSSOP − sSSOP) (2.106)
= A
d xk + Bd uk + Gd wk
where the last equality is due to equation (2.100). Similarly, application of (2.102) yields:
zk = h xk + sSSOP, uk + mSSOP,wk + pSSOP − qSSOP
= D
x xk + Du uk + Dw wk + (Dx sSSOP + Du mSSOP + Dw pSSOP − qSSOP)
(2.107)
= D
x xk + Du uk + Dw wk
Finally, it is found that
z
max = qmax − qSSOP =  rmax Imax −/d2av  (2.108)
z
min = qmin − qSSOP =  −−Imax dav/2  (2.109)
If the functions fd, h or l are nonlinear then a linearization procedure similar to that
of Section 2.3 can be applied to (2.91)-(2.93). The details of this linearization procedure
are left to the reader.
2.5.1 The Explicit Euler Method
While some discrete-time models exist purely within a discrete framework, such systems
are the exception. The more common scenario is to start with a continuous-time (or
differential equation) model and convert to a discrete-time model - the process of discretization.
Among the simplest of the conversion methods is the explicit Euler method. The
method begins with the continuous-time nonlinear system of Equation (2.1): ˙s = f (s, m,
44 Chapter 2. Modeling of Dynamic Systems
p). Next define a time sequence sk to approximate the function s(t). Specifically, sk =
s(∆t k), where k is the discrete-time (unit-less) time index. To recover “real” time, simply
multiply k by the sample interval ∆t. Similarly, define mk = m(∆t k) and pk = p(∆t k),
where it is assumed that m(t) and p(t) are both constant over the interval t = ∆t k to
t = ∆t (k + 1). Then, one can approximate the original process as:
sk+1 − sk
∆t
≈ ˙s = f (sk, mk, pk) (2.110)
Simple rearrange of this expression finally yields:
sk+1 = sk + ∆t f (sk, mk, pk) (2.111)
Given this recursion, the output equations are identical to the originals, but with the
continuous variables replaced by the new discrete variables: qk = h(sk, mk, pk) and
θk = h(sk, nk).
If the continuous-time model is linear and in deviation variable form, (2.68)-(2.70),
then application of the explicit Euler method results in the following discrete-time model:
xk+1 = Ad xk + Bd uk + Gd wk (2.112)
zk = Dx xk + Du uk + Dw wk (2.113)
yk = C xk + vk (2.114)
where
A
d = (I + ∆tA) Bd = ∆tB and Gd = ∆tG (2.115)
and D
x, Du, Dw and C are unaltered from (2.68)-(2.70).
Example 2.11. Reconsider to the surge tank example of Chapter 1. Recall that the original continuous-time process model for the surge tank is (V is volume and v is volumetric
flow):
V˙ = v
in − v (2.116)
Using the explicit Euler method, one can approximate the original process as:
Vk+1 −Vk
∆t
≈ V˙ = v(in)
k − vk (2.117)
which yields:
Vk+1 = Vk + ∆t vk(in) − ∆t vk (2.118)
Since (2.116) is a linear system, the formulas of (2.115) can be applied to arrive at:
Vk+1 = adVk + bd vk + gd vk(in) (2.119)
where ad = 1, bd = −∆t and gd = ∆t.
To illustrate how (2.119) can be used to simulate the surge tank process consider the
following scenario: Select ∆t = 0.1 and assume the tank volume is known to be 1 at time
sample k = 2 (t = 0.2), which defines V2 = 1. Additionally, assume the input sequences
2.5. Discrete-time Models 45
are expected to be as follows: v2 = 6 and vk = 0 for k > 2, v2(in) = 0, v3(in) = 10 and
v
(in)
k = 0 for k > 3. Then, application of (2.114) yields:
V2
= 1.0
V3
= 1.0 − 0.6 + 0.0 = 0.4
V4
= 0.4 − 0.0 + 1.0 = 1.4
V5
= 1.4 − 0.0 + 0.0 = 1.4
and so on.
2.5.2 The Sample and Hold Method
The downside of the explicit Euler method is that the state of the system is implicitly
assumed to be constant over the sample interval. While this may be a reasonable assumption for the input signals, especially the manipulated variable if under the influence
of a discrete-time controller, it is likely a poor assumption for the state variable. If the
continuous-time process of interest is linear, then one may employ the sample-and-hold
method. Since the sample-and-hold approach is based on the analytic solution of a linear
continuous-time process, derived in Section 2.4, it provides an exact representation of the
continuous-time solution under the assumption of the input signals being constant between the sample intervals. Although the method can be applied any linear system, the
following derivation is with respect to the deviation variable form of a linear continuoustime model, i.e., Equation (2.68). Similar to the Euler method, we begin with the define
discrete-time variables: xk = x(∆t k), uk = u(∆t k) and wk = w(∆t k), where the input
signals are again assumed to be held at constant during each sample interval. Now assume
we are given xk, uk and wk and would like to calculate xk+1 = x(∆t (k +1)). Application
of Equation (2.88) with t = ∆t (k + 1) and to = ∆t k yields:
x(∆t(k + 1)) = eA(∆t(k+1)−∆t k)x(∆t k)
+ ∫∆∆t kt(k+1) eA(∆t(k+1)−τ)B u(τ)dτ + ∫∆∆t kt(k+1) eA(∆t(k+1)−τ)Gw(τ)dτ (2.120)
Recall that the inputs are held constant over the interval of interest, u(τ) = uk and
w(τ) = wk for τ = ∆t k to τ = ∆t (k + 1). This indicates that these terms can be
moved outside the integration operators. Thus, one finds:
xk+1 = eA∆t xk + ∫∆∆t kt(k+1) eA(∆t(k+1)−τ)dτ!B uk
+ ∫∆∆t kt(k+1) eA(∆t(k+1)−τ)dτ!Gwk (2.121)
Next define τ′ = ∆t (k + 1) − τ and perform a change of variables in the integration
terms:
xk+1 = eA∆t xk + ∫0∆t eAτ′dτ′B uk + ∫0∆t eAτ′dτ′Gwk (2.122)
46 Chapter 2. Modeling of Dynamic Systems
Thus, the final form of the sample and hold method is
xk+1 = Ad xk + Bd uk + Gd wk (2.123)
where
A
d = eA∆t Bd = ∫0∆t eAτdτB Gd = ∫0∆t eAτdτG (2.124)
The important point to note is that for a given sample time ∆t, the matrices Ad, Bd,
and Gd will be constant and need only be calculated once prior to the discrete-time simulation. If the matrix A has an inverse, then the integrals of (2.124) can be performed
analytically:
B
d = ∫0∆t eAτdτB = A−1(eA∆t − I)B (2.125)
Gd = ∫0∆t eAτdτG = A−1(eA∆t − I)G (2.126)
An alternative approach that does not require A to be invertible is the following relation
eM∆t =

A
d Bd Gd
0 I 0
0 0 I

where M =

A B G
0 0 0
0 0 0

(2.127)
It is instructive to compare the sample-and-hold method with the explicit Euler method.
Recall Definition 2.3 (the exponential of a matrix) and note that the Euler approach, Ad =
(I + ∆tA), is simply the first two terms of the sample-and-hold approach. Thus, if ∆t is
sufficiently small, then one can expect the Euler method to be a good approximation of
sample-and-hold. Similarly, if ∆t is reasonably small then the integration terms in (2.125)
and (2.126) will be about equal to ∆t I, which is the approximation given by the Euler
method.
Example 2.12. Reconsider the mass-spring damper system of Example 2.4. At the end of
that example the continuous-time deviation variable model of the process was concluded
to be of the following form:
x˙ = Ax + B u + Gw (2.128)
If the parameters (M, b, k) are selected to be (1 k g, 2 N s/m, 3 N/m), then matrices A, B
and G will take the following values:
A=  −0 1 3 −2  B =  0 1  G =  0 1  (2.129)
Application of the explicit Euler method (with ∆t = 0.5 seconds) gives
A
d =  −1 0 1.5 0.5  Bd =  00.5  Gd =  00.5  (2.130)
Application of the sample-and-hold method (with ∆t = 0.5 seconds) gives
A
d =  −00.74 0 .84 0..18 28  Bd =  00..087 28  Gd =  00..087 28  (2.131)
2.5. Discrete-time Models 47
Application of the explicit Euler method (with ∆t = 0.2 seconds) gives
A
d =  −1 0 0.6 0..2 6  Bd =  00.2  Gd =  00.2  (2.132)
Application of the sample-and-hold method (with ∆t = 0.2 seconds) gives
A
d =  −00.95 0 .48 0..16 62  Bd =  00..017 16  Gd =  00..017 16  (2.133)
Clearly, (2.132) is a better approximation of (2.133) than (2.130) is of (2.131). Now consider a simulation of the mass-spring-damper process with the following inputs:
u(t) =  10 tt < ≥ 55 w(t) =  −02 tt<≥10 10 (2.134)
and an initial condition x(0) = [1 0]∗. The plots of Figure 2.9 show the simulation for
the Euler approximated case. While the sample rate of 0.2 seconds provides reasonable
accuracy, unacceptable degradation occurs if the sample rate is 0.5 seconds. In the sampleand-hold case, Figure 2.10, both sample rates provide an exact sampling of the continuoustime process.
Figure 2-9: Discrete-time simulation of mass-spring damper process using the explicit Euler method (left p
0 5 10 15
-1.5
-1
-0.5
0
0.5
1
Time (s)
State Variables (m or m/s)
Mass Position
Mass Velocity
0 5 10 15
-1.5
-1
-0.5
0
0.5
1
Time (s)
State Variables (m or m/s)
Mass Position
Mass Velocity
Figure 2.9. Discrete-time simulation of mass-spring damper process using the explicit Euler
method (left plot - ∆t = 0.5; right plot - ∆t = 0.2)
Figure 2-10: Discrete-time simulation of mass-spring damper process using the sample-and
0 5 10 15
-1.5
-1
-0.5
0
0.5
1
Time (s)
State Variables (m or m/s)
Mass Position
Mass Velocity
0 5 10 15
-1.5
-1
-0.5
0
0.5
1
Time (s)
State Variables (m or m/s)
Mass Position
Mass Velocity
Figure 2.10. Discrete-time simulation of mass-spring damper process using the sample-andhold method (left plot - ∆t = 0.5; right plot - ∆t = 0.2)
48 Chapter 2. Modeling of Dynamic Systems
Table 2.6: MATLAB code used in calculations for Example 2.12
clear
% Continuous-time Model of Mass-Spring-Damper
A=[0 1;-3 -2]; B=[0; 1]; G=[0; 1]; nx=2; nu=1; nw=1;
%Conversion to Discrete-time
dt=0.5; Euler=1;
if (Euler==1)
Ad=eye(nx)+dt*A; Bd=dt*B; Gd=dt*G;
else
M=[A B G; zeros(nu+nw,nx+nu+nw)];
M=expm(M*dt);
Ad=M(1:nx,1:nx);
Bd=M(1:nx,nx+1:nx+nu);
Gd=M(1:nx,nx+nu+1:nx+nu+nw);
end
%Simulate Forced Process
NNN=15/dt; ttt=zeros(1,NNN); xxx=zeros(2,NNN);
x0=[1; 0]; xxx(:,1)=x0;
for kk=1:NNN-1
ttt(kk+1)=dt*kk; uk=0; wk=0;
if (ttt(kk) >= 5) uk=1; end
if (ttt(kk) >= 10) wk=-2; end
xxx(:,kk+1)=Ad*xxx(:,kk)+Bd*uk+Gd*wk;
end
plot(ttt,xxx(1,:),'-k*',ttt,xxx(2,:),'-ko')
legend(' Mass Position',' Mass Velocity')
xlabel('Time (seconds)')
ylabel('State Variables (m or m/s)')
Figure 2-11: Comparison of continuous- and discrete-time simulations of the linearized DC-motor
0 20 40 60 80 100
1
1.5
2
2.5
Case 2
Field Current (A)
Time (s)
Discrete-time
Continuous-time
0 20 40 60 80 100
50
100
150
200
250
300
350
400
450
Case 2
Armature Current (A)
Time (s)
Discrete-time
Continuous-time
0 20 40 60 80 100
80
100
120
140
160
180
200
220
240
Case 2
Angular Speed (rad/s)
Time (s)
Discrete-time
Continuous-time
0 20 40 60 80 100
0
50
100
150
Case 2
Power Electrical (kW)
Time (s)
Discrete-time
Continuous-time
Figure 2.11. Comparison of continuous- and discrete-time simulations of the linearized DCmotor system using the sample and hold method, from Example 2.13
2.5. Discrete-time Models 49
Example 2.13. Reconsider the DC motor model of Example 2.8. If we discretize the linearized model using the sample-and-hold method and a sample time of 5 seconds, then a
repeat of the scenario of case 2 of part (iii) of the Example 2.8 results in the plots of Figure
2.11 (made with the code of Table 2.7). Notice that the sample and hold method mimics
the continuous-time solution of the linear system exactly, even though the sample time
is quite large. Of course, this is due to the fact that we are comparing with the linearized
simulation. If compared with the nonlinear simulation, the discrete-time result would
appear to be significantly degraded. If accuracy with the respect to the nonlinear simulation is desired then the implicit Euler method applied to the original nonlinear system
might be more appropriate, but has the downside of resulting in a nonlinear discrete-time
model. See section 2.5.3 for additional discussion
Table 2.7. Discrete-time simulation code for Example 2.13
clear all
s_ss=[1.44; 254; 178]; m_ss=[36; 360]; p_ss=-280; q_ss=[91200; 49700];
% Linear Continuous-time Model
AA=[-0.5 0 0; ...
-80.8 -0.25 -0.655; ...
46.3 0.262 -0.06];
BB=[ 0.02 0; 0 0.5; 0 0]; GG=[ 0; 0; 0.2];
Dx=[36 360 0; 0 0 -280]; Du=[1.44 254; 0 0]; Dw=[177];
% Discretization
dt=5; AAd=expm(AA*dt);
sum=zeros(3); Ndt=2000; ddt=dt/Ndt;
for ii=1:Ndt; sum=sum+expm(AA*ii*ddt); end
BBd=sum*BB*ddt; GGd=sum*GG*ddt;
% Disctete-time Simulation
NNN=round(100/dt); t_disc=zeros(1,NNN); x_disc=zeros(3,NNN); z_disc=zeros(2,NNN);
uu=[0; 0]; ww=0;
for ii=1:NNN-1
t_disc(ii+1)=ii*dt;
Case=2; t=t_disc(ii);
if (Case == 1) %Case 1
if t >= 10; uu=[2; 0]; end
if t >= 50; uu=[-2; 0]; end
else %Case 2
if t >= 10; uu=[20; 0]; end
if t >= 50; uu=[-10; 0]; end
end
x_disc(:,ii+1)=AAd*x_disc(:,ii)+BBd*uu+GGd*ww;
z_disc(:,ii)=Dx*x_disc(:,ii)+Du*uu+Dw*ww;
end
z_disc(:,NNN)=z_disc(:,NNN-1);
%Continuous-time Simulation
[t_lin,x_lin]=ode45('motor_mod_ode_lin',[0 100],s_ss-s_ss);
[NN,dumb]=size(t_lin); z_lin=zeros(NN,2);
for ii=1:NN
[dxdt,zout]=motor_mod_ode_lin(t_lin(ii),x_lin(ii,:)'); z_lin(ii,:)=zout';
end
%Plots
plot(t_disc,x_disc(1,:)+s_ss(1),'k*:',t_lin,x_lin(:,1)+s_ss(1),'k');
title('Case 2','FontSize',14,'FontName','Times New Roman');
ylabel('Field Current (A)','FontSize',14,'FontName','Times New Roman');
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
legend('Discrete-time','Continuous-time'); pause
plot(t_disc,x_disc(2,:)+s_ss(2),'k*:',t_lin,x_lin(:,2)+s_ss(2),'k')
title('Case 2','FontSize',14,'FontName','Times New Roman');
ylabel('Armature Current (A)','FontSize',14,'FontName','Times New Roman');
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
50 Chapter 2. Modeling of Dynamic Systems
legend('Discrete-time','Continuous-time'); pause
plot(t_disc,x_disc(3,:)+s_ss(3),'k*:',t_lin,x_lin(:,3)+s_ss(3),'k')
title('Case 2','FontSize',14,'FontName','Times New Roman');
ylabel('Angular Speed (rad/s)','FontSize',14,'FontName','Times New Roman');
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
legend('Discrete-time','Continuous-time'); pause
plot(t_disc,(z_disc(1,:)+q_ss(1))/1000,'k*:',t_lin,...
(z_lin(:,1)+q_ss(1))/1000,'k')
title('Case 2','FontSize',14,'FontName','Times New Roman');
ylabel('Power Electrical (kW)','FontSize',14,'FontName','Times New Roman');
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
legend('Discrete-time','Continuous-time'); pause
plot(t_disc,(z_disc(2,:)+q_ss(2))/1000,'k*:',t_lin,...
(z_lin(:,2)+q_ss(2))/1000,'k')
title('Case 2','FontSize',14,'FontName','Times New Roman');
ylabel('Power Mechanical (kW)','FontSize',14,'FontName','Times New Roman');
xlabel('Time (s)','FontSize',14,'FontName','Times New Roman')
legend('Discrete-time','Continuous-time'); pause
It is interesting to note both of the discussed discrete-time conversion methods preserve the set of steady-state operating conditions. That is, if a triple (sSSOP, mSSOP,
pSSOP) satisfies relation (2.28), then it will also satisfy relation (2.100). For the explicit
Euler method it is clear that the relation sSSOP = sSSOP + ∆t f (sSSOP, mSSOP, pSSOP)
is equivalent to 0 = f (sSSOP, mSSOP, pSSOP). In the sample and hold case, it is a bit
more challenging to illustrate equivalence. To simplify the analysis assume the inverse of
A exists, so that the expressions of (2.125) and (2.126) can be applied. Starting with the
discrete-time steady-state relation:
sSSOP = Ad sSSOP + Bd mSSOP + Gd pSSOP
(2.135)
= eA∆t sSSOP + A−1(eA∆t − I)B mSSOP + A−1(eA∆t − I)G pSSOP
Then, Definition 2.3, indicates that AeAt = eAtA, which can be used to rearranged (2.135)
into the following form:
0 = A−1 eA∆t − IAsSSOP + BmSSOP + G pSSOP (2.136)
Thus, any triple (sSSOP, mSSOP, pSSOP) that satisfies 0 = AsSSOP + BmSSOP + G pSSOP
will also satisfy (2.136).
This equivalence result will be quite useful in the later chapters of the book, when
the steady-state relation is incorporated into the design of the feedback controller. In particular, since the continuous-time steady state relation is likely simpler, owing to greater
sparsity, it will be beneficial to use it verses the discrete-time relation of (2.100).
2.6 Case Study Processes
In this section, we introduce a number of process models that will used throughout the
text as exercises. It is suggested that the reader select a few of these case study processes
and work through the associated exercises given in each chapter. In addition to being a
bit more involved than the regular exercise problems, use of the same case study system
within multiple chapters will serve to connect the concepts of each chapter.
2.6.1 Furnace Reactor Process
Consider the furnace reactor process of Figure 2.12. The process state, manipulated and
disturbance vectors are: s = [TF TR CO
2
C
CO]∗, m = [Ff eed Ff uel Pv]∗, p = [T0].
2.6. Case Study Processes 51
Figure 2.12. Process schematic of furnace reactor process
Based on step tests (around the operating point snom = [375K 500K 4% 100p pm]∗,
mnom = [10000 bbl/day 10 bbl/day 0.1%]∗, pnom = [300K]) the following dynamic
model has been determined:
A=

−8000 0 0 0
2000 −1500 0 0
0 0 −5000 0
0 0 0 −5000

B =

−75 75000 0
−25 0 0
0 −8500 8.5 × 105
0 0 −5 × 107

G =

10000
000

Note that the unit of time for this model is days, but the sample time of the controller
is expected to be on the order of seconds. Limitations on the state and manipulated
variables are as follows:
350K ≤ TF ≤ 400K
495K ≤ TR ≤ 505K
4% ≤ CO2 ≤ 6%
40p pm ≤ CCO ≤ 130p pm
9500 bbl/day ≤ FF eed ≤ 10100 bbl/day
7 bbl/day ≤ FF uel ≤ 12 bbl/day
0.09% ≤ Pv ≤ 0.11%
The economic objective function (to be maximized) is g = 10Ff eed − 30Ff uel − 0.1CCO.
52 Chapter 2. Modeling of Dynamic Systems
3
M2
k2
M1
k1 b1 Fm
M0
k0 b0
Fd
r0
r1
r2
Figure A-2: Process schematic of Three Mass System
)g )g
q
03333 m/s2" a " % .0 03333
Figure 2.13. Process schematic of a system of three masses
2.6.2 System of Three Masses
Consider the three mass system of Figure 2.13, described by the following equations:
d r
0
d t
= v
0
d r
1
d t
= v
1
d r
2
d t
= v
2
M0
d v
0
d t
= −b
0(v0 − v1) − k0(r0 − r1 − ∆¯r0) − M0 g0
M
1
d v
1
d t
= b
0(v0 − v1) − b1(v1 − v2) + k0(r0 − r1 − ∆¯r0) − k1(r1 − r2 − ∆¯r1)
− M
1 g0 + Fm
M2
d v
2
d t
= b
1(v1 − v2) + k1(r1 − r2 − ∆¯r1) − k2(r2 − ∆¯r2) − M2 g0 − Fm + Fd
The parameters of the system are
M0
= 75 k g b0 = 100 k g/s k0 = 10000 k g/s2 ∆¯r0 = 0.2 m g0 = 9.8 m/s2
M
1 = 500 k g b1 = 10000 k g/s k1 = 50000 k g/s2 ∆¯r1 = 0.28 m
M2
= 10 k g k2 = 5 × 105 k g/s2 ∆¯r2 = 0.03 m
The manipulated variable is Fm and the sample time of the controller is expected to be 0.1
seconds. The disturbance, Fd, has a nominal value of (M0 + M1 + M2)g0. The limitations
of the process are as follows: qmin ≤ q ≤ qmax where
qmin =

−5 m/s2
0.1 m
−0.45 m/s
−1 m/s2
0.075 m
−4.5 kN

q =

a
0
r
1
v
1
a
1
r
1 − r2
Fm

qmax =

5 m/s2
0.2 m
0.45 m/s
1 m/s2
0.3 m
0 kN

The acceleration terms are defined as:
a
0 = −b0(v0 − v1)/M0 − k0(r0 − r1 − ∆¯r0)/M0 − g0
a
1 = b0(v0 − v1)/M1 − b1(v1 − v2)/M1
+ k0(r0 − r1 − ∆¯r0)/M1 − k1(r1 − r2 − ∆¯r1)/M1 − g0 + Fm/M1
The economic objective function (to be minimized) is g = r1.
2.6. Case Study Processes 53
2.6.3 Endothermic Reactor
Consider the following model of an endothermic CSTR with preheating heat exchangers.
ρCpV1
dT
1
d t
= v
0ρCp(T0 − T1) + UA(T4 − T1)
V3
dC
A
d t
= v
0(CA0 − CA) − k0e−E/RT3CAV3
V3
dC
B
d t
= −v
0CB + k0e−E/RT3CAV3
ρCpV3
dT
3
d t
= v
0ρCp(T2 − T3) + (−∆H)k0e−E/RT3CAV3
ρCpV4
dT
4
d t
= v
0ρCp(T3 − T4) − UA(T4 − T1)
T2
= T
1 + Q/v0ρCp
The manipulated variable is the amount of heat added to stream 1, Q, and the disturbance is the inlet concentration, CA0. The sample time of the controller is expected
to be 0.1 hour. The process parameters are as following: V1 = V3 = V4 = 4 m3,
v
0 = 10 m3/h r, k0 = 1.5×103 /h r, E = 2×103 kcal/kmol e, R = 1.987 kcal/kmol eK,
ρ = 1000 k g/m3, Cp = 1 kcal/k gK, T0 = 298 K, (−∆H) = −2 × 105 kcal/kmol e,
U = 550 kcal/h r m2K and A = 50 m2. The steady-state operating point can be determined from QSSOP = 2.845 × 106 kcal/h r and CASSOP 0 = 1 kmol e/m3. Limitations on the state and manipulated variables are as follows: 350 K ≤ T3 ≤ 450 K and
2 × 106 kcal/h r ≤ Q ≤ 2.9 × 106 kcal/h r. The economic objective function (to be
maximized) is g = 100v0CB − 5Q.
2.6.4 Manufacturing Process
Storage
Unit 0
(S0)
Delivery Delay of 3 Weeks
Storage
Unit 1
(S1)
Storage
Unit 2
(S2)
Raw Material Orders (m0)
Processing
Unit
Consumer Demand
for Product 1 (d1)
Consumer Demand
for Product 2 (d2)
Production Rate
of Product 1
(m1)
Production
Rate of
Product 2
(m2)
Purchase of Product 1
from Outside Vendor
(m3)
Purchase of Product 2
from Outside Vendor
(m4)
Figure 2.14. Multi-echelon item manufacturing process.
Consider the multi-echelon manufacturing system of Figure 2.14. The process is inherently discrete-time with a sample period of 1 week. The disturbances to the process
are the two consumer demand signals, d1 and d2, which must be met at all times, each
with a mean of 200 items per week and 100 items per week, respectively. The manipulated
54 Chapter 2. Modeling of Dynamic Systems
variables are the raw material orders (m0 with units of items per week), the production
rates of products 1 and 2 (m1 and m2 with units of items per week), and purchases of
products 1 and 2 from outside vendors (m3 and m4 with units of items per week). The
processing time of product 2 is twice that of product 1, which is reflected in the production limitation constraints of the processing unit: m1+2m2 ≤ 450 items per week. Other
constraints on the manipulated variables are: 0 ≤ m0 ≤ 500, 0 ≤ m1 ≤ 450, 0 ≤ m2 ≤ 225,
0 ≤ m3 ≤ 200, 0 ≤ m4 ≤ 200. The three storage units are also constrained: 0 ≤ S0 ≤ 150
items, 0 ≤ S1 ≤ 500 items and 0 ≤ S2 ≤ 25 items. If there is insufficient inventory of
product 1 or 2 at the beginning of the week, then a purchase of product 1 or 2 from
an outside vendor must occur. Clearly, one would like to avoid such scenarios, as the
economic penalty of purchasing from a competitor is large.
If the state vector is defined as sk = [S0,k r3,k r2,k r1,k S1,k S2,k]∗ , the manipulated variable vector as mk = [m0,k m1,k m2,k m3,k m4,k]∗ and the disturbance as pk = [d1,k d2,k]∗
then the following system matrices could be used to model the process.
A
d =

1 1 0 0 0 0
0 0 1 0 0 0
0 0 0 1 0 0
0 0 0 0 0 0
0 0 0 0 1 0
0 0 0 0 0 1

B
d =

0 −1 −1 0 0
0 0 0 0 0
0 0 0 0 0
1 0 0 0 0
0 1 0 1 0
0 0 1 0 1

Gd =

0 0
0 0
0 0
0 0
−1 0
0 −1

The economic objective function (to be minimized) is g = 50m3 + 100m4 + 0.5S0 +
1.0S
1 + 1.5S2.
2.6.5 Building HVAC System
Volume of Air
(the Room) Air
Processing
Unit
Contaminant
Source: Sc
Solid
Material
F
rcy , Troom , Croom
F
rcy , Tcool , Croom
Ffresh , Tcool , Cfresh
Ffresh , Troom , Croom
Ffresh , Toutside , Cfresh
Ffresh , Troom , Croom
Troom , Croom
Tsolid
Energy Usage
Heat
Leakage
(Toutside
measured)
(Cfresh = 0)
Control Variables:
Troom and Croom
Manipulated Variables:
F
rcy and Ffresh
Disturbances:
Toutside and Sc
(Tcool = 20oC)
Figure A-7: Schematic of a single room HVAC system.
26 400
Figure 2.15. Schematic of a single room HVAC system.
Consider a single volume of perfectly mixed indoor air, along with a volume of solid
material (see Figure 2.16). The disturbances acting on the room are assumed to be the
temperature of the outside air, Tout si d e, (mean of 29◦C) as well as the rate of contaminant
2.6. Case Study Processes 55
generation, Sc (mean of 0.25 p pm/s). The control variables are temperature and contaminant concentration, each should satisfy: 22◦C ≤ Tr oom ≤ 26◦C and Cr oom ≤ 400 p pm.
The sample time of the controller is expected to be 15 minutes. The manipulated variables are the volumetric flows through the air processing unit; Fr c y being the flow of
air sourced from the room (recycled air) and Ff r es h being air from the outside (fresh
air). Each manipulated variable should satisfy for all time: 0 ≤ Fr c y ≤ 2 m3/s and
0 ≤ Ff r es h ≤ 0.3 m3/s. From an energy standpoint, the intake of fresh air increases energy use, due to the larger cooling duty required to arrive at Tcool from Tout si d e.
However, from an indoor air quality standpoint, fresh air is the only means of reducing
contaminant levels. Thus, the basic challenge is to identify the minimum flow of fresh air
required to keep the contaminant level below the requirement and then use the recycled
air for temperature regulation. Material and energy balances around the room yield the
following nonlinear dynamic model of the process:
˙ T
r oom =
(Fr c y + Ff r es h)
V
r oom
(Tcool − Tr oom)
+
UA
r oom
V
r oomρCp
(Tout si d e − Tr oom) +
UAs ol i d
V
r oomρCp
(Ts ol i d − Tr oom)
˙ T
s ol i d =
UAs ol i d
Vs ol i d(ρCp)s ol i d
(Tr oom − Ts ol i d)
˙ C
r oom =
F
f r es h
V
r oom
(Cf r es h − Cr oom) + Sc
whereV
r oom = 60 m3, Vs ol i d = 10 m3, Ar oom = 200 m2, As ol i d = 5 m2, U = 5.69 W /m2K,
ρ = 40 mol e/m3, Cp = 29 J /mol eK, (ρCp)s ol i d = 2000 J /m3K, Tcool = 20◦C, Cf r es h =
0 p pm. The cost of running the HVAC system is defined as: g = ρCp[Fr c y(25−Tcool)+
F
f r es h(29 − Tcool)].
2.6.6 Vapor Product Reactor
Consider a jacket cooled CSTR with vapour product.
V˙ = v
0 − v
˙CA
=
v
0 V
C
Ain −
v V
CA
− k
0e−E/RT CA
˙CB
= −
v V
CB
+ k0e−E/RT CA
T˙ = v0
V
T
in −
v V
T +
(−∆H)
ρCp
k
0e−E/RT CA − UA(T − Tj)
V ρCp
˙Tj
=
vj
Vj
(Tj in − Tj) +
UA(T − Tj)
Vj
ρj Cp j
P˙ = R1T
64 − V
(V k0e−E/RT CA − Fg)
The manipulated variables are the volumetric flow of liquid out of the reactor, v, the volumetric flow through the cooling jacket, vj , and the molar flow of gas out of the reactor,
56 Chapter 2. Modeling of Dynamic Systems
Figure 2.16. Schematic of a vapor product reactor [103].
Fg
. The nominal values of v, vj and Fg are 40 f t 3/h r, 56.6 f t 3/h r and 10.6 l b mol e/h r,
respectively. The sample time of the controller is expected to be 2 minutes. Limitations
on the state and manipulated variables are as follows:
40 ≤ V ≤ 55 f t 3
0.05 ≤ CA ≤ 0.35 l b mol e/ f t 3
560 ≤ T ≤ 620 ◦R
560 ≤ Tj ≤ 650 ◦R
445 ≤ P ≤ 475 l b f / f t 2
0 ≤ v ≤ 50 f t 3/h r
0 ≤ vj ≤ 100 f t3/h r
0 ≤ F
g ≤ 16 l b mol e/h r
The process disturbances are volumetric flow into the reactor, v0, and inlet concentration
of species A, CAin. The v0 disturbance has a mean value of 40 f t 3/h r and the CAin
disturbances has a mean of 0.5 l b mol e/ f t 3. The profit of the process is defined as:
g = 0.375vCB − 0.015vj − 0.00225F g. The parameters of the systems are
Vj
= 3.85 f t 3 Tin = 530◦R Tj in = 530◦R E = 2.99 × 104 b t u/l b mol e
R = 1.99 b t u/l b mol e ◦R R1 = 10.73 f t3 psi/l b mol e ◦R
k
0 = 7.08 × 1010 /h r −∆H = 3 × 104 b t u/l b mol e
ρCp = 37.5 b t u/ f t 3 ◦R ρj Cp j = 62.3 b t u/ f t3 ◦R UA= 2.25×104 b t u/h r ◦R
2.6.7 Two CSTR Process
Consider two non-isothermal CSTRs with cooling jackets in series with the following
reactions: A
(l) → B(l) and B(l) → C(l), where B is the product and C is an undesired side
product. Using material and energy balances around each of the CSTRs, along with an
arithmetic mean cooling water temperature approximation, yields the following differen
2.6. Case Study Processes 57
tial equations.
˙CA
,1 =
F1 V
(CAf − CA,1) − CA,1ko,1e−E1/RT1
˙CB
,1 = −
F1 V
CB
,1 + CA,1ko,1e−E1/RT1 − CB,1ko,2e−E2/RT1
˙T1
=
F1 V
(Tf − T1) −
(∆HR,1)
ρCp
CA
,1ko,1e−E1/RT1
−
(∆HR,2)
ρCp
CB
,1ko,2e−E2/RT1 − 2Uc,1Fc,1(T1 − Tc,1,in)
V (2Fc,1 + Uc,1)
˙CA
,2 =
F1 V
CA
,1 +
Fm V
Cm
−
(F1 + Fm)
V
CA
,2 − CA,2ko,1e−E1/RT2
˙CB
,2 =
F1 V
CB
,1 −
(F1 + Fm)
V
CB
,2 + CA,2ko,1e−E1/RT2 − CB,2ko,2e−E2/RT2
˙T2
=
F1 V
T1
+
Fm V
Tm
−
(F1 + Fm)
V
T2
−
(∆HR,1)
ρCp
CA
,2ko,1e−E1/RT2
−
(∆HR,2)
ρCp
CB
,2ko,2e−E2/RT2 − 2Uc,2Fc,2(T2 − Tc,2,in)
V (2Fc,2 + Uc,2)
Tc
,i,out =
2U
c,i(Ti − Tc,i,in)
(2Fc,i + Uc,i)
+ T
c,i,in, i = 1,2
The nominal values and parameters of the systems are F1 = 0.283 m3/s Fm = 0.229 m3/s
Fc
,1 = 0.7 m3/s Fc,2 = 0.7 m3/s E1/R = 6000 K E2/R = 4500 K V = 5 m3
k
o,1 = 2.7×108 s−1 ko,2 = 160 s−1 ∆HR,1/(Cpρ) = −5 m3K/kmol ∆HR,2/(Cpρ) =
−5 m3K/kmol Uc,1 = 0.35 m3/s Uc,2 = 0.35 m3/s Tc,1,in = 300 K Tc,2,in = 275 K
The manipulated variables are the volumetric flow rate and the makeup volumetric flow
rate (F1 and Fm) and the volumetric flow rate going to each cooling jacket (Fc,1 and Fc,2).
Process limitations include:
300K ≤ T1 ≤ 350K
275K ≤ T2 ≤ 350K
0 m3/s ≤ F1 + Fm ≤ 0.8 m3/s
300K ≤ Tc,1,out ≤ 330K
275K ≤ Tc,2,out ≤ 300K
0.05 m3/s ≤ F1 ≤ 0.8 m3/s
0.05 m3/s ≤ Fm ≤ 0.8 m3/s
0 kmol/m3 ≤ CA,2 ≤ 0.3 kmol/m3
The disturbance variables are the inlet temperatures to the CSTRs (Tf and Tm, each with
a nominal value of 300K) and the concentration of A being feed (CAf and Cm, each with
a nominal value of 20 kmol/m3). The profit of the process is defined by the following
expression, given in $/hr:
Φ = 10(F1 + Fm)CB2 − 0.01qcool,1 − qcool,2 − 0.1F1 − 0.1Fm
where qcool,1 = 2Uc,12FFc,1(T1−Tc,1,in)
c,1+Uc,1 and qcool,2 = 2Uc,22FFc,c2,(2T+2U−cT,2c,2,in).
58 Chapter 2. Modeling of Dynamic Systems
2.7 Chapter Summary
In the remainder of the text, the linear state-space model in deviation variable form will
play a central role and will serve as the starting point of the controller design methods
to be developed. The general procedure for developing such a model is to begin with
a continuous-time nonlinear state-space model, developed from the physical characteristics of the process. Based on the steady-state version of the model, one must identify
an appropriate SSOP - possibly based on the performance and/or economic objectives
of the process. Then, the nonlinear model can be linearized around this SSOP. As we
have seen the linearization procedure will also serve to re-cast the model into deviation
variable form. These deviation variables will serve to quantify how much the process
deviates from the SSOP and will be central to the construction of a feedback controller.
Finally, one has the option of converting to the discrete-time framework. The advantage
of the discrete-time model is that it more appropriately captures the response of a system
under the influence of a time sampled controller. Clearly, each step of the above model
development procedure will introduce a level of error. The point, however, is not that
the resulting model is exceedingly accurate, but that the linear model will provide access
to a variety of powerful design tools. Then, once a controller has been designed (using
the linear model), the final step in the design procedure is to test that controller on the
continuous-time nonlinear model.
It is highlighted that material similar to that given in this chapter can be found in
numerous textbooks (see for example Kwakernaak & Sivan, [104]; Stengle, [105]; Burl,
[106]), including those intended for an undergraduate course on process control (see for
example Stephanopoulos, [107]; Ogunnaike & Ray, [108]; Bequette, [109]; Seborg et al.,
[1]; Romagnoli & Palazoglu, [110]).
Exercises
2.1. Consider the following model of a surge tank for which we plan to implement a
liquid level control system:
A
d h
d t
= vin − vout
v
out = pv˘ρh
where A = 1 m2 is the cross-sectional area of the tank, h is the liquid level, vout is
the volumetric flow rate out of the tank, ρ = 1.2 g/c m3 is the fluid density and
pv is proportional to the position of the valve on the exit stream.
(i) Develop a 1-dimensional nonlinear state space model of the system and identify the process state.
(ii) If vin is considered the disturbance input and pv is the manipulated variable,
calculate the linearized model of the process. Assume nominal values of
v
s s o p
in = 1 m3/min and pvs s o p = 0.01 m4/(min k g1/2).
2.2. Consider the following first order differential equation x˙ = ax+b u where a = −2,
b = 10, u(t) = e−2t and the initial condition is x(0) = 5.
(i) Determine the analytic solution of this differential equation by identifying
the expression x(t).
(ii) Calculate x(t) at t = 0.5.
Exercises 59
(iii) Using the explicit Euler method with a sample time of 0.25, determine the
discrete-time model xk+1 = ad xk + bd uk.
(iv) Calculate xk for the time corresponding to t = 0.5.
(v) Comment on the accuracy (or lack thereof) of the discrete-time model and
why this is the case.
(vi) Repeat parts (iii), (iv) and (v) with a sample time of 0.1
2.3. Repeat Exercise 2.2 , but this time use the sample and hold method to arrive at a
discrete-time model.
2.4. Consider the differential equation m¨r = F , where r is the position of a particle
with mass m and F is an external force applied to the particle.
(i) Convert the above differential equation model into a state space form: x˙ =
Ax+B u and z = D
x x+Du u. Assume the input signal, u, is the applied force
and the output, z, is the particle position. Specifically, you should indicate
the matrix values (A, B, Dx and Du) that should be used. (Hint: You may
find it helpful to consider of the system m¨r + b ˙r + k r = F and set b and k
equal to zero.)
(ii) Convert the continuous-time state-space model of part (i) into a discretetime model, using the explicit Euler method. Specifically, find Ad and Bd
of the model xk+1 = Ad xk + Bd uk. Assume the mass, m, equals 1 and the
sample time, ∆t, is 1. (Hint: don’t forget about the output equation.)
(iii) Assume the particle is initially 25 units away from the origin and is at rest.
Determine the initial condition, x0, that should be used.
2.5. Consider the following nt h order differential equation (u the input and z the output):
d n z
d t n
+ a
n−1
d n−1z
d t n−1 + ··· + a1
d z
d t
+ a0z = b u
Verify that a state space representation of this process can be obtained as:
x˙ = Ax + B u z = D
x x + Du u
where
A=

0 1 0 0 ··· 0
0 0 1 0 ··· 0
0 0 0 1 ··· 0
...
...
...
.
.
.
...
0 0 0
.
.
. 1
−a
0 −a1 −a2 −a3 ··· −an−1

B =

000...0b

D
x = [1 0 0 ··· 0] Du = [0]
60 Chapter 2. Modeling of Dynamic Systems
2.6. Using Definition 2.3 verify the identities
(i) d t d eAt = AeAt = eAt A
(ii) eA(t1+t2) = eAt1 eAt2
(iii) eAt−1 = e−At
(iv) eAt∗ = eA∗t
2.7. Consider the pair of surge tanks depicted in Figure 2.17. Assume the first objective is to deliver a constant exit flow, v2, to the downstream unit, in the face
of upstream variations at v0. Similar to the tank example of Chapter 1, it is reasonable to assume that v
1 = v
(s p)
1 and v2 = v2(s p) for all time and that v1 and v2
can be selected as manipulated variables (through their relation to v1(s p) and v2(s p).
For each tank the volume of liquid should not exceed the total tank volume, and
neither tank should be allowed to run dry. A volume balance around each tank
yields:
˙V1
= v
0 − v1 V˙2 = v1 − v2
(i) If the nominal inlet flow, v0SSOP, is 30 m3/min, determine appropriate values for the other variables associated with the SSOP (V1SSOP, V2SSOP, v1SSOP,
vSSOP
2 ). It is also noted that the maximum volume allowed in each tank is
20 m3.
(ii) Assuming the performance output is q = [V1 V2 v1 v2]∗, define the vector
signals and matrices associated with the linear model of Equations (2.34)-
(2.35).
(iii) For the linear system of part (ii), show that the explicit Euler and sampleand-hold methods generate the same discrete-time model.
Figure 2-P1: Surge tanks for Problem 2-7
V2 FT
FC
0
V1
1
(sp)
FT
FC
2
(sp)
1 2
Figure 2.17. Surge tanks for Exercise 2.7
2.8. Consider the three mass system of Figure 2.18, described by the following set of
Exercises 61
M1
M2
M3
u1 u2
w
Figure 2-P2: Three mass system for Problem 2-8
Figure 2.18. Three mass system for Exercise 2.8
differential equations.
M
1
d2r
1
d t2 + b1 d r d t1 − d r d t2  + k1(r1 − r2) = u1
M2
d2r
2
d t2 − b1 d r d t1 − d r d t2  − k1(r1 − r2)
+ b2 d r d t2 − d r d t3  + k2(r2 − r3) = u2 − u1
M3
d2r
3
d t2 − b2 d r d t2 − d r d t3  − k2(r2 − r3) = w − u2
with parameters M1 = 1, M2 = 100, M3 = 10, b1 = 0.05, b2 = 3, k1 = 0.1 and
k
2 = 20.
(i) Verify that a state space representation of this process can be obtained as:
x˙ = Ax + B u + Gw z = D
x x + Du u + Dww
where
A=

0 0 0 1 0 0
0 0 0 0 1 0
0 0 0 0 0 1
−0.1 0.1 0 −0.05 0.05 0
0.001 −0.201 0.2 0.0005 −0.0305 0.03
0 2 −2 0 0.3 −0.3

B =

0 0
0 0
0 0
1 0
−0.01 0.01
0 −0.1

G =

00000
0.1

62 Chapter 2. Modeling of Dynamic Systems
D
x =

1 0 0 0 0 0
0 1 0 0 0 0
0 0 1 0 0 0
0 0 0 0 0 0
0 0 0 0 0 0

D
u =

0 0
0 0
0 0
1 0
0 1

D
w =

00000

Identify the variables contained in the state and performance output vectors.
(ii) Using the sample-and-hold method (with a sample period ∆t = 0.5), determine the discrete-time model.
(iii) Simulate the system using both the continuous and the discrete-time models.
Assume u
1, u2 and w equal zero for all time and the system initial condition
is x(0) = [1 0.1 0.5 0 0 0]∗.
(iv) Simulate the system using the discrete-time model. Assume x(0) = 0, w(t) =
sin(10t) and u1 and u2 equal zero for all time.
2.9. Consider the following model of an exothermic CSTR with cooling jacket.
Vr
dC
A
d t
= v
0(CA0 − CA) − k0e−E/RT CAVr
ρCpVr
dT
d t
= ρCpv0(T0 − T ) + (−∆H)k0e−E/RT CAVr − UA(T − Tj)
ρjCp jVj
dT
j
d t
= ρjCp j vj(Tj0 − Tj) + UA(T − Tj)
with the following parameters: Vr = 1 m3, Vj = 0.08 m3, v0 = 3 m3/h r, k0 =
3 × 106 /h r, E = 2 × 104 kcal/kmol, R = 1.987 kcal/kmolK, ρ = ρj =
1000 k g/m3, Cp = Cp j = 0.2 kcal/k gK, Tj0 = 300 K, (−∆H) = 5 × 105 kcal/
kmol, U = 800 kcal/h r m2K and A = 6 m2. The manipulated variable will
vj and two disturbances are expected: CA0 and Tj0. The nominal conditions
of the inputs are as follows: vjSSOP = 120 m3/h r, CASSOP 0 = 4 kmol/m3 and
T SSOP
j0 = 300K.
(i) Determine the three steady state operating points of the reactor. (Hint: solve
the first and third equations for CASSOP and TjSSOP respectively. After substituting these into the second equation, find the three zeros of the nonlinear
equation graphically.)
(ii) Using an ode solver in MATLAB, simulate the nonlinear system, using the
initial condition:
s(0) =

CA
(0)
T (0)
Tj
(0)

=

2.8 kmol e/m3
684 K
364 K

Assume v
j = vjSSOP, CA0 = CASSOP 0 and Tj0 = TjSSOP 0 for all time and simulate for a period of 0.5 hours. Repeat the simulation using the initial condition
s(0) =

CA
(0)
T (0)
Tj
(0)

=

2.8 kmol e/m3
687 K
364 K

Exercises 63
Write a paragraph explaining the simulation results. Do they have any relation to the results of (i)? Can these be used to say something about the
stability of the three steady-states.
(iii) Add a simple proportional controller to the process. Use reactor temperature as the control variable (CV) and jacket flow rate as the manipulated variable. That is, add to the simulation: vj(t) = vjSSOP + Kc(T SSOP −
T (t)) where T SSOP = 685.5K and Kc is the controller gain (should be ∼
−40 m3/h rK). (Assume CA0 = CASSOP 0 and Tj0 = TjSSOP 0 for all time.) Simulate this closed-loop system using a variety of initial conditions, say for
example x(0) = [2.0 690 364]∗. Write a paragraph analyzing the results.
(Hint: change the simulation time to about 0.05 hours.)
(iv) Define the performance output to be reactant conversion q = (1−CA/CA0).
Linearize the system around the steady-state condition:
sSSOP =

2.8 kmol e/m3
685.5 K
364 K

mSSOP = [120 m3/h r]
pSSOP =  4 kmol e 300 K/m3  qSSOP = [0.429]
Determine the stability characteristics of the linearized model. (Use the
MATLAB function ‘ss2tf’ to determine the open-loop characteristic equation. Then, use ‘roots’ to determine poles of the open-loop system.)
(v) Discretize the system using the sample-and-hold approach, using a sample
period, ∆t , of 1sec. Using this discrete-time model, simulate the open-loop
process and verify the stability result of part (iv).
(vi) Add a simple proportional controller to the process and simulate conditions
identical to those used in (iii). Compare the results with those of the nonlinear simulation. (Remember to change to deviation variables for the new
simulations. Additionally, remember to convert back to the original variables when making the plots.)
(vii) Using the closed-loop system of part (vi), simulate the response to step changes
at the disturbances. (Regarding the size of these step changes, you should select something reasonable).
2.10. Reproduce the results of the DC-Motor examples: Example 2.7, Example 2.8 and
Example 2.13.
2.11. Consider the Furnace Reactor process of Section 2.6.1.
(i) Indicate the deviation variable form of the process model.
(ii) Using a MATLAB ode solver, simulate the following scenario.
- The initial condition is s(0) = [350K 525K 6% 130p pm]∗
- m(t) = [10000b b l/day 10b b l/day 0.1%]∗ for t < 5 minutes and =
[10100b b l/day 9b b l/day 0.11%]∗ for t > 5 minutes
- p(t) = 300K for t < 10 minutes and = 325K for t > 10 minutes.
While this simulation should be performed using the model in deviation
variables, all plots should display the results in natural variables.
(iii) Convert the continuous-time linear model in deviation variables to a discretetime form using the sample and hold method and a sample time of 30 seconds
( = 0.000347 days). Report the values of Ad, Bd and Gd.
64 Chapter 2. Modeling of Dynamic Systems
(iv) Repeat the simulation of part (ii) using the discrete-time model and compare
with the continuous-time results.
2.12. Consider the Three Mass system of Section 2.6.2.
(i) If r1 is desired to be 0.15 m, determine value of Fm required. This will
require you to solve the steady-state relations of the system using r1 = 0.15
and F
m as a variable to be determined. Note that the nominal value of Fd,
given in Section 2.6.2 should be assumed.
(ii) Using the steady-state point of part (i), determine the deviation variable form of the process model. Report A, B, G, Dx, Du and Dw.
(iii) Using a MATLAB ode solver, simulate the following scenario. The initial
condition is s(0) = snom, m(t) = mnom for t < 1 second and = mnom +1 kN
for t > 1 second and p(t) = pnom for t < 3 seconds and = pnom +1.5 kN for
t > 3 seconds. While this simulation should be performed using the model
in deviation variables, all plots should display the results in natural variables.
(iv) Convert the continuous-time linear model in deviation variables to a discretetime form using the sample and hold method and a sample time of 0.1 seconds. Report the values of Ad, Bd and Gd.
(v) Repeat the simulation of part (iii) using the discrete-time model and compare
with the continuous-time results.
2.13. Consider the Endothermic CSTR process of Section 2.6.3.
(i) Put system model into the form of Equation (2.1)-(2.2).
(ii) Verify that the SSOP is given by:
sSSOP =

s(1)SSOP
s(2)SSOP
s(3)SSOP
s(4)SSOP
s(5)SSOP

=

362.22
0.0154
0.9846
449.79
385.58

,
where
s =

s(1)
s(2)
s(3)
s(4)
s(5)

=

T1CACBT3T4

(iii) Linearize the model around the SSOP. Report A, B and G.
(iv) Using a MATLAB ode solver, compare the linearized model with the original nonlinear model. Assume the initial condition is the SSOP and implement the following scenario:
- t < 0: CA0 = 1.0 kmol e/m3 and Q = 2.845×106 kcal/h r
- t > 0 and t < 10: CA0 = 1.2 kmol e/m3 and Q = 2.7×106 kcal/h r
- t > 10 and t < 20: CA0 = 1.2 kmol e/m3 and Q = 3.1×106 kcal/h r
(v) Discretize the linear model of part (iii) using a sample time 0.1 h r. Report
the values of Ad, Bd and Gd.
(vi) Repeat the scenario of part (iv) and compare the discrete-time simulation
with the linear continuous-time simulation.
Exercises 65
2.14. Consider the Manufacturing process of Section 2.6.4.
(i) Using the nominal values given in Section 2.6.4, determine the nominal values of all other variables. Note that the nominal values of the storage inventory will be indeterminate, so you should select reasonable values.
(ii) Indicate the deviation variable form of the process model.
(iii) Simulate the discrete-time process using the following scenario. The initial
condition is s
0 = snom, wk = wnom for all k, mk = mnom − [50 25 25 0 0]∗
for k < 10, mk = mnom + [100 25 25 0 0]∗ for 10 ≤ k < 20 and mk =
mnom + [100 25 25 15 15]∗ for 20 ≤ k < 30. While this simulation should
be performed using the model in deviation variables, all plots should display
the results in natural variables.
2.15. Consider the HVAC system of Section 2.6.5.
(i) If Tr oom and Cr oom are desired to be 25.5◦C and 400 p pm, determine required values of Fr c y and Ff r es h. This will require you to solve the steadystate relations of the system using Fr c y and Ff r es h as variables to be determined. Note that the nominal and parameter values given in Section 2.6.5.
(ii) Using the steady-state point of part (i), determine the deviation variable form of the process model. Report A, B and G.
(iii) Using a MATLAB ode solver, simulate the following scenario. The initial
condition is s(0) = snom, m(t) = mnom for t < 1 hour and m(t) = mnom +
[0.5 −0.1]∗ for t > 1 hour and p(t) = 29◦C for t < 2 hours and = 32◦C for
t > 2 hours. While this simulation should be performed using the model in
deviation variables, all plots should display the results in natural variables.
(iv) Convert the continuous-time linear model in deviation variables to a discretetime form using the sample and hold method and a sample time of 15 minutes. Report the values of Ad, Bd and Gd.
(v) Repeat the simulation of part (iii) using the discrete-time model and compare
with the continuous-time results.
66 Chapter 2. Modeling of Dynamic Systems
Chapter 3
Review of Linear Algebra
In this chapter we will review a number of the fundamental concepts related to linear
algebra. While many of these concepts are of independent interest, they will serve as
a foundation for our subsequent analysis of linear dynamic systems. In particular, the
fundamental theorem of linear algebra will be used in Chapter 4 to gain a deeper understanding of the concepts of controllability and observability. Similarly, eigenvector
decomposition will be used expose the inner workings of stability analysis. In addition,
the notion of similar matrices will lead to the canonical form of a dynamic system and
ultimately to the concepts of stabilizability and detectability, which will be prerequisites
for the design of a feedback controller. Finally, the Lyapunov stability theorem of Chapter 4 will serve as the basis for many of the subsequent control design methods (especially
those of Part III). However, this theorem rests heavily upon the notion of a positive definite matrix, which will be introduced in the current chapter.
3.1 Sets, Subsets and Linear Vector Spaces
Let us begin with the notion of a set. In essence, a set is just a collection of elements. The
collection may have a finite number of elements, say the set of all engineering graduate
students, or may have an infinite number of elements, say all real numbers in the interval
between 0 and 1. A particularly relevant example is the set of all vectors in the two
dimensional plane. This set will be denoted as R2 and is defined as follows
R2 = ƒx = [a b]T a and b are real numbers' (3.1)
(For the definition of transpose, T , see Definition 2.4.) Equation 3.1 is read as “R2 is the
set of all x with a form [a b]T such that a and b are real numbers.” Note the symbol “ ”
is shorthand for “such that”. A subset is just a set where its elements are all members of
the original set. For example, one could define the following set:
S = ƒx = [a b]T a and b are real numbers,0 ≤ a ≤ 1 and 0 ≤ b ≤ 1' (3.2)
In this case S would be a subset of R2, denoted as S ⊆ R2.
In this text, we will mostly be interested in sets that have been endowed with two
elementary operations - addition and scalar multiplication. Clearly, this requirement
will exclude the set of all engineering graduate students from our consideration, as it will
be difficult to define such operations for that collection of elements. However, the set R2
67
68 Chapter 3. Review of Linear Algebra
is certainly amenable to the definition of such operators. For example if x is an element
of R2 (denoted as x ∈ R2) and α is a real number then scalar multiplication can be defined
as αx = [αa αb]T . Similarly, if given two elements x1 and x2, both in R2 (denoted
x
1, x2 ∈ R2), then the addition of the two can be defined as x1 + x2 = [a1 + a2 b1 + b2]T .
It should be highlighted that the set of scalars used for scalar multiplication could be
defined as the set of complex numbers (i.e., α ∈ C).
Sets for which addition and scalar multiplication are defined are typically denoted as
vector sets. An important class of vector sets is those in which the operations of scalar
multiplication and/or addition using any elements of the set will result in an element that
is guaranteed to be within the original set. This property of never leaving the original
set (under the operations of scalar multiplication and/or addition) provides an important
starting point in the sense that the all linear combinations of elements are guaranteed to
be elements of the set. Think of it as defining the universe (or space of elements) for the
subsequent analysis.
Definition 3.1. A linear vector space is a set X such that α1x1+α2x2 ∈ X for all x1, x2 ∈ X
and all α
1,α2 ∈ R.
Returning to the previous example, consider the set R2. Since for all α1,α2 ∈ R and
all x
1, x2 ∈ X it is found that α1x1 + α2x2 = [α1a1 + α2a2 α1b1 + α2b2]T ∈ R2. Thus,
R2 is shown to be a linear vector space. In fact, if we generalize R2 to the set of elements
with n-tuple real values, Rn, then it is easily concluded that this is also a linear space.
However, the following counter example illustrates that the set S (of Equation 3.2) is
not a linear vector space. Let x1 = [0.5 0.5]T , x2 = [0 0]T , α1 = 4 and α2 = 0 then
α
1x1 + α2x2 = [2 2]T ∈/ S. The reader should note the difference in proving that a set
is or is not a linear vector space. In the former case, we must show the property for all
scalars and all elements of the set, while in the latter case one need only find a single
example for which the property fails.
Example 3.1. Let X be the set of all second order polynomials. In general an element of
X is a function x
1(t) = a1t2 + b1t + c1, where a1, b1,c1 ∈ R. If x2 is defined similarly then
it is easily verified that α1x1 + α2x2 ∈ X for all α1,α2 ∈ R.
In many cases, Definition 3.1 is expanded such that R is replaced by C. In these cases,
the vector space X will need to consist of complex elements, e.g. X = Cn. The following
two definitions and associated corollary are direct consequences of Definition 3.1.
Definition 3.2. A subset S of a linear vector space X (denoted as S ⊆ X ) is a subspace, if S
is also a linear vector space.
Definition 3.3. Let S be a subset of a linear vector space X . The span of S (denoted s pan{S})
is the set of all elements resulting from linear combinations of elements in S.
Corollary 3.1. If S is a subset of a linear space X , then s pan{S} is a subspace.
Example 3.2. Let X = R and consider the subsets of Figure 3.1. Subset S1 is contained
completely in the positive quadrant and thus is not a subspace. Subset S2 contains all
points along the identified line and is easily shown to be a subspace. Subset S3 also contains all points along a line, but does not contain the origin and thus is not a subspace.
3.2. Inner Products and Orthogonality 69
(a) (b) (c)
S1 S2 S3
Figure 3-1 Figure 3.1. : Candidate subsets for Example 3-2 Candidate subsets for Example 3.2
Subset S
3 is frequently denoted as a linear variety. The span of subset S1 is equal to subset
S2
. The span of subset S2 is equal to itself. The span of subset S3 equals the entire space .
In the context of Chapter 2, the obvious application of the linear vector space notion
is toward the concept of a state space model. Specifically, if given a model of the form of
Equation 2.1, then the state vector, s, is an element of Rnx, where nx is the dimension of
the state vector. More specifically, if the solution to Equation 2.1 is s(t), then at any given
time t
1, s(t1) ∈ Rnx. Similar notions can be applied to the space of inputs, associated with
m and p, as well as the space of outputs, associated with q and θ.
3.2 Inner Products and Orthogonality
In the two-dimensional space, R2, there is an intuitive understanding of directionality,
and specifically the notion of orthogonality, in that the intersection of two vectors forms
a right angle, or the two are perpendicular. In higher dimensional spaces, the generalized
notion of directionality will need to be formalized. We will find this formality within
the notion of an inner product.
Definition 3.4. Let X be a linear vector space and α be the complex conjugate of α. The
inner product, denoted [x, y], is a scalar function that satisfies the following five properties
for all x,y, z ∈ X :
(i) [y, x] = [x, y].
(ii) If α ∈ C, then [αx, y] = α[x, y] and [x, αy] = α[x, y].
(iii) [x + y, z] = [x, z] + [y, z].
(iv) [x, x] is real and non-negative.
(v) [x, x] = 0 only if x = 0.
Let X = Cn, then an element x ∈ X is denoted as x = [x(1) x(2) ··· x(n)]T . For this
linear vector space, a commonly defined inner product is
[x,y] =
n∑i=1
x(i)y(i) (3.3)
This is easily shown to satisfy criteria (i) − (v) of Definition 3.4.
70 Chapter 3. Review of Linear Algebra
Example 3.3. Let X = C2 and denote an element x ∈ X as x = [x(1) x(2)]T . Then, define
the function:
[x,y] = [y(1) y(2)] −11 4 −1  x x( (1 2) ) 
= y
(1)
x(1) − y(1)x(2) − y(2)x(1) + 4y(2)x(2)
To see if this a valid inner product, we will need to check if this function satisfies the five
criteria of Definition 3.4.
(i) [x, y] = y(1) y(2) −11 4 −1  x x( (1 2) ) 
= x(1) x(2) −11 4 −1  yy((12) )  = [y, x]
(ii) [x,αy] = αy(1) αy(2) −11 4 −1  x x((12) )  = α[x,y]
(iii) [x + y, z] = z(1) z(2) −11 4 −1  x x( (1 2) ) + + y y( (1 2) )  = [x, z] + [y, z]
(iv) First, recall that αα = |α|2 ≥ 0. Then,
[x, x] = x(1)x(1) − x(1)x(2) − x(2)x(1) + 4x(2)x(2)
= (x(1) − x(2))(x(1) − x(2)) + 3x(2)x(2) = (x(1) − x(2)) 2 + 3 x(2) 2 ≥ 0
(v) The only way [x, x] = (x(1) − x(2)) 2 + 3 x(2) 2 = 0 is if x(1) = 0 and x(2) = 0.
Let us now return to the intuitive nature of R2. If the inner product is defined as in
Equation (3.3), over R2, then one finds that the notion of two vectors being perpendicular is equivalent to the inner product being equal to zero (see Example 3.4 below). Thus,
the generalization to any linear vector space is the following - two vectors are perpendicular (or orthogonal) if the inner product of the two vectors is zero. One may also gain
intuition from the three-dimensional space R3. Specifically, a vector is said to be perpendicular to a plane if it is at a right angle to all vectors in that plane. One may additionally
ask: find the plane that perpendicular to a given vector or set of vectors. The following
definitions formalize all of the above notions.
Definition 3.5. Vectors x, y ∈ X are orthogonal, denoted x ⊥ y, if [x,y] = 0.
Definition 3.6. A vector x ∈ X is orthogonal to a set S, denoted x ⊥ S, if x ⊥ s for all
s ∈ S.
Definition 3.7. Let S be a subset of a linear vector space X , then the orthogonal complement
of S is defined as: S⊥ = {x ∈ X | x ⊥ S}. S⊥ is read as “S perpendicular” or just “S perp”.
Also, S⊥⊥ is read as “S double perp”.
Corollary 3.2. If S is a subset of a linear vector space X , then S⊥ is a subspace and S⊥⊥ =
s pan{S}.
3.3. Linear Transformations 71
Definition 3.8. Let S
1 and S2 be subspaces of a linear vector space X . The direct sum of S1
and S
2 is defined as: S1 ⊕ S2 = {x ∈ X | x = s1 + s2 where s1 ∈ S1 and s2 ∈ S2}.
Corollary 3.3. If S is a subset of a linear vector space X , then S⊥ ⊕ S⊥⊥ = X .
Example 3.4. Let X = R2 and employ the inner product of Equation (3.3).
(a) If x = [1 2]T , y1 = [−2 1]T , y2 = [2 − 1]T and y3 = [−20 10]T , then x ⊥ y for
i = 1, 2, 3.
(b) Consider the set S = ƒy ∈ R2 | y = α[−2 1]T , α ∈ R'. If x = [1 2]T , then x ⊥ S.
(c) Consider the singleton set S = ƒ[−2 1]T ', then S⊥ = ƒx ∈ R2 | x = α[1 2]T ,α ∈
R} and S⊥⊥ = ƒx ∈ R2 | x = α[−2 1]T ,α ∈ R'. Clearly, S⊥ ⊕ S⊥⊥ = R2.
Example 3.5. Let X = R3 and employ the inner product of Equation (3.3). If the set
is just S = ƒ[1 0 0]T ', then S⊥ = ƒx ∈ R3 | x = α1[0 1 0]T + α2[0 0 1]T ,α1,α2 ∈ R'
and S⊥⊥ = ƒx ∈ R3 | x = α[1 0 0]T ,α ∈ R'. Clearly, S⊥ ⊕ S⊥⊥ = R3.
3.3 Linear Transformations
Recall the model of a discrete-time process, given in Equation (2.91): sk+1 = fd(sk). In
this model, a vector at time zero, s0, is transformed by the mapping fd to generate a new
vector s
1. This iteration continues until all of the sk’s are calculated. As one might expect,
being able to characterize such mappings will be an important tool in the analysis of a
dynamic system. However, rather than consider the general class of mappings, we will
focus on the special class known as linear transformations. Our first effort to characterize
a linear transformation will be the definition of a pair of intuitively simple subspaces -
the null space and range space. Using these subspaces, the Fundamental Theorem Linear
Algebra will give conditions for the existence and uniqueness of a solution to a linear
equation based on a linear transformation. To help utilize the Fundamental Theorem, a
transformation companion to the original, known as the adjoint, will be introduced and
shown to lead to the four fundamental subspaces of a linear transformation.
Definition 3.9. Let X and Y be linear vector spaces, then a transformation L : X → Y
(commonly denoted as y = Lx, where y ∈ Y and x ∈ X ) is a linear transformation if for all
x
1, x2 ∈ X and α1,α2 ∈ C the following holds:
L(α1x1 + α2x2) = α1Lx1 + α2Lx2
Definition 3.10. Let X and Y be linear vector spaces, then the null space of linear transformation L : X → Y is defined as:
ℵ(L) = {x ∈ X | Lx = 0}
72 Chapter 3. Review of Linear Algebra
Definition 3.11. Let X and Y be linear vector spaces, then the range space of linear transformation L : X → Y is defined as:
ℜ(L) = {y ∈ Y | y = Lx where x ∈ X}
Corollary 3.4. If L : X → Y , where X and Y are linear vector spaces, then ℵ(L) is a
subspace of X and ℜ(L) is a subspace of Y .
Example 3.6. Let X and Y both be the set of second order polynomials. If the mapping
L : X → Y is the first derivative operator (d/d t), then L is easily shown to be a linear
transformation. The null space of L is the subspace of zero order polynomial (constants).
Also, the range space of L is the subspace of first order polynomials.
Example 3.7. Let X = R3, Y = R2, and define L : X → Y by the matrix  10 2 0 5 1 0 .
(i) Show that L is a linear transformation
(ii) Find the null space of L
(iii) Find the range space of L
Solution: (i) If an element x ∈ X is x = x(1) x(2) x(3)T , then using the usual convention
of matrix multiplication, y = Lx is found to be  y y( (1 2) )  =  10 5xx(1(1))++12xx(2(2))++00xx(3(3)) .
If x
1 = hx1(1) x1(2) x1(3)iT and x2 = hx2(1) x2(2) x2(3)iT , then
L(α1x1 + α2x2) =   10 5((αα11xx1(11(1))++αα22xx2(21(1))) + ) +12((αα11xx1(12(2))++αα22xx2(22(2))) + ) +00((αα11xx1(13(3))++αα22xx2(23(3))))  
= α
1Lx1 + α2Lx2
(ii) The problem is to find x = x(1) x(2) x(3)T such that Lx = 0, or equivalently x(1),
x(2) and x(3) such that  y y( (1 2) )  =  10 5xx(1(1))++12xx(2(2))++00xx(3(3))  =  0 0 . By inspection
one may easily conclude that [0 0 1]T ∈ ℵ(L). In fact, for all α1 ∈ ℜ, [0 0 α1]T ∈ ℵ(L).
Similarly, for all α2 ∈ ℜ, [α2 − 5α2 0]T ∈ ℵ(L). In addition, any vector that is a linear
combination of these two subspaces will also be in the null space of L. Specifically,
α
1

001

+ α2

1 −
5
0

∈ ℵ(L) for all α1,α2 ∈ ℜ
This is equivalently stated as: ℵ(L) = s pan{[0 0 1]T ,[1 −5 0]T }.
(iii) If an element x ∈ X is denoted by x = x(1) x(2) x(3)T , then
 yy((12) )  =  10 5xx(1(1))++12xx(2(2))++00xx(3(3))  =   255xx(1(1))++11xx(2(2))  
= 5x(1) + 1x(2) 1 2  = α 12 
3.3. Linear Transformations 73
Since all vectors y generated by Lx will be of the form α[1 2]T , ℜ(L) = s pan{[1 2]T }.
Another way to see the result is to express the transformation as a linear combination of
the matrix columns:
 yy((12) )  = x(1)  10 5  + x(2)  10 5  + x(1)  0 0 
Then one would conclude that ℜ(L) = s pan{[5 10]T ,[1 2]T ,[0 0]T }, which is clearly
equal to s pan{[1 2]T }.
Corollary 3.5. If a linear transformation L : Cm → Cn is defined by a matrix M with
columns c
1,c2,...,cm, then ℜ(L) = s pan{c1,c2,...,cm} .
The concepts of range space and null space are particularly useful for determining if a
solution to a linear equation exists and if that solution is unique. The following theorem,
termed the Fundamental Theorem of Linear Algebra, summarizes the result.
Theorem 3.1. If L : X → Y , where X and Y are linear vector spaces, then a solution x
will exist to the equation Lx = b if and only if b ∈ ℜ(L). Furthermore, the solution will be
unique if and only if ℵ(L) is empty (i.e., the only x in ℵ(L) is x = 0).
Proof. The existence part stems directly from the definition of range space. That is, for
every element b ∈ ℜ(L), there must exists an element x ∈ X such that b = Lx (i.e.,
b ∈ ℜ(L) implies existence). In addition, if x is such that Lx = b, then b must be in
the range space of L (i.e., existence implies b ∈ ℜ(L)). To prove the uniqueness part,
assume ℵ(L) is not empty, which implies there exists xN ∈ X such that LxN = 0. Then, if
xS ∈ X is such that LxS = b, one can also conclude that xS +xN ∈ X is also a solution since
L(xS +xN ) = LxS = b. Thus, ℵ(L) not being empty, implies the solution is not unique, or
equivalently that uniqueness implies ℵ(L) is empty. To prove the other direction, assume
we have two points x1, x2 ∈ X are such that Lx1 = b and Lx2 = b, then subtracting these
two equations gives L(x1 − x2) = b − b = 0 or x1 − x2 ∈ ℵ(L). Thus, non-uniqueness
implies ℵ(L) not empty, or equivalently empty implies uniqueness.
While Theorem 3.1 provides significant motivation to calculate the range space and
null space, the “by inspection” methods of Example 3.7 will quickly fail us, especially if
the vector spaces X and Y are of large dimension and the linear transformation is not
quite so simple. If the linear transformation is just a matrix, then the end of Example
3.7 indicates that the simplest method of calculating the range space is to recognize that
it is just the span of the columns of the matrix, as indicated by Corollary 3.5. However,
Example 3.7 also indicates that many of the columns of the matrix M may be redundant,
and the issue is to remove these redundancies. This will be of particular interest if one
is trying to use Theorem 3.1 to show that a solution to the equation Lx = b exists for
all b ∈ Y. To do so, one will need to show that the range space is the entire space (i.e.,
ℜ(L) = Y). In this case, finding redundant columns will be of critical importance. In
Section 3.4, a systematic method of finding and removing these redundancies will be
given.
In the remainder of the current section an alternative approach will be investigated.
Specifically we will consider the orthogonal complement of the range space: ℜ(L)⊥. If
one can show that ℜ(L)⊥ is empty, then this will be equivalent to showing that ℜ(L) = Y
74 Chapter 3. Review of Linear Algebra
and ultimately a solution to Lx = b exists regardless of the value used for b. This characterization of ℜ(L)⊥ will require the definition of a companion linear operator known
as the adjoint (which should not be confused with the “classical adjoint” associated with
matrix inversion and detailed in Definition 3.22). Using the notion of an adjoint, a rather
elegant decomposition of the vector spaces X and Y can be achieved that leads to a characterization of ℜ(L)⊥ as well as ℵ(L)⊥.
Definition 3.12. Let X and Y be linear vector spaces and L : X → Y be a linear transformation, then the adjoint of L is L∗ such that [Lx,y] = [x,L∗y] holds for all x ∈ X and
y ∈ Y .
Example 3.8. If L : R3 → R2 is defined by the matrix of Example 3.7, and the inner
product is defined as in Equation (3.3), determine the adjoint, L∗ : R2 → R3.
Solution: Since Lx =  10 5xx(1(1))++12xx(2(2))++00xx(3(3))  one finds that
[Lx,y] = y(1) y(2) 10 5xx(1(1))++12xx(2(2))++00xx(3(3)) 
= y(1) y(2) 10 2 0 5 1 0    x x x( ( (1 2 3) ) )   
= 5y(1) + 10y(2) 1y(1) + 2y(2) 0y(1) + 0y(2)

x(1)
x(2)
x(3)

= [x,L∗y]
Thus,
L∗y =

5y(1) + 10y(2)
1y(1) + 2y(2)
0y(1) + 0y(2)

=

5 10
1 2
0 0

 y y( (1 2)) 
and indicates that the matrix associated with L∗ is

5 10
1 2
0 0

.
Corollary 3.6. If a linear transformation L : Cm → Cn is defined by a matrix M and
the inner product is defined as in Equation (3.3), then the matrix defining L∗ is the complex
conjugate transpose of M or M∗ = MT .
Theorem 3.2. Let X , Y be linear vector spaces and L : X → Y be a linear transformation.
Then the following hold:
(i) ℜ(L)⊥ = ℵ(L∗) and ℜ(L) ⊕ ℵ(L∗) = Y .
(ii) ℵ(L)⊥ = ℜ(L∗) and ℵ(L) ⊕ ℜ(L∗) = X
Proof. Part (i): If y ∈ ℜ(L)⊥, then y ⊥ Lx for all x ∈ X, since Lx ∈ ℜ(L). Then, the
definition of adjoint indicates that [x,L∗y] = [Lx,y] = 0. Since this holds for all x ∈ X,
3.3. Linear Transformations 75
one must conclude that L∗y = 0, or y ∈ ℵ(L∗). Thus, ℜ(L)⊥ ⊆ ℵ(L∗). To show that
ℵ(L∗) ⊆ ℜ(L)⊥, assume y ∈ ℵ(L∗) which implies 0 = [x,L∗y] = [Lx,y] for all x ∈ X,
and finally y ∈ ℜ(L)⊥. Thus, ℜ(L)⊥ = ℵ(L∗). Then, since ℜ(L) ⊕ ℜ(L)⊥ = Y, one also
concludes that that ℜ(L) ⊕ ℵ(L∗) = Y.
Part (ii): see Exercise 3.7
Example 3.9. If L : R3 → R2 is defined by the matrix of Example 3.7, and the inner
product is defined as in Equation (3.3), determine ℜ(L) and ℵ(L) from ℜ(L∗) and ℵ(L∗)
and Theorem 3.2.
Solution: From Example 3.8, we know that the adjoint of L is the matrix
MT =

5 10
1 2
0 0

By inspection we find that ℵ(L∗) = s pan{[−2 1]T }. Thus, any y that is perpendicular to
[−2 1]T will be an element of ℜ(L). Clearly, the set of vectors perpendicular to [−2 1]T
is s pan{[1 2]T }, which indicates that s pan{[1 2]T } = ℵ(L∗)⊥ = ℜ(L). Using Corollary
3.5, one finds that ℜ(L∗) = s pan{[5 1 0]T , [10 2 0]T } = s pan{[5 1 0]T }. Clearly, the
set of vectors perpendicular to [5 1 0]T is s pan{[0 0 1]T , [1 − 5 0]T } = ℜ(L∗)⊥ =
ℵ(L).
It should be emphasized that the calculation of the adjoint and the orthogonal complement are both dependent on the specific inner product that is used. For example, use
of the inner product of Example 3.3 will result in the adjoint of a matrix being something other than just the complex conjugate transpose. However, Theorem 3.2 will hold
regardless of the inner product used. This is because both the adjoint and orthogonal
complement simultaneously will change accordingly when using a different inner product (see Exercise 3.21).
Corollary 3.7. If a linear transformation L : Cm → Cn is defined by a matrix M, and the
inner product is defined as in Equation (3.3), then using Corollaries 3.5 and 3.6 along with
Theorem 3.2 one concludes that ℵ(L) = (s pan{r1, r2,... r n})⊥, where r i are the complex
conjugates of the rows of M. More specifically, x ∈ ℵ(L) if x ⊥ r i for all i, or equivalently
[x, r i] = 0 for all i.
Summarizing the sub-section, Theorem 3.1 tells us that a solution x will exist for all
b, if ℜ(L) = Y. If L is defined by a matrix M, then Corollary 3.5 indicates that ℜ(L) = Y
is equivalent to s pan{c1,c2,...cn} = Y, where ci are the columns of M. In addition, the
second part of Theorem 3.1 tells us that a solution x will be unique, if ℵ(L) = 0, which
by Theorem 3.2 is equivalent to ℜ(L∗) = X. Thus, if L is defined by a matrix M, then
Corollary 3.5 indicate that ℜ(L∗) = X is equivalent to s pan{r1, r2,... r m} = X, where
r i are the complex conjugates of the rows of M.
Thus, for the case of L : Cm → Cn, we have boiled the conditions of Theorem 3.1
down to verifying if the span of a set of vectors is equal to the entire space (or equivalently
if the set of vectors spans the entire space). In the next section, we will describe two
systematic methods of performing this verification. However, before doing so, let us
develop a simple pretest exclusion condition. That is, if the pretest condition is satisfied,
then we will know immediately that the span of this set of vectors cannot be equal to
the entire space. If L : Cm → Cn, then Y = Cn and Y has a dimension of n. Then,
76 Chapter 3. Review of Linear Algebra
since at least n vectors are required to span all of Y, it is easily concluded that m must be
greater than or equal to n, before there is any hope of these m vectors spanning all of Y.
Thus, if m < n, then we know that s pan{c1,c2,...cn} ̸= Y. Similarly, since X = Cm, the
condition n < m, will guarantee that s pan{r1, r2,... r n} ̸= X.
As a final point, the condition m < n does not preclude there being a solution to
Lx = b, since the actual condition is b ∈ ℜ(L). If s pan{c1,c2,...cm} ̸= Y, then one
may still want to check if b ∈ s pan{c1,c2,...cm}. While the first method of the next section (the Gram-Schmidt procedure) can be used to check if s pan{c1,c2,...cm} =
s pan{c1,c2,...cm, b}, the second method (Singular Value Decomposition) will characterize ℵ(L) directly. Given this characterization, along with Theorem 3.2, it will be easy to
verify if b ∈ ℜL by checking if b ∈ ℵ(L∗)⊥, or equivalently if b ⊥ ℵ(L∗).
3.4 Linear Independence and Orthogonalization
While the characterization of the subspace spanned by a set of vectors has its origin in
the notion of linear independence and more specifically the notion of a basis set, we will
find that the procedure of orthogonalization will provide computationally based answers
to these questions. Specifically, what is the smallest number of vectors that can be used
to span a subspace? Given this number we will be able to ascertain if the span of a set of
vectors is the entire space, and if not what is the most compact characterization of the
subspace. At the end of the section a method will be provided that gives directly the four
characteristic subspaces of Theorem 3.2.
Definition 3.13. A set of vectors ϕ1,ϕ2 ...ϕn are linearly independent if the only way to
arrive at ∑n i=1 αiϕi = 0 is to set αi = 0 for all i.
Theorem 3.3. Consider a linear transformation L : Cm → Cn defined by a matrix M with
columns c
1,c2,...cm and rows r1, r2,... rn. Then,
(i) ℵ(L) is empty if and only if c1,c2,...cm are linearly independent.
(ii) ℜ(L) = Cn if and only if r1, r2,... r n are linearly independent.
Proof. Part (i) results directly from the definition linear independence and that of the null
space. Part (ii): From Theorem 3.2, we know that ℜ(L) = ℵ(L∗)⊥. Thus, ℜ(L) = Cn if
and only if ℵ(L∗)⊥ is empty. And, ℵ(L∗)⊥ is empty if and only if r1, r2,... r n are linearly
independent.
While Theorem 3.3 gives another perspective on the conditions of Theorem 3.1 (the
Fundamental Theorem of Linear Algebra), it shifts the original question to that of linear independence. One way to answer the question of linear independence is through
orthogonalization. We begin with a couple of definitions.
Definition 3.14. A set of vectors, ϕ1,ϕ2 ...ϕn, is orthogonal if [ϕi,ϕj] = 0 for all i ̸= j.
Definition 3.15. A set of vectors, ϕ1,ϕ2 ...ϕn, is orthonormal if
[ϕi,ϕj] = (0 1 if i if i ̸= = jj
3.4. Linear Independence and Orthogonalization 77
Theorem 3.4. If a set of vectors ϕ1,ϕ2 ...ϕn is orthogonal, then they are linearly independent.
Proof. Assume ϕ1,ϕ2 ...ϕn are orthogonal. Let α1,α2 ...αn be such that ∑n i=1 αiϕi = 0.
Then, for all j, 0 = ∑n i=1 αiϕi,ϕj = αj[ϕj,ϕj], since [ϕi,ϕj] = 0 for all i ̸= j. Since
each ϕj is non-zero, we conclude that αj must be equal to zero for all j.
It should be emphasized that the converse of Theorem 3.4 is not true. Specifically,
linear independence does not guarantee orthogonality.
(a) (b) (c)
1
2
1
2
1
3
2
(d) (e) (f)
q1
q2
q1 q1
q2
Figure 3-2: Candidate vectors for Example 3-10
Figure 3.2. Candidate vectors for Example 3.10
Example 3.10. Let X = R2 and consider the vectors of Figure 3.2. In case (a), the two
vectors are linearly independent. It is noted that the two vectors are not orthogonal and
thus Theorem 3.4 cannot be used to conclude linear independence. In case (b), the two
vectors occupy the same subspace and thus are not linearly independent. In the context
of Definition 3.13, take α1 = 1/|ϕ1| and α2 = −1/|ϕ2| to find the sum equal to zero,
where |ϕj | = [ϕj,ϕj]1/2 is the length of each vector. In case (c), the three vectors are not
linearly independent. In general, if the number of vectors is greater than the dimension
of the space, then they are not linearly independent. In cases (d), the two vectors are
orthogonal and as indicated by Theorem 3.4, must be linearly independent. Of course,
the orthogonality of case (d), assumes the inner product of Equation 3.3 is used. If some
other inner product was used, then the convention of a right angle may not indicate
orthogonality. In fact, for an appropriately defined inner product, the vectors of case
(a) could be orthogonal. However, those of cases (b) and (c) could never be orthogonal,
regardless of the inner product used.
Definition 3.16. Consider a set of vectors ϕ1,ϕ2 ...ϕn, then the following Gram-Schmidt
78 Chapter 3. Review of Linear Algebra
Orthogonalization procedure will generate a set of orthogonal vectors q1,q2 ...qn such that
s pan{q1,q2 ...qn} = s pan{ϕ1,ϕ2 ...ϕn}. The procedure is as follows:
q1 = ϕ1
q2 = ϕ2 − s2,1
q3 = ϕ3 − s3,1 − s3,2
... q
n = ϕn − sn,1 − sn,2 ··· − sn,n−1
where
si,j =

[ϕi,qj ]
[qj ,qj ] qj i f [qj,qj] ̸= 0
0 i f [qj,qj] = 0
More compactly the algorithm can be stated as qi = ϕi − ∑ij−=11 si,j i = 1...n
The particular benefit of the Gram-Schmidt procedure is that during execution one
may find that one or more of the resulting qi vectors is zero. If this is the case, then the
original set of vectors ϕ1,ϕ2 ...ϕn are not linearly independent. However, if all of the
resulting qi vectors are non-zero, then the original set is linearly independent.
Example 3.11. Let X = R2 and reconsider the vectors of Figure 3.2. If the inner product
of Equation 3.3 is used and the Gram-Schmidt procedure is applied to cases (a), (b) and
(c), then the result will be cases (d), (e) and (f), respectively.
To be more specific, consider case (a) and let ϕ1 = [2 1]T and ϕ2 = [−4 1]T . Since
q1 = [2 1]T we find that
s
2,1 =
[ϕ2,q1]
[q1,q1]
q1 =
−7
5  12  =  −−14 7//55 
and
q2 = ϕ2 − s2,1 =  −14  −  −−14 7//55  =  −126//55 .
Then, one can verify that q1 = [2 1]T and q2 = [−6/5 12/5]T are orthogonal by calculating [q1,q2] = −12/5 + 12/5 = 0.
In case (b), ϕ1 = [2 1]T and ϕ2 = [4 2]T . Since, q1 = [2 1]T we find that
s
2,1 =
[ϕ2,q1]
[q1,q1]
q1 =
10
5  12  =  42 
and
q2 = ϕ2 − s2,1 =  4 2  −  42  =  0 0 .
3.4. Linear Independence and Orthogonalization 79
As such, q2 is not included in case (e). If there were an additional vector, say ϕ3 =
[−4 1]T , then in the calculation of q3 one would set s3,2 = 0, since [q2,q2] = 0.
In case (c), ϕ1 = [2 1]T , ϕ2 = [−4 1]T and ϕ3 = [−2 −2]T . From case (a) we know
that q1 = [2 1]T and q2 = [−6/5 12/5]T . Then,
s
3,1 =
[ϕ3,q1]
[q1,q1]
q1 =
−6
5  12  =  −−12 6//55 
and
s
3,2 =
[ϕ3,q2]
[q2,q2]
q2 =
−12/5
36/5  −126//55  = −31  −126//55  =  −24//55 
Finally,
q3 = ϕ3 − s3,1 − s3,2 =  − −2 2  −  −−12 6//55  −  −24//55 
=  − −2 2  −  − −10 10/ /5 5  =  0 0 .
As such, q3 is not included in case (f).
Now return to the question of determining the range space of a matrix M : Cm → Cn,
ℜ(M) = s pan{c1,c2 ...cm}, and if that range space is equal to Cn. Begin by applying the
Gram-Schmidt procedure to the columns of M and remove all of the zero vectors from the
resulting qi set. If the number of remaining vectors is r, then the set will be q1,q2 ...qr.
If r is less than n, then ℜ(M) = s pan{c1,c2 ...cm} = s pan{q1,q2 ...qr} is a subset of Cn.
If r is equal to n, then Theorem 3.4 tells us that ℜ(M) = Cn. The third option, of r being
greater than n, is not possible, since the number of linear independent vectors cannot be
larger than the dimension of the space. It is noted that the number r, is actually equal to
the number of linear independent columns of M. The following definition gives a name
to this quantity.
Definition 3.17. The rank of a matrix M : Cm → Cn, denoted rank(M ), is equal to the
number of linearly independent columns of M , c1,c2 ...cm.
Our second computational method, the singular value decomposition, is quite a bit
more convenient, as it will give directly the four fundamental subspaces of Theorem 3.2,
if the linear transformation is a matrix. While the computational details of this procedure
are outside of our scope, the conceptual utility of this decomposition is undeniable. The
following definitions will be essential to understanding the singular value decomposition.
Definition 3.18. A linear transformation, U : X → X , is unitary if U U ∗ = U ∗U = I .
Definition 3.19. A set of vectors ϕ1,ϕ2 ...ϕn in a linear vector space X is a basis set for X ,
if ϕ1,ϕ2 ...ϕn are linearly independent and s pan{ϕ1,ϕ2 ...ϕn} = X .
Based on Definitions 2.5 and 3.18, it is clear that the inverse of a unitary transformation is equal to its adjoint, i.e., U −1 = U ∗. Furthermore, if given a unitary matrix
U : Cn → Cn, then it is easily concluded that the columns of U are an orthonormal basis
set for Cn.
80 Chapter 3. Review of Linear Algebra
Example 3.12. Reconsider the vectors of Figure 3.2. Since the span of the two vectors of
case (a) is X, these two may serve as a basis set. The vectors of the other two cases,(b) and
(c), may not serve as a basis set for X. In case (b), the span of the vectors is not X, and in
case (c) the vectors are not linearly independent.
Definition 3.20. The Singular Value Decomposition of a matrix, M : Cm → Cn, is composed of three matrices U , V and S with the following properties:
(i) M = U SV ∗
(ii) U : Cn → Cn and is unitary (U U∗ = U∗U = I )
(iii) V : Cm → Cm and is unitary (V V ∗ = V ∗V = I )
(iv) S : Cm → Cn and is of the form  Σ0 00 , where Σ is a square diagonal matrix
Σ =

σ
1 0 0
0
.
.
. 0
0 0 σ
r

and r = rank(M).
The diagonal elements of Σ are known as the singular values of M. These singular
values are all real and are usually arranged in decreasing order σ1 ≥ σ2 ≥ ···σr > 0. Of
greater interest is the fact that the columns of V form an orthonormal basis for Cm.
Then it is easily concluded that the span of last m − r columns of V is the null space of
M. Then, Theorem 3.2 tells us that the span of the remaining columns of V , the first r
columns, is the range space of M∗. A similar analysis of M∗ = V SU∗ indicates that the
first r columns of U span the range space of M and the remaining span the null space of
M∗. This decomposition of the four fundamental spaces of Theorem 3.2 is summarized
by the following Corollary.
Corollary 3.8. Consider a singular value decomposition of a matrix, M : Cm → Cn, as
described in Definition 3.20. If the columns of U are denoted as ui i = 1...n and the
columns of V are vi i = 1... m, then
(i) ℜ(M) = s pan{u1,..., ur} and ℵ(M∗) = s pan{ur+1,..., un}
(ii) ℜ(M∗) = s pan{v1,...,vr} and ℵ(M) = s pan{vr+1,...,vm}
It is noted that the MATLAB function ‘svd’ provides the Singular Value Decomposition.
Example 3.13. Consider a matrix
M =  10 2 0 5 1 0 
3.4. Linear Independence and Orthogonalization 81
Use of the MATLAB function ‘[U,S,V]=svd(M)’ on finds:
U =  − −0 0..4472 8944 0 −0.4472 .8944  S =  110 0 0 .4 0 0 
V =

−0.9806 −0.1961 0
−0.1961 0.9806 0
0 0 1

Clearly, both U and V are unitary. Based on the value determined for S, we conclude
that r = rank(M) = 1. Thus,
ℜ(M) = s pan{u1,..., ur} = s pan{[−0.4472 − 0.8944]T } = s pan{[1 2]T }
ℵ(M∗) = s pan{ur+1,..., un} = s pan{[−0.8944 0.4472]T } = s pan{[2 − 1]T }
ℜ(M∗) = s pan{v1,...,vr} = s pan{[−0.9806 − 0.1961 0]T } = s pan{[5 1 0]T }
ℵ(M) = s pan{vr+1,...,vm} = s pan{[−0.1961 0.9806 0]T ,[0 0 1]T }
= s pan{[1 − 5 0]T ,[0 0 1]T }
These results are in alignment with those of Examples 3.7 and 3.9.
Example 3.14. Consider a matrix
M =  1 1 2 −4 − −2 2 
Use of the MATLAB function ‘[U,S,V]=svd(M)’, gives:
U =  −−0 0..9940 1091 0 −0.9940 .1091  S =  4.9213 0 0 0 2.4043 0 
V =

−0.4261 0.3227 0.8452
0.78581 0.5950 0.1690
0.4483 −0.7361 0.5071

Based on the value determined for S, we conclude that r = rank(M) = 2. Thus,
ℜ(M) = s pan{u1,..., ur} = s pan{[−0.9940 − 0.1091]T ,[−0.1091 0.9940]T }
= R2
ℵ(M∗) = s pan{ur+1,..., un} = {0}
ℵ(M) = s pan{vr+1,...,vm} = s pan{[0.8452 0.1690 0.5071]T }
= s pan{[5 1 3]T }
ℜ(M∗) = s pan{v1,...,vr} = s pan{[5 1 3]T }⊥
82 Chapter 3. Review of Linear Algebra
3.5 Matrix Inverse and the Determinant
Let us return to the fundamental theorem of linear algebra (Theorem 3.1). It provides
conditions such that a unique solution to the equation Lx = b will exist for all b. Specifically, the two conditions for an operator L : X → Y are "ℜ(L) = Y implies existence for
all b" and "ℵ(L) = {0} implies uniqueness of the solution". If a unique solution will exist
for each b, then there must be a unique transformation L−1 such that x = L−1b. In addition, based on the original equation, Lx = b, this L−1 must be such that L−1L = I , where
I x = x for all x ∈ X. For the case of L being defined by a matrix M : Cm → Cn, the first
condition, ℜ(M) = Y, translates to s pan{c1,c2,...,cm} must be equal to Cn. Furthermore, the second condition, ℵ(M) = ℜ(M∗)⊥ = {0}, translates to s pan{r1, r2,..., r n}
must be equal to Cm. Clearly, the first condition requires m ≥ n . That is, if m < n,
then it would be impossible for s pan{c1,c2,...,cm} be equal to Cn. Similarly, the second
condition requires n ≥ m. Thus, the prerequisite requirement for the inverse, M−1, to
exists is that the matrix must be square (m = n or M : Cn → Cn).
For a square matrix, M, the condition s pan{c1,c2,...,cn} = Cn is equivalent to requiring that the columns of M are linearly independent. However, Theorem 3.3 indicates
that the condition of linearly independent columns is equivalent to ℵ(M) = 0. Thus, in
the case a square matrix, the one condition of linearly independent columns will satisfy
both conditions of the fundamental theorem of linear algebra and guarantee the existence
of a matrix inverse.
While the previous paragraph is sufficient to state the desired result, it will be instructive to also consider ℵ(M) = {0}, or equivalently ℵ(M)⊥ = s pan{r1, r2,..., r n} = Cn.
In this case, we find that linearly independent complex conjugate rows will satisfy this
condition, and thus guarantee uniqueness of a solution to M x = b. However, referring
again to Theorem 3.3 we find that r1, r2,..., r n being linearly independent is equivalent
to ℜ(M) = Cn and guarantee existence of a solution to M x = b, regardless of b. Thus,
we find that linearly independent complex conjugate rows is also enough to guarantee the
existence of a matrix inverse. In fact, it can be shown (see Theorem 3.12) that the number
of linearly independent columns is always equal to the number of linearly independent
complex conjugate rows.
The above discussion is summarized by the following Theorem.
Theorem 3.5. Given a matrix M : Cn → Cn, the following conditions are equivalent.
(i) The inverse of M , M−1, exists and is unique.
(ii) The columns of M are linearly independent.
(iii) ℵ(M) is empty.
(iv) det(M )̸= 0
Condition (iv) is likely the most common condition for the existence of a matrix inverse. To show that det(M)̸= 0 should be part of the list we will show that it is equivalent
to condition (ii). However, the definition of the det(M) must first be provided.
Definition 3.21. The determinant of a matrix M : Cn → Cn, denoted det(M ), is given by
the following formula, where mi j is the matrix element at the ith row and jth column.
det(M) =
n∑i=1
mi j Ci j for any j, or
3.5. Matrix Inverse and the Determinant 83
det(M) =
n∑j=1
mi j Ci j for any i
The terms C
i j are denoted as cofactors and are given by
C
i j = (−1)i+j det(Mi j)
The terms M
i j are denoted as minors and each is equal to the matrix M , with the ith row and
jth column removed. Finally, det(mi j ) = mi j .
It is immediately observed that det(M T ) = det(M) and det(M ∗) = det(M). For the case
of n = 2 and j = 1:
det(M) = m11m22 − m21m12.
For the case of n = 3 and j = 1:
det(M) = m11(m22m33 − m32m23) − m21(m12m33 − m32m13)
+ m31(m12m23 − m22m13)
Since each cofactor will require another determinant calculation, the nested nature of the
procedure indicates that the calculation will quickly become tedious for n larger than 3.
However, for matrices with convenient structures the calculations can be significantly
reduced. For example, consider a matrix of the following block form:
M =  BB11 21 B B12 22  (3.4)
where the submatrices, B11, B12, B21, B22 are of appropriate dimension. If M is block
triangular (i.e., either B12 is a zero matrix or B21 is a zero matrix) then, the following is
easily verified: det(M)=det(B11)det(B22). This result can be extended to the case of a full
triangular matrix (i.e., one with all zeros above and/or below the diagonal). In this case
the determinant is just the product of the diagonal elements. An immediate consequence
being: det(I)=1.
Another convenient property is that the determinate of the product is equal to the
product of the determinants: det(M1M2)=det(M1)det(M2). Of course this requires both
matrices to be square. Using these relations, one finds that det(M −1)=1/det(M) , since
1=det(I)=det(M −1M)=det(M −1)det(M).
Returning to the proof of Theorem 3.5, the following Lemma will be of great utility
Lemma 3.1. Consider a matrix M : Cn → Cn. Then the following hold:
n∑i=1
mi j Ci k = (det 0 (M) if j if j ̸==kk ) and ∑j=n1 mi j Ck j = (det 0 (M) if i if i ̸==kk )
As an illustration, consider the case of n = 3, k = 1 and j = 2. In this case, the
resulting sum
3∑i=1
mi2Ci1 = m12(m22m33 − m32m23) − m22(m12m33 − m32m31)
+ m32(m12m23 − m22m31)
84 Chapter 3. Review of Linear Algebra
is easily shown to be zero.
Proof of Theorem 3.5: Based on the discussion preceding Theorem 3.5, it is concluded
that parts (i), (ii) and (iii) are equivalent. To complete the proof we will need to show
that (ii) and (iv) are equivalent. Essentially, we will need to prove the following two
statements: (1) If det(M)̸= 0, then the columns of M are linearly independent, and (2) If
the columns of M are linearly independent, then det(M)̸= 0. However, it will be more
convenient to show the following equivalent statements: (1a) If the columns of M are
not linearly independent, then det(M)= 0, and (2a) If det(M)= 0, then the columns of
M are not linearly independent. Starting with (1a), assume the columns of M, denoted
c
1,c2,...,cn, are not linearly independent. This implies there exists α1,α2,...,αn such
that c
1 = ∑nj=2 αj cj. This is equivalent to mi1 = ∑nj=2 αj mi j, where where mi j is the
matrix element at the ith row and jth column. Thus,
det(M) =
n∑i=1
mi1Ci1 =
n∑i=1

n∑j=2
αj mi j

Ci
1 =
n∑j=2
αj
n∑i=1
mi jCi1!
Since Lemma 3.1 tells us that ∑n i=1 mi jCi1 = 0 for all j ̸= 1, we conclude that det(M)=0.
To prove (2a), begin by assuming det(M)=0, which implies m11 = −C1
11
∑n
j=2 m1jC1j. If
αj = C1j, j = 1...n, then ∑nj=1 αj cj = 0 is easily verified using ∑nj=1 mi jC1j = 0 if i ̸= 1.
The following Theorem makes good use of Theorem 3.5 and is of independent interest.
Theorem 3.6. If T is invertible, then rank(T M) = rank(M) .
Proof. Let us define rank(M) =∧ r1 and rank(T M) =∧ r2. Then, we must show that r1 = r2.
Let c
i be the columns of M, then T ci are the columns of T M. Now assume r2 < r1,
which requires that for all rearrangements of the columns of T M, there exist non-zero
αi such that ∑ir=1 1 αiT ci = 0. However, this implies that T ∑ir=1 1 αici = 0 and since
T is invertible and does not have a null space, it is concluded that for all rearrangements
of the columns of M, there exist non-zero αi such that ∑ir=1 1 αici = 0, which contradicts
rank(M) = r1. Thus, r2 ≥ r1. Using similar arguments one may establish that r1 ≥ r2.
We are now in a position to define a formula for the calculation of the inverse of a
matrix. This calculation will require the use of the classical adjoint, which should not be
confused with the adjoint given in Definition 3.12.
Definition 3.22. The classical adjoint of a matrix M : Cn → Cn, denoted adj(M ), is given
by the transpose of the matrix of cofactors
adj(M) =

C
11 ··· C1n
...
.
.
.
...
Cn
1 ··· Cnn

T
Using Lemma 3.1, the following Corollary is easily proved.
3.6. Eigenvector Decomposition and Diagonalization 85
Corollary 3.9. The inverse of a matrix, M : Cn → Cn, is M−1 = adj(M)/det(M).
3.6 Eigenvector Decomposition and Diagonalization
The eigenvector decomposition will be central to our understanding of how a linear dynamic system behaves. Most importantly, the associated eigenvalues will characterize the
stability of the system, as will be discussed in Section 4.1.
Definition 3.23. Consider a square linear transformation L : X → X . An eigenvalueeigenvector pair consists of a scalar λ ∈ C and a vector ϕ ∈ X such that Lϕ = λϕ.
If one is given an eigenvalue-eigenvector pair, (λ,ϕ), then by Definition 3.23 one finds
ϕ ∈ ℵ(λI − L). Similar to the definition of the null space, the zero vector cannot be an
eigenvector. It is also customary to normalize the eigenvectors (i.e., [ϕ,ϕ] = 1), although
this is certainly not required. In the case of the linear transformation being a matrix,
M : Cn → Cn, we are looking for the null space of λI − M to not be empty (i.e. the
exists ϕ such that ϕ ∈ ℵ(λI − L)). Theorem 3.5 tells us that this condition is equivalent
to det(λI − M) = 0.
Definition 3.24. Consider a square matrix transformation M : Cn → Cn. Then, the nth
order polynomial ∆(λ) = det(λI − M) = 0 is known as the characteristic equation.
Since the characteristic equation is an nth order polynomial, there should be n eigenvalue-eigenvector pairs, (λj,ϕj), j = 1...n. Furthermore, since an nth order polynomial
may have complex roots, both the eigenvalues and eigenvectors can have complex values,
even if the matrix contains only real elements. However, if the all the elements of the matrix M have real values, then the all the coefficients of the characteristic polynomial will
be real. If a polynomial has real coefficients, then it is well-known that all of its complex
roots must appear as complex conjugate pairs. Thus, if a matrix has real elements, then
its eigenvalues must be real or appear as complex conjugate pairs.
The following three Theorems will be of great utility in Chapter 4.
Theorem 3.7. If a matrix M : Cn → Cn has all real elements, then M and M∗ have the same
eigenvalues.
Proof. If M has all real elements, then
det(λI − M∗) = det(λI − MT ) = det((λI − M)T ) = det((λI − M))
Thus, the characteristic polynomial of M and M∗ = MT are the same and will generate
the same eigenvalues.
Theorem 3.8. Consider a matrix of the following block form:
M =  BB11 21 B B12 22  (3.5)
with submatrices, B11, B12, B21, B22, of appropriate dimension. If M is block triangular (i.e.,
either B
12 is a zero matrix or B21 is a zero matrix), then the eigenvalues of M are equal to the
eigenvalues of B11 combined with those of B22.
86 Chapter 3. Review of Linear Algebra
Proof. If M is block triangular, then det(M) = det(B11)det(B22) and the characteristic
equation is ∆(λ) = det(λI − M) = det(λI − B11)det(λI − B22) = 0
Definition 3.25. If T is invertible, then T MT −1 is denoted as similar to M
Theorem 3.9. Similar matrices have the same eigenvalues
Proof. Consider (λ,ϕ) such that T MT −1ϕ = λϕ. Then, clearly (λ,T −1ϕ) is an eigenvalueeigenvector pair for M.
Example 3.15. Consider the following matrix M : C2 → C2 M =  − −1 2 1 −4 . Then,
the characteristic equation is
0 = ∆(λ) = (λ + 1)(λ + 4) − (−1)(2) = λ2 + 5λ + 6 = (λ + 2)(λ + 3)
Thus, the eigenvalues are λ1(M) = −2 and λ2(M) = −3. Then, ϕ1 is found as the non-zero
(or non-trivial) solution to 0 = (λ1I −M)ϕ1 =  −1 2 1 −2 ϕ1, which is ϕ1 = [2 −1]T .
Similarly, 0 = (λ2I − M)ϕ2 =  −1 1 2 −2 ϕ2, implies ϕ2 = [1 − 1]T .
Example 3.16. Consider a matrix T MT −1, where M =  − −1 2 1 −4  and
T =  −2 1 1 −1 . It is easily verified that T −1 =  −1 1 1 −2 , and thus T MT −1 =
 −03 − −3 2 . Using Theorem 3.8, we conclude that λ1(T MT −1) = −2 and λ2(T MT −1)
= −3. Of course, given Theorem 3.9 it is no surprise that the similar matrices, M and
T MT −1, have the same eigenvalues. It is also not surprising to find that another similar
matrix T MT −1 also has the same eigenvalues. The more interesting point, however, is
the fact that T MT −1 =  −02 0 −3  is diagonal, which can be exploited to achieve a
computational advantage.
Motivated by Example 3.16, let us consider a square matrix transformation M : Cn →
Cn and arrange the eigenvalue-eigenvector pairs (Mϕi = λiϕi) into a matrix form: MΦ =
ΦΛ, where Φ has columns consisting of the eigenvectors, Φ = [ϕ1 ϕ2 ... ϕn], and Λ is a
diagonal matrix with elements consisting of the eigenvalues; Λ = diag{[λ1 λ2 ... λn]}.
Then, the eigenvector decomposition is achieved by simply multiplying both sides by
Φ−1:
M = ΦΛΦ−1 or equivalently Λ = Φ−1MΦ
Given the decomposition M = ΦΛΦ−1, a number of matrix calculations become rather
simple. The following two are easily verified:
Mi = ΦΛiΦ−1, where Λi = diag{(λ1)i (λ2)i ··· (λn)i}
eM = ΦeΛΦ−1, where eΛ = diag{eλ1i eλ2i ··· eλin}
3.6. Eigenvector Decomposition and Diagonalization 87
Of course, this decomposition assumes that the inverse of Φ exists, in which case the
matrix M is said to be diagonalizable. The following theorem, in combination with
Theorem 3.5, gives a sufficient condition for a matrix to be diagonalizable (i.e., Φ−1 exists).
Theorem 3.10. Consider a square matrix transformation M : Cn → Cn, and assume it has
n distinct eigenvalues (i.e., λi ̸= λj for all i ̸= j ). Then, the collection of n eigenvectors is
linearly independent.
Proof. Assume the eigenvectors are not linearly independent. Then we will need to show
that the eigenvalues are not distinct (i.e., there exists i ̸= j such that λi = λj). Denote
the largest number of linearly independent eigenvectors as p. That is, any collection
of p + 1 eigenvectors will be linearly dependent. Since the eigenvectors are not linearly
independent, this p must be such that 1 ≤ p ≤ n. Thus, there exists non-zero αj such
that ∑p+1
j=1 αjϕj = 0. If multiplied by M, one finds ∑p j=+11 αjλjϕj = 0. Multiplying
the first equation by λp+1 and subtracting from the second equation, gives ∑p j=1 αj (λj −
λ
p+1)ϕj = 0. Since this collection of p eigenvectors is linearly independent, αj (λj −λp+1)
must equal zero for all j. Since at least one αj must be non-zero, we conclude that
λ
j = λp+1 for that j. Thus, there exists i ̸= j such that λi = λj, which completes the
proof.
If a matrix does not have distinct eigenvalues, then it is still possible for the matrix
to be diagonalizable. Again, this hinges on the linear independence of the eigenvectors
associated with the repeated eigenvalues. For cases in which the repeated eigenvalues
actually share the same eigenvector, one can construct what is known as the Jordan form,
which is close to a diagonal form. Specifically, M = ΦJΦ−1 (or equivalently J = Φ−1MΦ)
where the columns of Φ are composed of generalized eigenvectors, which are constructed
to be linearly independent. In this case, the matrix J will also have eigenvalues along the
diagonal, but may also have “1” values in the diagonal just above the main diagonal. In
this case, we will again have Mi = ΦJiΦ−1 and eM = ΦeJ Φ−1, but Ji and eJ will be more
difficult to calculate. However, given the particular form of this calculation is far from
tedious.
Example 3.17. (a) Consider a matrix
M =

1 2 −1
0 3 −1
0 0 2

.
Clearly the eigenvalues of M are λ1 = 1, λ2 = 2 and λ3 = 3. In addition it is found that
ϕ1 = [1 0 0]T , ϕ2 = [1 1 1]T and ϕ3 = [1 1 0]T . Thus, one would construct the
eigenvalue decomposition as
Λ =

1 0 0
0 2 0
0 0 3

Φ =

1 1 1
0 1 1
0 1 0

.
A similar result is obtained using the MATLAB function ‘[Phi, Lam] = eig(M)’, which
88 Chapter 3. Review of Linear Algebra
results in:
Lam =

1 0 0
0 3 0
0 0 2

P hi =

1 0.7071 0.5774
0 0.7071 0.5774
0 0 0.5774

.
Although the MATLAB function normalized the eigenvectors and switched the order of
the eigenvalues, the result is the same. In both cases, one can verify that M is equal to
ΦΛΦ−1 and P hi ∗ Lam ∗ inv(P hi).
(b) Now consider the matrix
M =

1 1 0
0 2 0
0 0 2

.
In this case, use of the MATLAB function ‘[Phi, Lam] = eig(M)’, gives
Lam =

1 0 0
0 2 0
0 0 2

P hi =

1 0.7071 0
0 0.7071 0
0 0 1

.
However, since the eigenvalues are not distinct, there is a chance that M may not be diagonalizable. However, since the columns of P hi are linearly independent (i.e., inv(P hi)
exists), these matrices can be used for the eigenvalue decomposition.
(c) Now consider the matrix
M =

1 2 −1
0 3 −1
0 1 1

.
In this case, use of the MATLAB function ‘[Phi, Lam] = eig(M)’, gives
Lam =

1 0 0
0 2 0
0 0 2

P hi =

1 0.5774 0.5774
0 0.5774 0.5774
0 0.5774 0.5774

.
Again, we find repeated eigenvalues, but this time the two eigenvectors are the same.
Thus, the columns of P hi are not linearly independent and inv(P hi) does not exist. To
determine the Jordan form, one may use the MATLAB function ‘[Phi,J]=jordan(M)’,
which gives
J =

1 0 0
0 2 1
0 0 2

P hi =

−1 1 1
0 1 1
0 1 0

.
Clearly, this P hi is invertible and one may easily verify that P hi ∗ J ∗ inv(P hi) is equal
to M.
As a final note, we could have used the function ‘jordan’ in parts (a) and (b) of this
example. In fact, doing so would have resulted in more natural eigenvectors, in that they
would not have been normalized. However, the downside of the function ‘jordan’ is that
the algorithm it uses is based on symbolic manipulations. In contrast, ‘eig’ uses a purely
numeric algorithm, and thus runs much faster, especially for large matrices.
3.6. Eigenvector Decomposition and Diagonalization 89
The following much celebrated Cayley-Hamilton Theorem will be an essential tool
for the developments of Chapter 4.
Theorem 3.11. A matrix M : Cn → Cn satisfies its own characteristic equation. That is, if
∆(λ) = det(λI − M) = λn −an−1λn−1 +···+ a1λ + a0 = 0
then
∆(M) = M n −an−1M n−1 +···+ a1M + a0I = 0n×n
Proof. To simplify the proof, we will additionally assume the matrix M is diagonalizable
(for the full proof please see Chen (1999)). As such, each power of M can be written as
M i = ΦΛiΦ−1. Thus, ∆(M) = Φ∆(Λ)Φ−1, where ∆(Λ) = d ia g{[∆(λ1) ∆(λ2)...∆(λn)]}.
Since each eigenvalue satisfies the characteristic equation, one finds ∆(Λ) = 0n×n, which
leads to ∆(M) = 0n×n and completes the proof.
The utility of the Cayley-Hamilton Theorem is the identity
M n = −
n−1
∑i=0
ai M i.
Thus, any matrix polynomial ρ(M), regardless of degree, can converted to the form of
ρ(M) = bn−1M n−1 +···+ b1M + b0I
Most notably, since eM is just a matrix polynomial, though with infinite degree, it too can
be converted to a polynomial of degree n − 1 . It is also noted that the Cayley-Hamilton
Theorem is particularly useful in calculating the powers of a Jordan form matrix. Specifically, the J i and eJ found in M i = ΦJ iΦ−1 and eM = ΦeJ Φ−1. For the details of these
useful conversions, please see Chen (1999).
In subsequent chapters, the following trace operator will serve to simplify some of
the developed relations.
Definition 3.26. The trace of a square matrix M is defined as the sum of the diagonal elements:
T r{M} =
n∑i=1
mii (3.6)
Among the most useful properties of the trace operator is that the order of matrix
products can be ‘wrapped around’ if within the trace operator. Specifically:
T r{ABC} = T r{BC A} = T r{C AB} (3.7)
Using the (generalized) eigenvector decomposition, one can easily prove the following
two corollaries.
Corollary 3.10. The trace of a matrix is equal to the sum of its eigenvalues:
T r{M} =
n∑i=1
λ
i (3.8)
90 Chapter 3. Review of Linear Algebra
Corollary 3.11. The determinant of a matrix is equal to the product of its eigenvalues:
det(M) =
n∏i=1
λ
i (3.9)
3.7 Non-Square Systems of Equations
In this section, we will focus on relations of the form M x = b, but remove the assumption
of the matrix M being square. We will start with a few technical results that will be
required later in the section. The following corollary is a generalization of a concept that
is commonly encountered in an introductory physics courses.
Corollary 3.12. If ϕ1,ϕ2 ...ϕn is a basis set for X , then all x ∈ X can be represented as a
linear combination of the basis vectors ϕ1,ϕ2 ...ϕn.
Corollary 3.12 states that for all x ∈ X there exists a projection, α = [α1 α2 ... αn]T ,
such that:
x =
n∑i=1
αiϕi (3.10)
If X = Cn and Φ = [ϕ1,ϕ2 ...ϕn], then Equation (3.10) can be written as x = Φα. Since
a set of basis vectors must be linearly independent, it is known that Φ−1 exists and the
projection can be calculated as α = Φ−1x. If the basis set is orthonormal, then Φ−1 = Φ∗,
α = Φ∗x, and the elements of α are calculated as αi = [x,ϕi], assuming the inner product
is defined as in Equation (3.3). This case of using an orthonormal basis is equivalent to
the introductory physics notion of “projecting a vector into unit vector directions”. In
this case of an orthonormal basis set, Equation (3.10) is usually stated as
x =
n∑i=1
[x,ϕi]ϕi (3.11)
If a vector is in the subspace spanned by a subset of the basis vectors, then the projection coefficients associated with the other vectors will be zero. Specifically, if x ∈
s pan{ϕ1,ϕ2 ...ϕm}, m < n, then αi = 0 for i > m. This convenient property will be
used in the proof of the following Lemma.
Lemma 3.2. Consider a matrix, M : Cm → Cn. Then, the following hold
(i) ℜ(MM∗) = ℜ(M)
(ii) ℵ(M∗M) = ℵ(M)
Proof. (i) The range space is defined as the set of vectors y = M x, where x can be any vector in Cm. However, the set of available vectors, x, need not be the entire space Cm. Consider a basis set for the null space of M, along with a basis set its orthogonal complement,
ℵ(M)⊥ = ℜ(M∗). In the notation of Corollary 3.8, these are ℵ(M) = s pan{vr+1,...vm}
and ℜ(M∗) = s pan{v1,...vr}. Then, from Corollary 3.12 we know that for any x ∈ Cm,
there exists α
i such that x = ∑im=1 αi vi. Thus, y = M x = ∑ir=1 αi M vi = M x′ where x′ ∈
ℜ(M∗). Thus, when calculating ℜ(M) , one need only consider vectors x ∈ ℜ(M∗). Since
3.7. Non-Square Systems of Equations 91
the operation x = M ∗y can reach all vectors in ℜ(M ∗), we find that ℜ(MM ∗) = ℜ(M). To
show (ii), begin by observing that x ∈ ℵ(M) implies x ∈ ℵ(M ∗M). Thus, it only remains
to show that x ∈ ℵ(M ∗M) implies x ∈ ℵ(M), which is equivalent to x ∈ ℵ / (M) implies
x ∈ ℵ / (M ∗M). If x ∈ ℵ / (M), then M x ∈ ℜ(M). Since ℜ(M) = ℵ(M ∗)⊥, we observe that
M x ∈ ℵ / (M ∗), which implies x ∈ ℵ / (M ∗M) and completes the proof.
Using Lemma 3.2 we can return to the question of the number of linearly independent columns and rows of a non-square matrix.
Theorem 3.12. For any matrix, M : Cm → Cn, the number of linearly independent columns
is equal to the number of linearly independent complex conjugate rows.
Proof. The statement is equivalent to ‘M and M ∗ have an equal number of linearly independent columns’. From Lemma 3.2, we know that ℜ(M) = ℜ(MM ∗) and ℜ(M ∗) =
ℜ(M ∗M). Thus, the statement is equivalent to ‘MM ∗ and M ∗M have an equal number
of linearly independent columns’. Now, let λ be a non-zero eigenvalue of MM ∗ with
ϕ as the associated eigenvector, which gives: MM ∗ϕ = λϕ. Multiplying by M ∗ results
in M ∗M(M ∗ϕ) = λ(M ∗ϕ), which indicates that M ∗ϕ is an eigenvector of M ∗M with an
eigenvalue of λ. This indicates that MM ∗ and M ∗M have the same non-zero eigenvalues,
and thus have the same number of non-zero eigenvalues. The proof is completed by noting that for a square matrix the number of linearly independent columns is equal to the
number of non-zero eigenvalues.
3.7.1 Least Squares Solutions and the Pseudo-Inverse
We can now return to the subject of a non-square system of equations, M x = b, where
M : Cm → Cn. On the surface, there are two cases. The first is when the number
of equations, n, is greater than the number of variables, m. Such a set of equations is
denoted as overdetermined, and while a solution might exist (if b ∈ ℜ(M)), there are
physically meaningful situations in which no solution exists. If this is the case, then we
will look for a vector xˆ that results in M xˆ being as close as possible to b. The second case
is when the number of equations, n, is less than the number of variables, m. Equations of
this class are denoted as underdetermined, and while the set of solutions might be unique
(if ℵ(M) = {0}), there are physically meaningful situations in which an infinite number
of solutions are possible. If this is the case, then a systemic methodology of selecting
one of these solutions will be desired, and one may also be interested in characterizing all
possible solutions.
s4 s5
s2
s1
s3
Unit 1 Unit 2
Figure 3-3: Simple process flow diagram.
Figure 3.3. Simple process flow diagram.
92 Chapter 3. Review of Linear Algebra
To help illustrate the overdetermined case, consider the flow network of Figure 3.3.
The material balance equations are found to be: s3 + s4 − s5 = 0 and −s1 − s2 − s3 + s5 = 0.
Or equivalently:
0 =  −01  s1 +  −01  s2 +  −11  s3 +  10  s4 +  −11  s5 (3.12)
Let us now suppose that four of these flow rates are measured (s1 = 5, s2 = 7, s3 = 2 and
s
4 = 12) and we would like to calculate s5. In this case, the set of equations to be solved
can be stated as M x = b, where
M =  −11 , x = s5,
and b =  −01  s1 +  −01  s2 +  −11  s3 +  1 0  s4 =  −14 14  (3.13)
Since b ∈ ℜ(M), Theorem 3.1 tells us that a solution will exist, which we trivially find to
be x = 14. Let us now assume there is a bit of error in each of the measurements s
1 = 5.2,
s
2 = 6.9, s3 = 2.1 and s4 = 11.5. In this case, we find that b = [13.6 −14.2]T . Clearly, this
b is not in the range space of M, and thus we should not expect there to be a solution.
As an alternative, we seek xˆ such that M xˆ is as close as possible to b. In particular,
one could form an optimization problem to minimize the quantity (M xˆ − b)∗(M xˆ − b).
Since this scalar quantity is just the inner product of the residual, (M xˆ − b), with itself,
this optimization is frequently denoted as the least squares problem (i.e., minimizing the
sum of the squared errors). Taking the derivative of this sum of squared errors function,
xˆ∗M∗M xˆ − 2xˆ∗M∗b + b∗b, with respect to xˆ, one finds 2M∗M xˆ − 2M∗b. Setting this
derivative equal to zero, one arrives at the following set of relations, known as the normal
equations:
M∗M xˆ = M∗b (3.14)
If the inverse of M∗M exists, then xˆ = (M∗M)−1M∗b. The expression (M∗M)−1M∗ is
known as the Moore-Penrose pseudo-inverse. Of course, the pseudo-inverse will exist
only if the inverse of M∗M exists.
Theorem 3.13. Consider a matrix, M : Cm → Cn. The inverse of M∗M will exist if and
only if M has linearly independent columns.
Proof. From Theorem 3.5 it is known that inverse of M∗M will exist if and only if
ℵ(M∗M) = 0. However, from Lemma 3.2 it is known that ℵ(M∗M) = ℵ(M). Finally,
from Theorem 3.3 it is known that ℵ(M) is empty if and only if M has linearly independent columns.
While the optimization based derivation of the pseudo-inverse is fairly simple, the
following graphical interpretation gives much more insight into the origin of the normal
equations of Equation (3.14). Begin by noting that for all xˆ, M xˆ must be in the range
space of M. In the example above, this is calculated as M xˆ ∈ ℜ(M) = s pan{[1 − 1]T },
which is indicated as the dashed of Figure 3.4. If the vector b is not in the range space of
M, then it will not coincide with this line. Then, the question is to select xˆ such that M xˆ is
as close as possible to b. Based on Figure 3.4, this will be the point such that the residual,
M xˆ − b, is perpendicular to ℜ(M), or equivalently M xˆ − b ∈ ℜ(M)⊥. However, from
3.7. Non-Square Systems of Equations 93
Figure 3.4. Graphical derivation of the normal equations
Theorem 3.2 we know that ℜ(M)⊥ = ℵ(M∗). Thus, xˆ is such that M xˆ − b ∈ ℵ(M∗), or
equivalently the normal equations: M∗(M xˆ− b) = 0. The fact that M xˆ− b is orthogonal
(or normal) to ℜ(M) is the origin of the terminology ‘normal equations’. In Chapter 5
we will find a generalization of the least squares problem and find that similar notions of
orthogonality will provide significant insight into the problem characteristics.
Table 3.1. Test Data for Example 3.18.
Independent Variable t 1 2 3 4 5
Test 1: f (t) 2 7 16 29 46
Test 2: f (t) 2.2 7.5 14.5 30.5 44.5
Example 3.18. Suppose you have collected the data of Table 3.1. It is postulated that the
function f (t) is of quadratic form f (t) = a2t2 +a1t +a0 and the question is to determine
the coefficients a
2, a1 and a0. If we assume f (t) is of quadratic form, then the data of Test
1 can be written in the following matrix form: M x = b1, where
M =

1 1 1
4 2 1
9 3 1
16 4 1
25 5 1

, x =

a
2
a
1
a
0

, and b1 =

27
16
29
46

(3.15)
If by some miracle you select a2 = 2, a1 = −1 and a0 = 1, it can be shown that b1 ∈ ℜ(M).
Of course, selecting these values by inspection is nearly impossible. However, one may
employ the pseudo-inverse:
(M∗M)−1M∗ =

979 225 55
225 55 15
55 15 5

−1
M∗
=

0.143 −0.0714 −0.143 −0.0714 0.143
−1.057 0.3286 0.857 0.5286 −0.657
1.800 0.000 −0.800 −0.600 0.600

94 Chapter 3. Review of Linear Algebra
Then, one would find that
ˆ x
1 = (M ∗M)−1M ∗b1 =

2 −
1
1

If this xˆ
1 is then multiplied by M, then the original b1 would be recovered indicating that
indeed b
1 ∈ ℜ(M). If we now look at Test 2, then the matrix form is M x = b2, where
M is as before and b
2 = [2.2 7.5 14.5 30.5 44.5]T . In this case, application of the
pseudo-inverse yields:
ˆ x
2 = (M ∗M)−1M ∗b2 =

1.886
−0.554
0.760

To illustrate the graphical interpretation, note that:
M xˆ
2 − b2 =

−0.1086
−0.3057
1.5686
−1.7857
0.6314

Then, it is easily verified that M ∗(M xˆ2 − b2) = 0, indicating that M xˆ2 − b2 ∈ ℵ(M ∗). As
a final note, the pseudo-inverse is made possible by the fact that the columns of M are
linearly independent. If this were not the case, then we would find that (M ∗M)−1 does
not exists. In a more practical sense, we would likely be warned by MATLAB that our
matrix M ∗M is ‘close to singular or badly scaled’ and the inversion results are likely to
be inaccurate. If such a warning occurs, then it is likely that the columns of M are not
linearly independent. As an illustration, consider the case of taking only the first 2 data
points of each test, for a total of 4 data points. In this case, M would be defined as
M =

1 1 1
4 2 1
1 1 1
4 2 1

In this case, the columns of M are not linearly independent. This can be verified by trying
to calculate (M ∗M)−1, which will give a close to singular warning. Section 3.7.3 will
discuss how to interpret such a system and how to find a least squares solution. However,
such methods should only be used if one is sure that an appropriate formulation of the
problem has been given. In most cases, this issue of linearly dependent columns is the
result of a flawed formulation of the problem, a typographical error or most likely a bug
in the code used to generate the system of equations.
3.7.2 Non-uniqueness and the Minimum Norm Solution
Now return to the case of an underdetermined set of equations: M x = b (M : Cm → Cn),
where the number of equations, n, is less than the number of variables, m. In this case,
it is likely that there will be an infinite number of solutions and one may be interested
in characterizing all possible solutions. From the fundamental theorem of linear algebra
3.7. Non-Square Systems of Equations 95
(Theorem 3.1), we know that the set of solutions will be non-unique if and only if the
null space of M is not empty (or ℵ(M) ̸= {0}). So, one way to characterize all solutions
is to start with a solution, xˆ, such that M xˆ = b. Then, all x such that M x = b can be
defined as:
x = xˆ +
p∑i=1
αiϕi (3.16)
where α
i are arbitrarily selected scalars and ϕi are basis vectors for the null space, i.e.,
ℵ(M) = s pan{ϕ1,ϕ2,...,ϕp}. The first question one might ask about this characterization is how does one go about finding the first solution xˆ. To develop a procedure, let
us begin by assuming that xˆ is known and that the ϕi vectors are orthonormal. Then,
we can look for α
i values such that the size of x = xˆ + ∑ip=1 αiϕi is as small as possible.
More appropriately, find αi such that the size of the inner product of x with itself (the
square of the norm of x) is as small as possible. Specifically, seek to minimize
f (α1,α1,...,αp) = x∗x = xˆ +
p∑i=1
αiϕi!∗ xˆ + ∑i=p1 αiϕi!
(3.17)
= xˆ∗xˆ + 2
p∑i=1
αiϕ∗i xˆ +
p∑i=1
α2
i
Taking the derivative of this expression with respect to each αi and setting each equal to
zero we find the following relations
0 =
∂ f
∂ α
i
= 2ϕ∗i xˆ + 2αi (3.18)
Thus, the αi’s that minimize Equation (3.17) are those such that αi = −ϕ∗i xˆ for all i =
1 ... p.
If we now turn the problem around and let xˆ be the variable while setting the αi’s
to zero, we find that the smallest x is equal to xˆ (from Equation (3.16) with αi = 0), and
xˆ is characterized as being such that ϕi xˆ = 0. Of course, these relations indicate that xˆ
must be orthogonal to the null space of M, or equivalently xˆ ∈ ℵ(M)⊥ = ℜ(M∗), where
the last equality is from Theorem 3.2. Thus, there must exist a y such that M∗y = xˆ. If
this relation is substituted into the original expression M xˆ = b, we find the dual of the
normal equations: MM∗y = b. If the inverse of MM∗ exists, then y = (MM∗)−1b and
ultimately
xˆ = M∗(MM∗)−1b (3.19)
Note the similarity of (3.19) with the pseudo-inverse. Application of Theorem 3.13 to
M∗ indicates that the inverse of MM∗ will exist if and only if the rows of M are linearly
independent.
To illustrate the minimum norm procedure graphically, let use consider the simplest
case of one equation and two variables. Specifically, let M = [1 1] and b = 1. Then, the
linear variety that characterizes all solutions to M x = b is the dashed line of Figure 3.5,
which is parallel to the null space of M. Then, the smallest vector in the linear variety
is clearly indicated as xˆ, which by inspection should be perpendicular to the null space
(xˆ ∈ ℵ(M)⊥ = ℜ(M∗)), while also satisfying M xˆ = b. Based on Figure 3.5, this point
96 Chapter 3. Review of Linear Algebra
!
N(M)
Mx=b
Figure 3-5 Figure 3.5. : Graphical interpretation of the minimum norm point Graphical interpretation of the minimum norm point
should be xˆ = [0.5 0.5]T , which is verified by the minimum norm calculation:
xˆ = M∗(MM∗)−1b =  1 1 [1 1] 1 1 −1 [1] =  0 0..5 5  (3.20)
Since the null space of M is found to be the span of [−1 1]T , we find that the set of all
solutions is characterized as:
x =  0 0..5 5  + α −11  (3.21)
where α can be any number.
Example 3.19. Consider a set of differential equations: ˙s = As + B m + G p, where
A=  −1 0 1 0 , B =  1 0 1 −1  and G =  −01  (3.22)
Suppose pSSOP is given to be 3 and we would like to characterize all possible steady-state
conditions (sSSOP, mSSOP), i.e., such that 0 = AsSSOP + B mSSOP + G pSSOP. This can be
restated as: find all x such M x = b, where
M =  −1 0 1 0 1 0 1 −1 , x =  msSSOP SSOP  and b =  03  (3.23)
Since the rows of M are clearly linearly independent, we can use Equation (3.19) to find
xˆ = M∗(MM∗)−1b =

−1 1
0 0
1 1
0 −1

 2 0 0 3 −1  0 3 
=

−1/2 1/3
0 0
1/2 1/3
0 −1/3

 0 3  =

101 −
1

(3.24)
3.7. Non-Square Systems of Equations 97
By inspection one may conclude that the following vectors are in the null space of M:
[0 1 0 0]T and [1 0 1 2]T . Thus, the set of all solutions is found to be
x =  msSSOP SSOP  =

101 −
1

+ α1

0100

+ α2

1012

(3.25)
An alternative approach to solving Example 3.19 is to rearrange the steady-state relation 0 = AsSSOP + B mSSOP + G pSSOP to be mSSOP = −B−1(AsSSOP + G pSSOP ) and
find
mSSOP =  1 0 2 0  sSSOP −  0 3 
Then, if sSSOP is defined as sSSOP = [α1 α2]T , one can conclude that
x =  msSSOP SSOP  =

000 −3

+ α1

1012

+ α2

0100

(3.26)
While this approach appears to be simpler, it requires the inverse of B to exist. We did
not even attempt to solve for sSSOP =? −A−1(B mSSOP + G pSSOP ), since the inverse of
A clearly does not exist. If B was defined as B =  1 1 − −1 1 , then its inverse would
not exist either, and the above ‘intuitive’ approach would require the use of column 1
from A and either column from B to arrive at linearly independent columns and thus an
invertible matrix. In the general case, where there may be many large columns to choose
from, the selection of appropriate columns to create an invertible matrix is likely to be
a process of trial and error. In contrast, the generalized method of Equation (3.16), with
xˆ defined by Equation (3.19), can be completely automated. The only challenge is to
identify a basis set for the null space of M. However, the singular value decomposition
along with Corollary 3.8 can always be used to find such a basis set. Using the MATLAB
function ‘[U,S,V]=svd(M)’ and noting from the resulting S that the rank of M is 2, we
conclude that the null space of M is spanned by columns 3 and 4 of V . Using these
columns, the characterization of all solutions would be stated as:
x =  msSSOP SSOP  =

101 −
1

+ α1

0.2357
−0.8165
0.2357
0.4714

+ α2

0.3333
0.5773
0.3333
0.6667

(3.27)
While this characterization has less intuitive appeal as compared to Equations (3.25) or
(3.26), it is exactly equivalent and can be completely automated using MATLAB. The
next subsection will illustrate the utility (and in some case the necessity) of the singular
value decomposition in solving a set of linear equations.
3.7.3 Singular Value Decomposition and Solutions to Mx = b
In this subsection, we will begin by illustrating how the singular value decomposition
can be used to reduce the computational effort of calculating both the pseudo-inverse and
98 Chapter 3. Review of Linear Algebra
the minimum norm solution. It will be concluded by showing that appropriate solutions
to M x = b can be found regardless of rank if given the singular value decomposition.
However, first we will introduce a bit of terminology. In Section 3.7.1, it was noted
that the pseudo-inverse will exist if and only if the matrix M : Cm → Cn is such that its
m columns are linearly independent. A more technical way of stating the condition of
linearly independent columns is that the rank of M is equal to m. Such a matrix will be
denoted as having full column rank. In Section 3.7.2, it was found that the minimum
norm solution will exist if and only if its n rows are linearly independent, or its rank is
equal to n. Such a matrix will be denoted as having full row rank. Alternatively, we can
combine the above two definitions to arrive at the following generalization that works
for all square and non-square matrices:
Definition 3.27. A matrix M : Cm → Cn is denoted as full rank if rank(M ) = min(n, m).
If m < n, then the condition of full rank is equal to full column rank and is sufficient
for the existence of the pseudo-inverse. In addition, if n < m, then full rank is the same
as full row rank and will guarantee the existence of a minimum norm solution. In fact, if
n = m , then the condition of full rank indicates that the regular inverse will exist (recall
Theorem 3.5).
With the full rank terminology in hand, recall the singular value decomposition of
Definition 3.20: M = U SV ∗, where S is of the form  Σ0 00  and Σ is a square diagonal
matrix with dimension r = rank(M) and only non-zero values on the diagonal. In
addition, both U and V are unitary and based on Corollary 3.8 have the form of U =
[U1 U2] and V = [V1 V2], where ℜ(M) = s pan{U1}, ℵ(M∗) = s pan{U2}, ℜ(M∗) =
s pan{V1} and ℵ(M) = s pan{V2}.
Let us begin with the overdetermined case: M : Cm → Cn and the number of columns
is less than the number of rows (m < n). If M is full column rank (i.e., ℵ(M) = {0}), then
S will be of the form  Σ0  and M = U1ΣV ∗. Substituting this decomposition into the
pseudo-inverse, one finds:
(M∗M)−1M∗ = (V ΣU1∗U1ΣV ∗)−1V ΣU1∗
(3.28)
= (V Σ2V ∗)−1V ΣU1∗ = V Σ−2V ∗V ΣU1∗ = V Σ−1U1∗
Since ℵ(M) = 0 the resulting least squares solution (which may actually be a solution,
depending on the value of b) will be unique. The one questionable part of Equation (3.28)
is that U∗
1 U1 = I. You should be able to convince yourself this is true by considering the
example of U equal to a 3×3 identity matrix and r = 2. Then, evaluate U∗U and UU∗,
both of which will be equal to identity but will get there in a different ways.
Now consider the underdetermined case: M : Cm → Cn and the number of rows is
less than the number of columns (n < m). If M is full row rank (i.e., ℜ(M) = Cn), then
S will of the form [Σ 0] and M = UΣV1∗. Substituting this decomposition into the
minimum norm matrix of Equation 3.19, one finds:
M∗(MM∗)−1 = V1ΣU∗(UΣV1∗V1ΣU∗)−1
(3.29)
= V
1ΣU∗(UΣ2U∗)−1 = V1ΣU∗UΣ−2U∗ = V1Σ−1U∗
Similar to Equation (3.28), the one questionable part of Equation (3.29) is that V1∗V1 = I,
which you should be able to convince yourself is true. It is noted, that since ℜ(M) = Cn
3.7. Non-Square Systems of Equations 99
there will always be at least one solution to M x = b. However, given that n < m and
the number of linearly independent columns must be equal to the number of linearly
independent rows (recall Theorem 3.12), we know that ℵ(M) = s pan{V2} ̸= {0}, and we
can be confident that this solution will not be unique.
At this point, it will be helpful to review the cases we have considered in the context of
the fundamental theorem of linear algebra (Theorem 3.1). If we consider only the matrix
M : Cm → Cn (i.e., exclude the impact of the b vector), then there are four possible cases.
1) The first case is when ℜ{M} = Cn and ℵ(M) = {0}. As discussed is Section 3.5,
such a situation is only possible if M is square and full rank. In this case, the inverse
of M will exist and the solution will be unique.
2) If ℜ{M} ̸= Cn and ℵ(M) = {0}, then the set of equation must be overdetermined
(m < n) and M must be full (column) rank. In this case, a solution may not
exist, but we will always be able to calculate a least squares solution, using the
pseudo-inverse or Equation (3.28). In either case, the result will be unique, since
the pseudo-inverse matrix will be unique.
3) If ℜ{M} = Cn and ℵ(M) ̸= {0}, then the set of equation must be underdetermined
(n < m) and M must be full (row) rank. In this case, an infinite number of solutions will always exist and we can always find the minimum norm solution using
Equations (3.19) or (3.29).
4) If ℜ{M} ̸= Cn and ℵ(M) ̸= {0}, then we have the worst of both worlds - the solution may not exist and it (or the least squares solution) will not be unique. This
type of situation can occur for square, underdetermined and overdetermined systems. The following theorem can be applied to all three cases.
Theorem 3.14. Consider a non-full rank matrix, M : Cm → Cn (i.e., ℜ{M} ̸= Cn and
ℵ(M) ̸= {0}). Then, the following hold
(i) The set of all possible least squares solutions to M x = b can be characterized as xˆ =
V1
Σ−1U∗
1 b +V2α2, where α2 = [α(r+1) α(r+2) ... α(n)]T is arbitrarily selected and r
is the rank of M .
(ii) The minimum norm element, selected from the infinite set of least squares solutions, is
found to be xˆ ˆ = V1Σ−1U1∗b (i.e., when α2 = 0).
Proof. (i) The approach is to define α = V ∗x and find the least squares solution with
respect to α. Then, the appropriate xˆ can be determined from x = V α, since V = (V ∗)−1.
Since M is not full rank, S must be of the form  Σ0 00  and M = U1ΣV1∗. Using this
along with x = V α, it is found that:
M x = U
1ΣV1∗V α = U1ΣV1∗[V1 V2] αα12 
= U
1Σ[V1∗V1 V1∗V2] α α1 2  = U1Σ[I 0] αα12  = U1Σα1
Thus, we are left with an overdetermined system U1Σα1 = b. However, since U1Σ is full
(column) rank, the unique least squares solution is found to be α1 = Σ−1U1∗b. Since α2 is
100 Chapter 3. Review of Linear Algebra
unspecified we conclude that
α =  α α12  =  Σ−1αU2 1∗b  and xˆ = V  Σ−1αU2 1∗b  = V1Σ−1U1∗b +V2α2
To verify that this xˆ is indeed the least squares solution, let us verify that the residual,
M xˆ − b, is indeed in the null space of M∗. First, note that the residual is:
M xˆ − b = U
1ΣV1∗(V1Σ−1U1∗b +V2α2) − b
= U
1U1∗b + U1ΣV1∗V2α2 − b = (U1U1∗ − I)b
Then, we find that M∗(M xˆ−b) = V1ΣU1∗(U1U1∗−I)b = (V1ΣU1∗U1U1∗−V1ΣU1∗)b = 0.
(ii) To find the minimum norm element, form the scalar function
f (α2) = xˆ∗xˆ = (V1Σ−1U1∗b +V2α2)∗(V1Σ−1U1∗b +V2α2)
= b∗U
1Σ−1V1∗V1Σ−1U1∗b + α2∗V2∗V2α2
= b∗U
1Σ−2U1∗b + α2∗α2
Thus, the minimum value of f (α2) is obviously achieved at α2 = 0 , which completes the
proof.
To help understand Theorem 3.14, let us think about the various cases. If the system
is overdetermined and full (column) rank, then ℵ(M) = 0 and the (least squares) solution
will be unique. If the full rank assumption is removed (ℵ(M) ̸= 0), then it is natural to
conclude that there will be an infinite number of least squares solutions. If the system
is square, then the logic is similar. The main difference is that a square matrix must be
either case 1 (ℜ(M) = Cn and ℵ(M) = 0) or case 4 (ℜ(M) ̸= Cn and ℵ(M) ̸= 0). If the
system is underdetermined, then the logic is bit strange. If it is full (row) rank, then
ℜ(M) = Cn and we are guaranteed an infinite number of solutions. However, if the full
rank assumption is removed (ℜ(M) ̸= Cn), then it may be that none of these infinite
solutions exist. The remedy is to find the infinite least squares solutions. While this may
seem confusing, it is just the steps of the overdetermined case, but in the reverse order.
The good news is that Theorem 3.14 covers all three cases. In fact, Theorem 3.14 can be
used to address all cases regardless of rank. To generalize Theorem 3.14 just apply the
following: (1) if ℜ(M) = Cn, then U1 = U and U2 = 0 and (2) if ℵ(M) = 0, then V1 = V
and V
2 = 0. Using these along with Theorem 3.14, the results of Equations (3.28) and
(3.29) can be recovered. In addition, for a square matrix, M = U SV ∗, it is easily verified
that M−1 = V S−1U∗ if M (or equivalently S) is full rank.
Example 3.20. Consider a system of equations M x = b where:
M =  10 2 0 5 1 0  and b =  12 6 
By inspection, we see that one possible solution is x = [1 1 1]T . Using the singular value
decomposition results of Example 3.13, it is concluded that Σ = 11.4,
U1
=  − −0 0..4472 8944 , U2 =  −00.4472 .8944 ,
V1
=

0.9806
−0.1961
0

and V
2 =

−0.1961 0
0.9806 0
0 1

3.8. Positive Definite Transformations 101
Since U
2 ̸= 0 and V2 ̸= 0, we know that ℜ(M) ̸= C2 and ℵ(M) ̸= {0}. Thus, Theorem
3.14 should be applied to find the minimum norm least squares solution:
xˆ ˆ = V
1Σ−1U1∗b =

0.9806
−0.1961
0

111.4[−0.4471 − 0.8944] 12 6 
=

1.1538
0.2307
0

This is clearly different than the ‘by inspection’ solution x = [1 1 1]T . However, we do
find that M xˆ ˆ does equal b. Thus, we have at least two solutions. The set of all solutions
is given by:
xˆ = V
1Σ−1U1∗b +V2α2 =

1.1538
0.2307
0

+ α(2)

−0.1961
0.9806
0

+ α(3)

001

If α(2) is selected to be 0.7845 and α(3) is 1, then we find that xˆ = [1 1 1]T , which
aligns with our ‘by inspection’ solution. Strictly speaking none of these are least squares
solutions, since each is actually a solution (thought one could argue that a solution is a
least squares with a zero residual). If one were to select a b such that b ∈ ℜ / (M), then all
would be proper least squares solutions.
3.8 Positive Definite Transformations
If x is a complex scalar (i.e., x ∈ C1), then the function f (x) = p xx(∈ R1) is positive
for any positive value of p. In this subsection, such a notion is generalized through
the definition of a positive definite transformation. These transformations are actually a
subset of the class of self-adjoint transformations, which have properties of independent
interest.
Definition 3.28. A linear transformation L : X → X is self-adjoint if L∗ = L.
Theorem 3.15. A self-adjoint linear transformation, L, has real eigenvalues and its eigenvectors are orthogonal.
Proof. Let (λ,ϕ) be any eigenvalue-eigenvector pair of L. If L = L∗, then Lϕ = L∗ϕ and
[Lϕ,ϕ] = [L∗ϕ,ϕ]. Then, the definition of adjoint indicates that [Lϕ,ϕ] = [ϕ,Lϕ].
Since (λ,ϕ) is an eigenvalue-eigenvector pair, we find that [λϕ,ϕ] = [ϕ,λϕ]. This implies λ[ϕ,ϕ] = λ[ϕ,ϕ] and finally (λ − λ)[ϕ,ϕ] = 0. Since an eigenvector cannot be
the zero vector, it must be concluded that (λ − λ) = 2j Im{λ} = 0, where Im{} denotes
the imaginary part of λ. Thus, λ must be real. To prove that the eigenvectors are orthogonal, let us further assume the eigenvalues are distinct. Let (λ1,ϕ1) and (λ2,ϕ2) be two
eigenvalue-eigenvector pairs. Then, [Lϕ1,ϕ2] = [ϕ1,L∗ϕ2] = [ϕ1,Lϕ2], which implies
λ
1[ϕ1,ϕ2] = λ2[ϕ1,ϕ2] and leads to (λ1 − λ2)[ϕ1,ϕ2] = 0. Since the eigenvalues are
assumed distinct the only possible conclusion is that [ϕ1,ϕ2] = 0. Graham and Rawlings
[114] provide a proof without the assumption of distinct eigenvalues, but only for the
case of matrix transformations.
102 Chapter 3. Review of Linear Algebra
Corollary 3.13. A self-adjoint matrix is diagonalizable.
Corollary 3.13 is based on the fact that orthogonal eigenvectors are also linearly independent (Theorem 3.4), which guarantees that the matrix Φ = [ϕ1 ϕ2 ... ϕn] will have
an inverse. If the eigenvectors are normalized (i.e., defined such that [ϕj,ϕj ] = 1), then
Φ will additionally be unitary (i.e., Φ−1 = Φ∗).
Now that we know that all of the eigenvalues of a self-adjoint matrix are real, let
us further consider the cases of all eigenvalues having the same sign. These notions are
captured by the following definition and subsequent Theorem.
Definition 3.29. A linear transformation P : X → X is
(i) positive definite (P > 0), if P∗ = P and [P x, x] > 0 for all nonzero x ∈ X .
(ii) positive semi-definite (P ≥ 0), if P∗ = P and [P x, x] ≥ 0 for all nonzero x ∈ X .
(iii) negative definite (P < 0) if −P > 0.
(iv) negative semi-definite (P ≤ 0) if −P ≥ 0.
It should be emphasized that a positive definite matrix does not imply or require that
all of the elements of the matrix are positive. The following theorem provides the actual
criteria for a transformation to be positive definite.
Theorem 3.16. P = P∗ is positive definite if and only if P has positive eigenvalues.
Proof. We will need to prove two statements: (1) If P > 0, then P has positive eigenvalues,
and (2) If P = P∗ has positive eigenvalues, then P > 0. (Statement (1) is known as the
“only if direction” and statement (2) is known as the “if direction”.)
Only if direction: Assume P is positive definite and let λ ∈ R and ϕ ∈ X be an
eigenvalue-eigenvector pair. Since [P x, x] > 0 for all x ∈ X and Pϕ = λϕ, one finds that
[Pϕ,ϕ] = [λϕ,ϕ] = λ[ϕ,ϕ] > 0. Since ϕ cannot be the zero vector, it must be that
λ > 0.
If direction: To simplify the proof, let us additionally assume P is a matrix (i.e., X =
Cn). Assume all eigenvalues of P are positive. This combined with the P being self
adjoint indicates that P = ΦΛΦ∗ where Λ is a diagonal matrix containing the positive
eigenvalues and the columns of Φ contain the orthonormal eigenvectors. Then, for any
x ∈ Cn, one finds:
[P x, x] = [(ΦΛΦ∗)x, x] = [ΛΦ∗x,Φ∗x] = [Λα,α] =
n∑i=1
λ
iα2i > 0
where α = Φ∗x. Since λ
i > 0 for all i, the only conclusion is that [P x, x] > 0.
In the case of a positive semi-definite transformation, the only distinction is that zero
eigenvalues are allowed. That is, P = P∗ is positive semi-definite if and only if it has
non-negative eigenvalues. In this case, the null space of P can be non-empty.
Corollary 3.14. If P > 0, then L∗PL > 0 if ℵ(L) is empty. Otherwise, L∗PL ≥ 0 .
Example 3.21. Consider the matrices of Table 3.2. Since all are symmetric, all have real
3.9. Chapter Summary 103
eigenvalues. Cases 1 and 2 are positive definite and Case 3 is positive semi-definite. Case
6 is negative definite and Cases 4 and 5 have no definiteness properties.
Table 3.2. Symmetric Matrices and Associated Eigenvalues for Example 3.21.
Case 1 2 3
Matrix

2 1
1 2


2 −1
−1 2


2 1
1 0.5

Eigenvalues
λ
1 = 1.0
λ
2 = 3.0
λ
1 = 1.0
λ
2 = 3.0
λ
1 = 0
λ
2 = 2.5
Case 4 5 6
Matrix

2 1
1 0.25


2 1
1 −2


−2 1
1 −2

Eigenvalues
λ
1 = −0.204
λ
2 = 2.454
λ
1 = −2.24
λ
2 = 2.24
λ
1 = −1
λ
2 = −3
In the case of n = 2 and P having elements pi j, positive definiteness is guaranteed by
the following conditions p11 > 0, p22 > 0 and p11 p22 − p12 p21 > 0. The conditions for
positive semi-definiteness are the same but with the strict inequalities replaced by regular
inequalities. This method can be applied to the matrices of Example 3.21, to arrive at
the same conclusions. Unfortunately, this simple rule does not generalize well for n > 2.
In some cases, we will find it convenient to split a positive semi-definite matrix into
two roots. The following definition indicates one approach to doing so.
Definition 3.30. Consider a positive semi-definite matrix P, then a principal square root
of P is a positive semi-definite matrix defined as P1/2 = ΦΛ1/2Φ−1, where Φ and Λ are from
the eigenvalue-eigenvector decomposition of P.
3.9 Chapter Summary
In this chapter we have focused on three main topics, all related to linear transformations: L : X → Y. The first concerns the solution to a linear equation Lx = b. The
Fundamental Theorem of Linear Algebra indicates that the existence and uniqueness of a
solution can be determined by the characteristics of the range and null space of the operator L. Then, for the case of matrix transformation we have described methods that can
be used to calculate both of these subspaces. In Chapter 4, the Fundamental Theorem
will be used to derive conditions for some the most basic properties desired by a dynamic
system - controllability and observability.
The second major topic of the chapter concerns matrix polynomial calculations, including the matrix exponential. In this case, it was found that the eigenvector decomposition could be used to greatly simplify these calculations by converting general matrix
powers into powers of a diagonal matrix. It was also shown that the Cayley-Hamilton
104 Chapter 3. Review of Linear Algebra
Theorem could be used to achieve similar ends. In Chapter 4, the eigenvector decomposition will be used to derive another fundamental property of a controlled system -
stability - and the Cayley-Hamilton Theorem will serve as an important theoretical tool
in the advanced topic of connecting stability to controllability and observability.
The final main topic of the chapter concerns positive definite matrices. While this
topic appears to be just a generalization parabolas, we will see that matrix inequalities
are among the most powerful tools we have available for the analysis and design of linear
control systems. As such, the reader should expect to see this topic appear in some form
or another in all subsequent chapters. In particular, these concepts will be core to the
economic based design and analysis methods to be discussed in Part III of the book.
As one might expect, much of the material presented in this chapter can be found in
other texts, see for example Luenburger [111], Akhiezer and Glazman [112], Debnath
and Mikusinski [113]and Graham and Rawlings [114]. Many of the proofs provided in
this chapter can also be found in Grossman [115], Balakrishnan [116], Chen [117] and
Anton [118].
Exercises
3.1. Consider a set of two differential equations in state-space form: x˙ = Ax, with the
initial conditions x(0) = xo. Prove the following:
“If we are allowed to choose the initial conditions arbitrarily (i.e., xo can be selected as any value in ℜ2), then the set of functions defined by y(t) = C x(t), where C
has 1 row and 2 columns, is a linear vector space.”
(Hint: Assume eAt is a matrix of the form aa1 3( (t t) ) a a2 4( (t t) ), where the ai(t) functions are known.)
3.2. For the linear transformations: M : X → Y in Table 3.3, determine (i) X, (ii) Y,
(iii) If the range space is the entire space (iv) If the null space is empty. You should
not need to use a computer for these determinations.
3.3. For the linear transformations: M : X → Y in Table 3.4, determine (i) the range
space, (ii) the null space. Your answers should be either X, Y “empty” or make
use of the “span” operator.
3.4. Reconsider the inner product defined in Example 3.3:
[x,y]p = yT P x where P = −11 4 −1
For each of the following vectors find a vector that is orthogonal under this inner
product:
x
1 = 1 1 x2 = −11 x3 = 0 1
For each case, sketch the pair of orthogonal vectors and show that they do not
conform to our usual understanding of being at a right angle, which would be the
case if the inner product was defined as in Equation 3.3 (i.e., with P = I).
Exercises 105
Table 3.3. Table for Exercise 3.2.
X =? Y =? ℜ(M) =? Y ℵ(M) =? {0}
(a)

1 0
0 1
2 2
0 2

Yes or No Yes or No
(b)

1 1 1 1
1 1 1 2

Yes or No Yes or No
(c)

1 2
3 4

Yes or No Yes or No
(d)

1 0 1
1 −1 0
0 1 1

Yes or No Yes or No
(e)

0 1
2 2
1 0
0 2

Yes or No Yes or No
(f)

1 0 1
1 1 0
0 1 −1

Yes or No Yes or No
(g)

1 2 1 1
1 2 1 2

Yes or No Yes or No
3.5. Consider a linear operator M : X → Y defined by the matrix
M =

1 1
0 1
1 0

(i) Determine the spaces X and Y
(ii) Determine the range space of M : ℜ(M) = {y ∈ Y such that y = M x where
x ∈ X}
(iii) Determine the null space of M∗ : ℵ(M∗) = {y ∈ Y such that M∗y = 0}
(iv) Determine a vector b such that a solution to M x = b exist. Verify this using
the null space of M∗. (Your verification must use the ℵ(M∗))
(v) Determine a vector b such that a solution to M x = b does NOT exist. Verify
this using the null space of M∗. (Your verification must use the ℵ(M∗))
106 Chapter 3. Review of Linear Algebra
Table 3.4. Table for Exercise 3.3.
ℜ(M) =?? ℵ(M) =??
M =

1 −1 0 0
0 0 −1 1

M =

1 0 0
0 2 0
0 0 0

M =

1 0
0 1
1 0

3.6. Find the four fundamental subspaces of the following matrices. (Do this by hand.
Then verify your results with the MATLAB commands “null” and “orth”.)
(i) M = −42 1 −2 (ii) M = 2 1 − −12 3 −1
(iii) M =

5 1
3 4
1 2

(iv) M =

5 0 1
0 5 −7
1 −7 10

3.7. Prove part (ii) of Theorem 3.2
3.8. (i) Using the Gram-Schmidt procedure, orthogonalize the following vectors
ϕ1 =

110

ϕ2 =

022

ϕ3 =

200

(ii) Using the Gram-Schmidt procedure, orthogonalize the following vectors
ϕ1 =

110

ϕ2 =

022

ϕ3 =

132

(iii) Using the Gram-Schmidt procedure, orthogonalize the following vectors
ϕ1 =

110

ϕ2 =

022

ϕ3 =

030

(iv) How is the null space of M = 1 1 0 0 2 2 related to the solution of part (i)?
3.9. Consider the following set of vectors:
ϕ1 =

100

ϕ2 =

111

ϕ3 =

1 −
1
−1

Exercises 107
(i) Use Gram-Schmidt to determine an orthonormal basis for s pan{ϕ1,ϕ2,ϕ3}.
(ii) What is the dimension of s pan{ϕ1,ϕ2,ϕ3}?
3.10. Consider a set of algebraic equations M x = b where
M =

0 1 2 0
1 0 0 0
2 0 0 1
0 0 0 1

The Singular Value Decomposition of M is M = U SV ∗ where
U =

0 1 0 0
−0.365 0 −0.447 0.816
−0.913 0 0 −0.408
−0.183 0 0.894 0.408

S =

2.45 0 0 0
0 2.24 0 0
0 0 1 0
0 0 0 0

V =

−0.894 0 −0.447 0
0 0.447 0 0.894
0 0.894 0 −0.447
−0.447 0 0.894 0

For which of the following b vectors will a solution to M x = b exist?
(a) b =

1000

(b) b =

1121

(c) b =

0102

(d) b =

1
0.5
0 −
1

3.11. Show that the U and V matrices of Exercise 3.10 are unitary.
3.12. Prove Corollary 3.9.
3.13. Consider the following matrix and three vectors.
M =

2 −2 2
−1 1 1
1 −1 3

u
1 =

011

u
2 =

110

u
3 =

1 −
1
7

(i) Are any of these vectors in the Null Space of M?
(ii) Are any of these vectors eigenvectors of M?
(iii) Are any of these vectors in the Range Space of MT ?
3.14. Use Definition 2.3 show the following:
(i) If D =

λ
1 0 0 0
0 λ
2 0 0
0 0
.
.
. 0
0 0 0 λ
n

, then eDt =

eλ1t 0 0 0
0 eλ2t 0 0
0 0
.
.
. 0
0 0 0 eλn t

(ii) If A= ΦDΦ−1, then eAt = ΦeDtΦ−1
108 Chapter 3. Review of Linear Algebra
3.15. Consider a set of algebraic equations M x = b where
M =

−1 1 0 −1
1 −1 1 0
0 1 −1 1
−1 0 1 0

b =

1010

An eigenvector decomposition of M is MΦ = ΦΛ where
Φ =

0.5 −0.577 −0.5 0.408
−0.707 0 −0.707 0
0.5 0.577 −0.5 −0.408
0 −0.577 0 −0.817

Λ =

−2.414 0 0 0
0 −2 0 0
0 0 0.414 0
0 0 0 1

(i) Show that the matrix Φ is unitary. Is there a way you could have known this
without doing any calculations?
(ii) Determine if a solution to M x = b will exist.
(iii) If a solution exists, calculate such a solution without the aid of a computer.
(iv) Is this the only solution?
3.16. Prove Corollaries 3.10 and 3.11.
3.17. Consider a set of algebraic equations M x = b where
M =

1 −0.778 −1.222
0 0.889 −0.889
−1 −0.111 2.111

The singular value decomposition of M is M = U SV ∗ where
U =

−0.540 0.613 0.577
−0.260 −0.774 0.577
0.800 0.161 0.577

S =

2.91 0 0
0 1.30 0
0 0 0

V =

−0.461 0.348 −0.816
0.034 −0.912 −0.408
0.887 0.216 −0.408

(i) Based on this decomposition, show that if an exact solution to M x = b
exists, then it will not be unique.
(ii) Determine any value for the vector b such that a solution to M x = b will
exist?
(iii) What is the set of all b such that a solution to M x = b will exist?
(iv) For the b of part (ii), determine a solution to M x = b.
Exercises 109
(v) Using the b of part (ii), determine all solutions to M x = b. Rather than perform the calculations, based on the above numbers, please use the notation
below to develop a formula for the solution.
U = [u1 u2 u3] S =

σ
1 0 0
0 σ
2 0
0 0 0

V = [v1 v2 v3]
where u
i and vi are the columns of U and V .
3.18. Consider a set of algebraic equations M x = b
where M =

1 1
2 4
−1 1

and b =

0 −2 −2

(i) Determine if a solution to this problem exists.
(ii) If a solution exists, determine that solution. If a solution does not exist,
determine the least squares solution.
(iii) Repeat parts (i) and (ii) using b = [2 5 0]T .
(iv) Determine an orthonormal basis set for ℜ(M).
3.19. Consider a linear operator M : X → Y defined by the matrix
M =

0.48 0.64
−0.40 0.30
0.36 0.48

The singular value decomposition of M is M = U SV ∗ where
U =

0.8 0 0.6
0 1 0
0.6 0 −0.8

S =

1 0
0 0.5
0 0

V = 0 0..6 8 0 −0.6.8
(i) Determine the pseudo-inverse operator associated with the least squares solution.
(ii) If b =

111

, determine the least squares solution to M x = b.
3.20. Determine the definiteness (either positive definite, positive semi-definite, negative
definite, negative semi-definite or none of the above) for the following matrices:
(Feel free to use any MATLAB commands)
(i) P = −42 1 −2 (ii) P = −42 − −2 1 (iii) P = −24 2 −1
(iv) P =

5 1
3 4
1 2

(v) P =

5 0 1
0 5 −7
1 −7 10

(vi) P =

5 0 1
0 5 −7
1 −7 12

3.21. In Corollary 3.6 it was stated that the adjoint of a matrix M is found to be M∗ =
M
T
, if the inner product is defined by Equation 3.3.
(i) Prove Corollary 3.6
110 Chapter 3. Review of Linear Algebra
(ii) If the inner product is defined as [x,y]p = yT P x, where P is a positive
definite matrix, show that the adjoint of a matrix M is M ∗ = P−1M T P
(iii) Verify that Theorem 3.2 holds true if [x,y]p = yT P x where P = −11 4 −1
and M = 10 2 0 5 1 0
3.22. Consider the manufacturing process given in section 2.6.4. The process model is
sk+1 = Ad sk + Bd mk + Gd pk, where the system matrices are
A
d =

1 1 0 0 0 0
0 0 1 0 0 0
0 0 0 1 0 0
0 0 0 0 0 0
0 0 0 0 1 0
0 0 0 0 0 1

B
d =

0 −1 −1 0 0
0 0 0 0 0
0 0 0 0 0
1 0 0 0 0
0 1 0 1 0
0 0 1 0 1

Gd =

0 0
0 0
0 0
0 0
−1 0
0 −1

The steady-state value of the disturbance, ps s o p, is given to be 200 100∗. Determine all the steady-state condition (s s s o p, ms s o p). (Hint: feel free to use the
MATLAB function ‘svd’ to find the null space that is needed.)
Part II
Modern Control Theory
Chapter 4
Linear System Theory
In Chapter 2 it was shown that the method of linearization can be used to approximate
the dynamics of a nonlinear state-space process. The resulting linear model (in combination with the tools of linear algebra) can then be used to characterize the abilities of
the process. Specifically, one would like to know answers to the following questions:
How well will the system respond to feedback? Do the process measurements provide
sufficient information? This chapter will address these questions by introducing the concepts of stability, controllability, and observability and will focus on presenting tests to
determine if a given system possesses these properties. Most importantly, the chapter
will address the question of the existence of a feedback element capable of yielding a stable closed-loop system by introducing the concepts of stabilizability and detectability. If
a given process does not possess these most basic criteria, then one will know that it is
futile to attempt to design a controller and the only remaining option is to redesign of
the open-loop process such that such conditions are satisfied.
4.1 Stability of a Linear Dynamic System
In the design of a control system, the first property of interest is to ensure the closed-loop
system behaves reasonably well. Specifically, one would like to avoid situations in which
one or more of the state variables becomes an unbounded function of time. As such, the
notion of stability is concerned with the fate of the state trajectory (i.e., where the state
will tend toward as time goes to infinite). This section will focus on autonomous systems
(i.e., those in which all inputs are held constant at their nominal values). Subsequent
sections will illustrate how these notions apply to system subject to feedback.
4.1.1 Stability in the Discrete-time Framework
In the discrete-time framework, the linear state-space model of interest is
xk+1 = Ad xk (4.1)
The solution to this recursion is easily found as xk = Adk x0. As discussed above the
property desired from the sequence xk is that none of its elements becomes unbounded
as k tends to infinity. However, our definition of stability will be the stronger condition
of requiring all elements of the state to approach zero for all initial conditions.
113
114 Chapter 4. Linear System Theory
Definition 4.1. A discrete-time linear system, xk+1 = Ad xk, is stable if limk→∞{xk} = 0
for all initial conditions x0 ∈ ℜn.
To illustrate the characteristics required to achieve a stable system, let us assume Ad
is diagonalizable. Then, as indicated in Section 3.8, Ad = ΦΛΦ−1 where Φ has the eigenvectors of Ad as its columns (Φ = [ϕ1 ϕ2 ···ϕn]) and Λ is a diagonal matrix with the
eigenvalues of Ad as its element (Λ = dia g{[λ1 λ2 ···λn]}). Using this eigenvector decomposition it is easily concluded that:
xk = Φ(Λ)k Φ−1x0 =
n∑i=1
λk
i αiϕi (4.2)
As indicated in Section 3.7, the α’s are elements of the projection of the initial condition,
x
0, into the eigenvector directions, or simply α = Φ−1x0. This is also observed by setting
k = 0.
The importance of Equation (4.2) is that it elucidates the relation between the eigenvalues and the fate of the state vector. The first point to note is that the fate of λk i
depends on the magnitude of λi, where magnitude of a complex number is defined as
|λi| = qλiλi. The salient points are captured by the following identity:
lim
k→∞ƒ|λik|' =

0 if |λi| < 1
1 if |λi| = 1
∞ if |λi| > 1
Thus, if |λi| < 1 for all i, then it is guaranteed that xk will tend to zero, for all values of
α = Φ−1x
0. On the other hand, if |λi| ≥ 1 for one of more i, then there will exist an initial
condition such that xk will not tend to zero. Specifically, if |λi| ≥ 1, then x0 = Φα with
αi ̸= 0 will cause the limit of xk to be non-zero. These observations are made precise by
the following fact.
Theorem 4.1. The system xk+1 = Ad xk is stable, if and only if all eigenvalues of the matrix
A
d have a magnitude strictly less than one (i.e., |λi| < 1 for all i).
Note that Theorem 4.1 does not require Ad to be diagonalizable. To illustrate, consider the following non- diagonalizable matrix, with repeated eigenvalues at 0.9.
A
d = 11.9 −−01.1 = 1 1 1 000 0 .9 1.90 1 1 −1 = ΦJΦ−1
Then, once again Adk = ΦJ kΦ−1 and it is easily concluded that
J k = (0.09)k k((00..99))kk−1 and xk = [α1(0.9)k + α2k(0.9)k−1]ϕ1 + α2(0.9)kϕ2
Thus, it is guaranteed that limk→∞{xk} = 0 for all α = Φ−1x0. The unique feature of
this system is that the term k(0.9)k−1 will initially increase with k, and then eventually
decrease for large values of k. (For this example the transition occurs at k = 10.)
It should be emphasized that Theorem 4.1 cannot be used to conclude that limk→∞{xk
} = 0 implies that all eigenvalues of Ad are within the unit circle of the complex plane.
4.1. Stability of a Linear Dynamic System 115
This will be true only if limk→∞{xk} = 0 occurs for all initial conditions x0. In fact, if
A
d is unstable (i.e., there exists an eigenvalues of Ad outside the strict unit circle), then it
is entirely possible to find an initial condition such that limk→∞{xk} = 0. The following
definition indicates which initial conditions will generate such a result.
Definition 4.2. Consider a matrix Ad and organize the generalized eigenvalue-eigenvectors
pairs (λi,ϕi), i = 1...n, to be in increasing order with respect to |λi|, so that λ1 has the
smallest magnitude and λn has the largest. Define s such that λs is the largest eigenvalue
with a magnitude strictly less than 1. Then, the stable subspace is defined as MS(Ad) =
span{ϕ1 ...ϕs} and the unstable subspace is defined as MU S(Ad) = span{ϕs+1 ...ϕn}.
The implication of Definition 4.2 is that if the initial condition, x0, is in the stable subspace then, the α’s associated with the unstable eigenvalues will be zero and limk→∞{xk}
will be guaranteed 0. On the other hand, if x0 is not in MS(Ad), then some of the α’s
associated with unstable eigenvalues will not be zero and limk→∞{xk} ̸= 0.
Another way to interpret the stable and unstable subspaces is to project the state sequence in the eigenvector directions. Specifically, define zk = Φ−1xk, where the columns of Φ are the eigenvectors of Ad. Then, since Φ−1AdΦ = Λ, xk+1 = Ad xk becomes
zk+1 = Λzk. Then, if an element of the vector zk is denoted as zk(i), then one finds the
scalar recursions: z(i)
k+1 = λi zk(i), or equivalently zk(i) = (λi)k z0(i). Thus, if |λi| ≥ 1 and
z
(i)
0 ̸= 0 then limk→∞{zk(i)} ̸= 0. Then, recalling the first discussion of Section 3.7, the
only way to arrive at z0(i) = 0 (from z0 = Φ−1x0) is for x0 to be a linear combination of
the stable eigenvalues, or equivalently x0 is in MS(Ad).
Example 4.1. Consider the following matrix
A
d = −1 0 0.1 0..2 7
Using the MATLAB function ‘eig(A)’, one finds that the eigenvalues are 0.8 and 0.9,
indicating that the open-loop process is stable.
Example 4.2. Consider the following matrix
A
d = −10.4 0 .3 0..6 5
Using the MATLAB function ‘[Phi, Lam]= eig(A)’, one finds the following eigenvalue
and eigenvector matrices (as defined in Section 3.6)
Λ = 10 0 .1 0.8 Φ = −00.8944 .4472 0 −0.7071 .7071
The system is clearly unstable (since one eigenvalue is outside the unit circle). In this case,
the stable subspace is MS(A) = span{[−0.7071 0.7071]T } and the unstable subspace is
M
U S(A) = span{[0.8944 −0.4472]T }.
116 Chapter 4. Linear System Theory
4.1.2 Stability in the Continuous-time Framework
In the continuous-time framework, the linear state-space model of interest is
x˙ = Ax (4.3)
In Chapter 2 it was asserted that the solution to Equation (4.3) is x(t) = eAt x(0).
Definition 4.3. A continuous-time linear system, x˙ = Ax, is stable if limt→∞{x(t)} = 0 for
all initial conditions x(0) ∈ ℜn.
If the matrix A is diagonalizable, (i.e., A= ΦΛΦ−1), then x(t) is easily found to be
x(t) = ΦeΛtΦ−1x(0) =
n∑i=1
αi eλi tϕi (4.4)
where (λi,ϕi) are the eigenvalue-eigenvector pairs of A, and the αi’s are elements of the
projection α = Φ−1x(0). As compared to the discrete-time framework, Equation (4.4)
gives a slightly different relation between the stability of the system and the eigenvalues
of A. Specifically, if the real part of an eigenvalue, λi, is strictly negative (i.e., Re{λi} < 0),
then eλi t will converge to zero for large t. On the other hand, if Re{λi} ≥ 0, then eλi t
will not converge to zero.
Theorem 4.2. The system x˙ = Ax is stable if and only if all eigenvalues of the matrix A have
negative real parts.
Again, the condition for stability does not require A to be diagonalizable. If A is not
diagonalizable and the Jordan form is employed, then solution will include the matrix eJ t.
Then, using the Cayley-Hamilton Theorem, it can be shown that this matrix will include
the expected eλi t terms, but will also include t q−1eλi t terms where q is the number of
repeated eigenvalues. Such a term should be familiar to those well versed in the subject of
Laplace transforms, as the inverse transform of (q −1)!/(s −λi)q.
Definition 4.4. Consider a matrix A and organize the generalized eigenvalue-eigenvectors
pairs (λi,ϕi), i = 1...n, to be in increasing order with respect to Re(λi ), so that λ1 has the
smallest real part and λn has the largest. Define s such that λs is the largest eigenvalue with a
real part strictly less than 0. Then, the stable subspace is defined as MS(A) = span{ϕ1 ...ϕs}
and the unstable subspace is defined as MU S(A) = span{ϕs+1 ...ϕn}.
Example 4.3. Consider the following matrix
A= −0 2 1 −3
Using the MATLAB function ‘eig(A)’, one finds that the eigenvalues are -1 and -2, indicating that the open-loop process is stable.
Example 4.4. Consider the following matrix
A= −4 6 3 −5
4.1. Stability of a Linear Dynamic System 117
Using the MATLAB function ‘[Phi, Lam]= eig(A)’, one finds the following eigenvalue
and eigenvector matrices (as defined in Section 3.6)
Λ = 1 0 0 −2 Φ = −00.8944 .4472 0 −0.7071 .7071
The system is clearly unstable (since one eigenvalue is positive). In this case, the stable
subspace is MS(A) = span{[−0.7071 0.7071]T } and the unstable subspace is MU S(A) =
span{[0.8944 − 0.4472]T }.
4.1.3 Stability in the Sense of Lyapunov
The Lyapunov Stability Theorem is among the most celebrated result in all of control
theory. Specifically, it provides a stability test alternative to the simple eigenvalue condition. While this approach appears to be more complicated, it is central to the controller
synthesis methods to be described in later chapters.
Theorem 4.3. The following three statements are equivalent (in the sense that if any one
holds then the other two also hold).
(1) x˙ = Ax is stable
(2) There exists P > 0 such that A∗P + PA< 0
(3) There exists P > 0 such that AP + PA∗ < 0
Before giving the proof of Theorem 4.3, the discrete-time version is stated to illustrate
the similarities of the two. The proof of Theorem 4.4 is left as Exercise 4.19.
Theorem 4.4. The following three statements are equivalent (in the sense that if any one
holds then the other two also hold).
(1) xk+1 = Ad xk is stable
(2) There exists P > 0 such that Ad PA∗d − P < 0
(3) There exists P > 0 such that A∗d PAd − P < 0
Proof of Theorem 4.3: Let us begin by noting that the real part of the eigenvalues of A
and A∗ are the same. Using this fact it is concluded that if (1) is equivalent to (2), then one
can replace A in (1) with A∗ and find it equivalent to (3). Thus, the remaining challenge is
to show that (1) implies (2) and that (2) implies (1). We will begin with the later.
Assume the existence of P > 0 such that A∗P + PA < 0 and let λ ∈ C and ϕ ∈ Cn be
an eigenvalue-eigenvector pair for A. This indicates that
0 > [(A∗P + PA)ϕ,ϕ] = [Pϕ,Aϕ] + [PAϕ,ϕ]
= [Pϕ,λϕ] + [Pλϕ,ϕ] = (λ + λ)[Pϕ,ϕ]
Thus, it is found that 2Re{λ}[Pϕ,ϕ] < 0. Since P > 0 and ϕ cannot be the zero vector,
it is concluded that Re{λ} < 0, and it is confirmed that (2) implies (1).
For the other case, (1) implies (2), a P > 0 will need to be constructed and shown to
satisfy A∗P + PA< 0, using only the assumption of stability. Consider the matrix
P ˆ=∫0∞ eA∗tQeAt d t (4.5)
118 Chapter 4. Linear System Theory
where Q is any positive definite matrix of appropriate dimension. Using Corollary 2.1,
the following equalities are easily obtained:
A∗P = ∫0∞ A∗eA∗tQeAtd t = ∫0∞ d t d eA∗tQeAtd t (4.6)
PA= ∫0∞ eA∗tQeAtAd t = ∫0∞ eA∗tQ d t d eAtd t (4.7)
Then, application of the product rule for derivatives (in reverse) as well as the fundamental theorem of calculus yields:
A∗P + PA= ∫0∞ d t d eA∗tQeAt + eA∗tQ d t d eAtd t
= ∫0∞ d t d eA∗tQeAtd t (4.8)
= eA∗tQeAt ∞ 0 = tlim →∞ƒeA∗tQeAt' − Q
The stability assumption tells us that limt→∞ eAt = 0, and indicates the desired result:
A∗P + PA= −Q < 0 (4.9)
The final issue is to show that P > 0. Extending Definition 3.4(iii) to integration gives:
[P x, x] = ∫0∞[QeAt x,eAt x]d t (4.10)
Then noting that the null space of eAt is empty for all t (since (eAt)−1 = e−At exists for all
t), indicates that [P x, x] > 0 for all non-zero x ∈ Cn.
Example 4.5. Consider the following matrix
A= −0 2 1 −3
Using the MATLAB function ‘lyap(A′,eye(2))’, one finds that the solution to the Lyapunov equation A∗P + PA+ I = 0 is
P = 01 0 .5 0..5 5
Since this P is also positive definite (with eigenvalues 0.191 and 1.309), the result of Example 4.3 is confirmed. Next consider the matrix of Example 4.4.
A= −4 6 3 −5
Using the MATLAB function ‘lyap(A′,eye(2))’ again, one finds that the solution to the
Lyapunov equation A∗P + PA+ I = 0 is
P = −−108.5 − −10 12..5 5
4.2. Linear Feedback and State Observers 119
However, this P matrix is not positive definite (with eigenvalues -20.99 and 0.488). Thus,
a strict conclusion about stability cannot be made. However, if one works from the other
direction (the knowledge that A is not stable based on the eigenvalues), then Theorem 3.3
tells us that there does not exist a positive definite P satisfying the Lyapunov equation, so
we should stop looking.
4.2 Linear Feedback and State Observers
Consider the following linear state-space process
x˙ = Ax + B u (4.11)
y = C x (4.12)
where u is the manipulated variable and y is a physical measurement. Let us initially
assume C = I. That is the controller has full access to all the state variables at all times. In
this case, it is reasonable to assume the controller is of the following form: u(t) = −Lx(t).
Substitution of this linear feedback policy into Equation (4.11) yields:
x˙ = Ax − BLx = (A− BL)x (4.13)
Based on the previous section, the selection of L should be such that the closed-loop
system matrix, (A − BL), has eigenvalues with negative real parts, or equivalently the
closed-loop system is stable.
Example 4.6. Consider the matrix pair
A= −4 6 3 −5 B = −21
If the feedback gain is selected to be L = [1 0], then the closed-loop system becomes
x˙ = (A− BL)x = −2 6 2 −5 x
Using the MATLAB function ‘eig(A-B*L)’, one finds that the eigenvalues are -1 and -2,
indicating that the closed-loop system is stable.
Before beginning the design of a controller (i.e., the selection of L), one would like a
answer to the following question: “Does there exist a linear feedback L such that (A−BL)
is stable?” Section 4.3 will develop a set of conditions aimed at answering this question.
As one may expect, these conditions will be based solely upon the characteristics of the
matrices A and B. The following definition gives a name to this question.
Definition 4.5. A matrix pair (A, B) is stabilizable if there exists a matrix, L, such that the
closed-loop system matrix, (A− BL), is stable.
Let us now return to the more general case, where C is not equal to I. In this case, one
would like to use a policy similar to u = −Lx, but a substitute for x must be found since
x cannot be measured. One option is to use measurement feedback (u = −Ly = −LC x).
Unfortunately, such an approach greatly narrows the design freedom with respect to L
and ultimately will limit the performance capabilities of the closed-loop system. An
120 Chapter 4. Linear System Theory
alternative is to construct a state observer to generate an estimate of the state vector. This
estimate will be denoted as xˆ(t) and will eventually be used to construct the following
control policy: u = −Lxˆ. However, before analyzing this new feedback policy, the
characteristic of the observer must be investigated.
A state observer is defined by the following linear state space process:
xˆ˙ = Axˆ + B u + K(y − C xˆ) (4.14)
where y is from Equation (4.12). The basic idea being that data collected from the measurement y(t) will be used to drive xˆ(t) to the current value of x(t) regardless of the
initial condition of each. To see this, define the following error signal: e(t) = x(t)− xˆ(t).
Then, by combining (4.14) with (4.11)-(4.12), one arrives at the following model for the
time evolution of the error signal:
˙e = (A− KC )e (4.15)
Thus, if K is selected such that (A− KC ) is stable, then the error signal will go to zero
regardless of the initial condition e(0). This issue of stability of the error system is at the
heart of observer design.
Example 4.7. Consider the matrix pair
A = −4 6 3 −5 C = 1 1
If the observer gain is selected to be K = [2 2]T , then the error system becomes
˙e = (A− KC )e = −2 4 5 −7e
Using the Matlab function ‘eig(A-K*C)’, one finds that the eigenvalues are -2 and -3, indicating that the error system is stable.
Similar to the state feedback case, one would like to an answer to the following question: “Does there exist an observer gain K such that (A−KC ) is stable?” Section 4.4 will
develop a set of conditions for the following definition.
Definition 4.6. A matrix pair (A, C ) is detectable if there exists a matrix, K, such that the
closed-loop system matrix, (A− KC ), is stable.
Now return to the question of using the state estimate in the feedback policy: u =
−Lxˆ. For this analysis one will need to construct a compound system to capture the
dynamics of both the original process and the observer. That is, if u = −Lxˆ, then x˙ =
Ax−BLxˆ. Thus, one will need to know the dynamics of xˆ, from xˆ˙ = Axˆ+B u+K(y−C xˆ)
which is equal to xˆ˙ = Axˆ−BLxˆ+KC x −KC xˆ. Thus, we arrive at the compound system
x xˆ˙ ˙ = KC A (A− KC −BL− BL)x xˆ (4.16)
Then, the question is to find matrices L and K such that this compound system is stable.
Using the form of Equation (4.16), this will be a challenging task indeed. However, the
task is made much simpler by considering one of two possible variable transformations.
4.3. Controllability and Stabilizability 121
The first is arrived at by defining the feedback policy u = −Lxˆ as u = −L(x − e), since
e = x − xˆ. Then, we quickly arrive at the following compound system.
x˙ ˙e = (A−0BL) (A−BLKC)xe (4.17)
The second form, is based on the observation that Equation (4.14) is the same as xˆ˙ =
Axˆ + B u + KC e. Then, the compound system is found to be
xˆ˙ ˙e = (A−0BL) (A−KCKC)xˆe (4.18)
Since the compound system matrix of each case is similar to the others, Theorem 3.8
tells us that the eigenvalues of each are the same. Thus, stability for one is equivalent
to stability for all. Then, since the compound system matrices of Equation (4.17) or
(4.18) are block triangular the eigenvalues of the compound system are those of (A−BL)
combined with those of (A− KC). Thus, the compound system is stable if and only if
(A− BL) and (A− KC) are both stable.
The importance of this separation principle is that the question of the existence of
gains, L and K, such that the compound system is stable is addressed by the independent
questions of stabilizability and detectability (Definitions 4.5 and 4.6).
Example 4.8. If the feedback and observer gains of Examples 4.6 and 4.7 are applied to
Equation (4.17), one finds:
x˙ ˙e =

2 6 −2 0
−2 −5 1 0
0 0 2 4
0 0 −5 −7

xe
As expected the eigenvalues of this system matrix are -1, -2, -2 and -3, indicating that the
compound system is stable.
4.3 Controllability and Stabilizability
The notions introduced in this section represent the most basic properties one would
desire from a process that is to be controlled. That is, does the open-loop system possess
the linear algebraic ability to respond to feedback favorably? More specifically, is the
system stabilizable? If the system does not possess this property, then one will know with
certainty that a controller will never exist that is capable of meeting this most modest
control objective. In such cases, the appropriate action is to go back and re-design the
open-loop process such that this condition is meet. As will be shown in subsequent
chapters, the properties of this section are only the first step in determining the existence
of a controller that is capable of meeting the desired objectives.
4.3.1 Complete Controllability
We again start with the discrete-time framework and consider the properties of the following linear state-space process
xk+1 = Ad xk + Bd uk (4.19)
122 Chapter 4. Linear System Theory
Definition 4.7. A linear system xk+1 = Ad xk + Bd uk is completely controllable, if any
final state, x˘ ∈ Rn, can be reached in finite time, starting from an initial state of zero.
Let us begin by looking more closely at Equation (4.19).
x
1 = Ad x0 + Bd u0
x
2 = Ad x1 + Bd u1 = A2d x0 + AdBd u0 + Bd u1
x
3 = Ad x2 + Bd u2 = A3d x0 + A2dBd u0 + AdBd u1 + Bd u2
Thus, in general
xk = Ak d x0 +
k−1
∑i=0
Ak−1−i
d Bd ui
(4.20)
= Ak
d x0 +
k−1
∑i=0
Ai
dBd uk−1−i
This is the discrete-time version of Equation (2.57). If the initial condition is zero and xk
is set equal to x˘, then Equation (4.20) can be written as
x˘ = L
c,k zk where Lc,k = Bd AdBd A2dBd ··· Ak d−1Bd and zk =

uk−1
uk−2
...u
1
u
0

Thus, for a fixed k, the question is: Does there exist a solution to x˘ = Lc,k zk for all values
of x˘ ∈ Rn? The answer to the question is given by the Fundamental Theorem of Linear
Algebra (Theorem 3.1) and states that a solution to x˘ = Lc,k zk will exist for all values of
x˘ ∈ Rn if and only if ℜ(Lc,k) = Rn. Thus, the remaining question is to select value a for
k. Since we are allowed to select any finite value of k, let us begin with k = n + 1. In
this case, the last set of columns of Lc,n+1 will be An dBd. However, the Cayley-Hamilton
Theorem tell us that An
d can be expressed as a linear combination of lower powers of Ad.
This means that the columns of An
dBd are not linearly independent of the other columns
of L
c,n+1, and thus can be omitted from the range space calculation. Clearly, the same
will occur for any value of k > n. In sum, it is sufficient to select k ≤ n. Let us now
look at the other extreme of Bd being a column vector. In this case, each Ak dBd will also
be a column vector, and if k < n, then Lc,k will have less than n columns. Under such
a scenario, it will be impossible for the range space of Lc,k to be the entire space, Rn.
Thus, to generate a condition that will work for all Bd while having the fewest redundant
columns we should select k = n. The above discussion is summarized in the following
theorem, where Lc,n is denoted as just Lc.
Theorem 4.5. A linear state space system xk+1 = Ad xk + Bd uk is completely controllable if
and only if ℜ(Lc) = Rn where Lc = Bd AdBd A2dBd ··· An d−1Bd.
Stated more simply, the system is completely controllable if and only if the range
space of Lc is the entire space. The continuous-time results are nearly identical, although
4.3. Controllability and Stabilizability 123
the proof is a bit more complicated, see for example Chen, [117], or Kwakernaak &
Sivan, [104].
Definition 4.8. A linear system x˙ = Ax +B u is completely controllable, if any final state,
x˘ ∈ Rn, can be reached in finite time, starting from an initial state of zero.
Theorem 4.6. A linear state space system x˙ = Ax +B u is completely controllable if and only
if ℜ(Lc) = Rn where Lc = B AB A2B ··· An−1B.
The fact that the controllability matrix is of identical form for the discrete-time and
continuous-time cases indicates that the property has more to do with the structure of
the matrices than the values of the non-zero elements.
Example 4.9. Consider the matrix pair
A= 1 0 0 1 B = 1 1
In this case the controllability matrix Lc is
L
c = [B AB] = 1 1 1 1
Clearly, the two columns of the controllability matrix are linearly dependent, indicating
the pair is not completely controllable. Now, consider a slight modification of A
A= 1 1 0 1 B = 1 1 then Lc = B AB = 1 2 1 1
Now, the two columns are linearly independent, indicating that the pair is completely
controllable and any state can be reached from zero. Now, consider another modification
of B
A= 1 1 0 1 B = 10 then Lc = B AB = 1 1 0 0
Again, the columns are linearly dependent and the pair is not completely controllable.
The concept of controllability can now be used to answer the stabilizability question
of whether or not there exists a linear feedback, L, such that A−BL is stable. The answer
lies in the much celebrated Pole Placement Theorem.
Theorem 4.7. Consider real matrices A and B. The pair (A, B) is completely controllable
if and only the eigenvalues of (A − BL) can be assigned arbitrarily (assuming the complex
conjugate of each is also an eigenvalue) by appropriate selection of a real matrix L.
The proof of the pole placement theorem is a bit involved, so the interested reader is referred to Chen, [117], for details. To help the reader develop some insight, the
following example is provided.
124 Chapter 4. Linear System Theory
Example 4.10. Consider the following pair:
A= 1 0 0 0 B = 10
These are easily shown to be completely controllable, since the controllability matrix is
the identity matrix. If the linear feedback is L = [l1 l2] then, the closed-loop system
matrix is A − BL = −1 0 l1 −l2 and the characteristic equation is λ2 + l1λ + l2 = 0.
This indicates complete freedom in the section of the coefficients of the characteristic
equation, which gives complete freedom in the selection of its roots. In contrast, consider
A= 0 0 0 1 B = 10
In this case, the characteristic equation of A− BL is λ2 + l1λ = 0. While one of the roots
can be arbitrarily selected the other root will be zero regardless of the values of L. As
one should expect from the pole placement theorem, the pair (A, B) is not completely
controllable, which is verified to be true from ℜ(Lc) = span{[1 0]T }.
4.3.2 The Controllable Subspace
Using the pole placement theorem, we now have a sufficient condition for stabilizability.
Specifically, we know that if the pair (A, B) is completely controllable, then one can
assign closed-loop eigenvalues to be such that the closed-loop system is stable, either with
a magnitude strictly less than 1, or with a real part strictly less than 0. Unfortunately,
this observation is not the complete answer to the stabilizability question. Consider the
example of B = 0, which guarantees the pair (A,B) will not be completely controllable,
regardless of A. Thus, the pole placement theorem cannot be applied. However, if A is
already stable then we know that any feedback will result in a stable closed-loop system.
The bottom line is that we would prefer a condition that is not just sufficient, but also
necessary. To find such a condition (given in the next subsection) we will need to expand
our perspective on controllability. We begin with a few simple examples in the discretetime framework.
Consider the following system:

x
(1)
k+1
x
(2)
k+1

= 1 1 0 1  xxk k((12) )   + 1 0 uk
If the initial condition is zero, then x(1)
k = ∑k i=0 ui and xk(2) = 0. Thus, the only set of
final conditions that can be reached are those in span{[1 0]T }, which happens to be the
only linearly independent column of Lc. Now consider the following slightly different
system:

x
(1)
k+1
x
(2)
k+1

= 1 0 0 1  xxk k((12) )   + 1 1 uk
Similarly, an inspection this system indicates that if the initial condition is zero, then the
two elements of the state vector must be equal, xk(1) = ∑k i=0 ui and xk(2) = ∑k i=0 ui. As
4.3. Controllability and Stabilizability 125
you might expect, it is not a coincidence that the set of reachable states, span{[1 1]T },
is the same as the only linearly independent column of Lc. These observations are made
precise by the following definition and fact.
Definition 4.9. The controllable subspace of the pair (A, B), denoted M C (A, B), is the set
of final conditions that can be reached within a finite time, assuming a zero initial condition.
Theorem 4.8. The controllable subspace is the range space of the controllability matrix. That
is, M C (A, B) = ℜ(Lc ).
The controllable subspace represents the region of influence for the input u. That
is, the structure of the open-loop process will preclude the input, u, from modifying
the portion of the state that is outside of the controllable subspace. The following fact,
known as the controllable canonical form, is central to illustrating this point.
Theorem 4.9. The pair (A, B) is not completely controllable if and only if there exists a
projection z = T −1x, such that
T −1AT = A011 A A12 22 and T −1B = B01 (4.21)
and the pair (A11, B1) is completely controllable.
To understand the implication of Theorem 4.9, consider the continuous-time system
x˙ = Ax + Bu. Using of the projection of Theorem 4.9 (or equivalently x = T z) leads to
the following system in the projected state variable z˙ = T −1AT z +T −1Bu, or equivalently:
zz˙ ˙1 2 = A011 A A12 22z z1 2 + B01 u (4.22)
Given this form it is clear that the input, u, is unable to modify the z2 portion of the state.
The following theorem will be used in the proof of Theorem 4.9 and is of independent
interest.
Theorem 4.10. The controllable subspace is invariant to the matrix A. That is, if y ∈ ℜ(Lc )
then Ay ∈ ℜ(Lc ).
The proof of Theorem 4.10 boils down to showing that the columns of ALc are a
linear combination of the columns of L
c, which is easily observed from the CayleyHamilton theorem.
Proof of Theorem 4.9: If portion: Assume there exists T such that (4.21) is found and the
pair (A11, B1) is completely controllable. In this case, the only issue is to show that the dimension of M
C (A, B) is equal to the dimension of M C (T −1AT, T −1B). In the later case,
the controllability matrix is T −1Lc, where Lc is the controllability matrix of the former.
Using Theorem 3.6, it is concluded that rank(T −1Lc) = rank(Lc). Then, by inspection
we conclude that (T −1AT, T −1B) is not completely controllable or rank(T −1Lc) is less
than the number of columns of A. Thus, we conclude that (A, B) cannot be completely
controllable.
126 Chapter 4. Linear System Theory
For the only if portion, one will need to construct a matrix T that gives the desired
result. Since (A, B) is not completely controllable, MC(A, B) = ℜ(Lc) is not the full space
and ℜ(Lc)⊥ is not empty. Thus, the projection can be constructed as T = T1 T2,
where the columns of T
1 form an orthonormal basis for ℜ(Lc) and the columns of T2
form an orthonormal basis for ℜ(Lc)⊥. Since all of the columns of T are orthonormal
T −1 = T ∗ = T T1 2∗ ∗
Then, evaluation of the similarity matrices gives:
T −1AT = T T1 2∗ ∗AT AT1 1 T T1 2∗ ∗AT AT2 2 and T −1B = T T1 2∗ ∗B B
Since each row of T
2 is orthogonal to ℜ(Lc) and each column of B is in ℜ(Lc), it is readily
concluded that T ∗
2 B = 0. Similarly, T2∗AT1 = 0, if each column of AT1 is in ℜ(Lc). This
is guaranteed by Theorem 4.10, since each column of T1 is in ℜ(Lc). Finally, we will
need to show that the pair (A11, B) = (T1∗AT1, T1∗B) is completely controllable. To do
so, consider controllability matrix for the pair (T −1AT, T −1B)
e L
c = T −1B (T −1AT )T −1B (T −1AT )2T −1B ··· (T −1AT )n−1T −1B
= T −1B T −1AB T −1A2B ··· T −1An−1B
= TT12−−11B T B T12−−11AB T AB T12−−11AA22BB ··· ··· TT12−−11AAnn−−11BB
= T10 0 ∗B T1∗AB T1∗A02B ··· ··· T1∗A0n−1B
The last equality is due to the fact that each row of T2 is orthogonal to ℜ(Lc) and each column of AkB is in ℜ(Lc). Noting that if x ∈ ℜ(Lc), then T −1T x = T1∗T1x it is concluded
that
e L
c = T10∗B (T1∗AT01)T1∗B (T1∗AT01)2T1∗B ··· ··· (T1∗AT10)n−1T1∗B
If rank(Lc) = r then another use of the Cayley-Hamilton theorem indicates that the
columns of (T1∗AT1)kT1∗B, k ≥ r are linearly dependent on the others. Thus, it is sufficient to consider the controllability matrix of (A11,B1) = (T1∗AT1, T1∗B)
e e L
c = T1∗B (T1∗AT1)T1∗B (T1∗AT1)2T1∗B ··· (T1∗AT1)r−1T1∗B
That is, ℜ(Lec) = ℜ(Le ec). Then, recalling Theorem 3.6 and that Lec = T −1Lc, we conclude
that r = rank(Lc) = rank(Lec) = rank(Le ec) and finally that Le ec is full rank or equivalently
(A11,B1) = (T1∗AT1, T1∗B) is completely controllable, which completes the proof.
4.3.3 Necessary and Sufficient Conditions for Stabilizability
Given the canonical form of Equation (4.22), it is clear that the input u will have no influence on the state z
2. To see this more clearly, consider a linear feedback u = −Le1 Le2
4.3. Controllability and Stabilizability 127
z z1 2, which gives z z˙˙12 = A11 −0B1Le1 A12 A−22 B1Le2z z1 2. Thus, if A22 is not stable,
then we know that there will not exist a feedback that will make the system stable. On
the other hand, if A22 is stable, then we need only find an Le1 such that A11−B1Le1 is stable.
Since (A11,B1) is completely controllable, the pole placement theorem tells us that a stabilizing Le1 will always exist. In sum, a necessary and sufficient condition for stabilizability
of the pair (A, B) is for A22 to be stable. The only problem is that for one to verify this
condition one will need to compute A22 as T2∗AT2, which is a bit tedious. The following
Theorem gives conditions directly related to the pair (A, B).
Theorem 4.11. The pair (A, B) is stabilizable if and only if the unstable subspace is contained
within the controllable subspace, or MU S(A) ⊆ MC(A, B).
From the preceding paragraph, it has been established that (A, B) is stabilizable if and
only if A22 is stable. Furthermore, since the eigenvalues of A and T −1AT are the same,
A
22 is stable if and only if all unstable eigenvalues of A are also eigenvalues of A11. To
simplify the remainder of the proof, let us assume the eigenvalues of A are distinct. In
this case, λ is an eigenvalue of A11 only if it is not an eigenvalue of A22 and the associated
eigenvector of T −1AT must be of the form ϕe= ϕe∗ 1 0∗. If the eigenvector associated
with λ and A is denoted as ϕ, then the two eigenvectors are related by the projection
ϕe= T −1ϕ. This tells us that if λ is an eigenvalue of A11, then ϕ ∈ ℜ(Lc) = MC(A, B),
since ϕe0∗ 1 = T T1 2∗ ∗ϕ. Thus, if all unstable eigenvalues are associated with A11, then
M
U S(A) ⊆ MC(A, B). On the other hand, if MU S(A) ⊆ MC(A, B), then any unstable
eigenvector, ϕ, will be such that ϕe0∗ 1 = T T1 2∗ ∗ϕ, which indicates its associated eigenvalue must be an eigenvalue of A11.
Example 4.11. Consider the matrix pair
A= −4 6 3 −5 B = −21
In this case the controllability matrix Lc is
L
c = B AB = −2 2 1 −1
Clearly, the two columns of the controllability matrix are not linearly independent,
indicating that the pair is not completely controllable. Using the MATLAB function
‘orth(Lc)’, one finds that the range space is just a single dimension (in the direction of
[−0.8944 0.4472]T ). Thus, the controllable subspace is
M
c(A, B) = span−0.8944 0.4472T
Using the MATLAB function ‘[Phi, Lam]= eig(A)’, one finds the following eigenvalue
and eigenvector matrices (as defined in Section 3.6)
Λ = 1 0 0 −2 Φ = −00.8944 .4472 0 −0.7071 .7071
128 Chapter 4. Linear System Theory
Thus, the unstable subspace MU S(A) is exactly aligned with the controllable subspace,
indicating that the pair is stabilizable. The following pair is similarly shown to be not
stabilizable since M
c(A, B) = span−0.7071 0.7071T
A = −4 6 3 −5 B = −11
4.4 Observability and Detectability
The notions of the previous section assume full information with regard to the initial
condition of the process and focus on the ability to take actions to influence the process.
We now turn the second half of feedback - the ability gather information about the process. Clearly, both abilities (to influence the process as well as gather useful information
about its conditions) are required to arrive at an effective controller. This section will focus on the following question: Does the open-loop system possess the ability to estimate
the state of the process? More specifically, is the system detectable? If the system does
not possess this property, then one will know with certainty that an estimator will never
exist that is capable of meeting this most modest objective. In such cases, the appropriate
action is to go back and re-design the open-loop process such that these conditions are
meet.
The material of this section also represents our first encounter with the notion of
duality. Specifically, we will see that the tests for observability and detectability are very
similar to those of controllability and stabilizability. Additional examples of duality between control and observation will occur throughout the text.
4.4.1 Observability and the Unobservable Subspace
We again start with the discrete-time framework, but this time focus on the measurement
portion rather than the input.
xk+1 = Ad xk
(4.23)
yk = C xk
Before giving the definition of observability consider the following scenario. Assume
two experiments are performed, both using the above system and each starting at a different, but unknown, initial condition. In this case, one would expect the measurement
sequences, yk, from each experiment to be different. However, if the measurement sequences from each experiment are exactly the same, then we know that it will be impossible to distinguish between the two initial conditions, even if we know they must be
different. Avoiding this type of situation motivates the following definition.
Definition 4.10. A linear system xk+1 = Ad xk; yk = C xk is completely observable, if any
initial condition, x0 ∈ Rn, can be uniquely determined using a finite number of measurements yk.
4.4. Observability and Detectability 129
Let us begin by looking more closely at Equation (4.23).
y0 = C x0
y1 = C x1 = C Ad x0
y2 = C x2 = C A2d x0
...
yk = C xk = C Ak d x0
This set of equations can be written as:
zk = LO,k x0 where LO,k =

C
C Ad
C A2
d
...
C Ak−1
d

and zk =

y0
y1
y2
...
yk−1

Thus, for a fixed k, the question is: Does there exist a unique solution, x0, to the linear
equation zk = LO,k x0? The existence part of the question is answered trivially, due to the
fact that the sequence yk is assumed to be generated by the system (4.23) using some (although unknown) initial condition. The more interesting part of the question concerns
the uniqueness of the solution. To answer this part of the question, we again turn to the
Fundamental Theorem of Linear Algebra (Theorem 3.1), which states that a solution to
zk = LO,k x0 will be unique if and only if ℵ(LO,k) is empty. Thus, the remaining question
is to select a value for k. Since we are allowed to select any finite value of k, let us begin
with k = n + 1. In this case, the last set of rows of LO,n+1 will be C An d. However, the
Cayley-Hamilton Theorem tell us that An d can be expressed as a linear combination of
lower powers of Ad. This means that the rows of C An d are not linearly independent of
the other rows of L
O,n+1, and thus can be omitted from the null space calculation. Clearly, the same will occur for any value of k > n. In sum, it is sufficient to select k ≤ n . Let
us now look at the other extreme of C being a single row vector. In this case, each C Ak d
will also be a single row vector, and if k < n, then will have less than n rows. Under such
a scenario, it will be impossible for the null space of LO,k to be empty. Thus, to generate
a condition that will work for all C while having the fewest redundant rows, one should
select k = n. The above discussion is summarized in the following theorems, where LO,n
is denoted as just LO.
Theorem 4.12. A linear system xk+1 = Ad xk; yk = C xk is completely observable if and
only if ℵ(LO) is empty, where
L
O =

C
C Ad
C A2
d
...
C An−1
d

130 Chapter 4. Linear System Theory
To bring this result back to the original definition of observability, assume ℵ(LO) is
not empty and consider a non-zero initial condition in ℵ(LO). Then, that initial condition can be added to any other non-zero initial condition to arrive at two distinct initial
conditions that generate the same output sequence yk. However, if ℵ(LO) is empty, then
this situation can never occur.
The continuous-time result is again nearly identical to the discrete-time version.
Theorem 4.13. A linear system x˙ = Ax; y = C x is completely observable if and only if
ℵ(LO) is empty, where
L
O =

C
C A
C A2
...
C An−1

If the pair (A, C) is not completely observable, then it will be of interest to determine
the set of initial condition that cannot be observed.
Definition 4.11. The unobservable subspace of the pair (A, C), denoted MUO(A, C), is the
set initial condition such that the output is zero for all time.
Theorem 4.14. The unobservable subspace is calculated as: MUO(A, C) = ℵ(LO).
4.4.2 First Experience with Duality
It is expected that most readers will find a great deal of similarity between the concepts
of Sections 4.3 and 4.4. This is by far no coincidence. In fact, the notions of controllability and observability are intimately linked. As such, the question of observability is
frequently denoted as the dual of controllability. To see this duality, let us begin by recalling Theorem 3.2, which indicates that ℵ(LO) will be empty if and only if ℜ(L∗ O) is the
full space. However, the adjoint of the observability matrix bears a striking resemblance
to the controllability matrix.
L∗
O = C∗ A∗C∗ A∗2C∗ ··· A∗n−1C∗
Given this observation, the following corollaries are easily proven:
Corollary 4.1. The pair (A, C) is completely observable if and only if the pair (A∗, C∗) is
completely controllable.
Corollary 4.2. The unobservable subspace of the pair (A, C) is equal to the controllable
subspace of the pair (A∗, C∗). That is, MUO(A, C) = MC(A∗, C∗).
The following estimator version of the pole placement theorem can be easily proven,
given the original theorem and the notion of duality.
Theorem 4.15. Consider real matrices A and C . The pair (A, C) is completely observable
if and only if the eigenvalues of A − KC can be assigned arbitrarily (assuming the complex
conjugate of each is also an eigenvalue) by appropriate selection of a real matrix K.
4.4. Observability and Detectability 131
The proof hinges on the fact that the eigenvalues of a real matrix and its adjoint are
identical (recall Theorem 3.6). Thus, assignment of eigenvalues for (A∗ − C∗K∗) is the
same as assignment for A− KC. Then, given Corollary 4.1, it is clear that Theorem 4.15
is identical to Theorem 4.7, except that (A, B) is replace by (A∗, C∗).
4.4.3 Necessary and Sufficient Conditions for Detectability
Similar to the discussion of Section 4.3.2, the pole placement theorem indicates that complete observability is a sufficient condition for detectability, but it is clearly not necessary. For example, if C = 0, then (A, C) will not be completely observable regardless of
A. However, if that A is stable, then any matrix K will render A − KC stable and thus
the system detectable. To arrive at necessary and sufficient conditions for detectability,
we will follow a path similar to that of Section 4.3.3. Specifically, the system will be
transformed into the observable canonical form.
Theorem 4.16. The pair (A, C) is not completely observable if and only if there exists a
projection z = T −1x, such that
T −1AT = AA11 21 A022 and CT = C1 0 (4.24)
and the pair (A11, C1) is completely observable.
To understand the implication of Theorem 4.16, consider the continuous-time system
x˙ = Ax; y = C x. Use of the projection of Theorem 4.16 (or equivalently x = T z)
leads to the following system in the projected state variable z˙ = T −1AT z; y = CT z, or
equivalently:
zz˙ ˙1 2 = AA11 21 A022z z12
(4.25)
y = C1 0z z12
Given this form it is clear that the output, y, is unable to observe the z2 portion of
the state. The proof of Theorem 4.16 (see Exercise 4.20) is based on constructing the
projection as T = T T1 2, where the columns of T2 form an orthonormal basis for ℵ(LO)
and the columns of T
1 form an orthonormal basis for ℵ(LO)⊥. It will also require the
following Theorem concerning invariance of the unobservable subspace.
Theorem 4.17. The unobservable subspace is invariant to the matrix A. That is, if x ∈
ℵ(LO) then Ax ∈ ℵ(LO).
Using the observable canonical form of Equation (4.25) to construct the error equation of the associated state estimator, one finds
˙ ˙ee1 2 = A A11 21 A022 − K K12C1 0e e1 2
= AA11 21 − − K K1 2CC1 1 A022e e1 2
132 Chapter 4. Linear System Theory
Since the pair (A11, C1) is completely observable, one may employ the pole placement
theorem to determine a stabilizing matrix K1. Then, the question of detectability will
boil down to the stability of A22. Specifically, A22 is stable if and only if the pair (A, C)
is detectable. Given this initial argument, the proof of Theorem 4.18 is left as Exercise
4.22.
Theorem 4.18. The pair (A, C) is detectable if and only if the unobservable subspace is
contained within the stable subspace, or MUO(A, C) ⊆ MS(A).
Example 4.12. Consider the matrix pair
A = −4 6 3 −5 C = 2 3
In this case the observability matrix LO is
L
O = C A C  = −2 3 1 −3
Since the columns of L
O are linearly independent, the null space of LO is the empty.
Thus, the pair is completely observable.
Example 4.13. Consider the matrix pair
A = −4 6 3 −5 C = 1 1
In this case the observability matrix LO is
L
O = C A C  = 1 1 1 1
Since the columns of L
O are not linearly independent, the pair is not completely observable. Using the MATLAB function ‘null(Lo)’, one finds that the unobservable subspace
is M
UO(A, C) = span−0.7071 0.7071T , which is exactly aligned with the stable
subspace, indicating that the pair is detectable. The following pair is similarly shown to
be not detectable.
A = −4 6 3 −5 C = 1 2
4.5 Chapter Summary
This chapter has presented a set of analysis tools representing a preliminary stage of control system design. If a proposed open-loop system (designated by a triple of system
matrices: A, B, C) fails to pass the stabilizability and detectability tests, then one is confident that further analysis of this system is futile, as it has been revealed to be such that
there does not exist a feedback element capable of achieving the most basic criterion of a
Exercises 133
Table 4.1. Summary of Ability Tests for Linear Systems.
Continuous-time Discrete-time
Stability Theorem 4.2 Theorem 4.1
Controllability Theorem 4.6 Theorem 4.5
Stabilizability Theorem 4.11 Theorem 4.11
Observability Theorem 4.13 Theorem 4.12
Detectability Theorem 4.18 Theorem 4.18
control system - the property of being a stable closed-loop system. In the design methods
of subsequent chapters, the tests of this chapter will be implicit. That is, while additional
performance criteria may be added, the resulting procedures will be guaranteed to fail
if the open-loop system is not stabilizable and detectable. It is also emphasized that all
of the presented results are conceptually valid in both the continuous- and discrete-time
frameworks. Table 4.1 highlights this fact along with the notion of duality with respect
to manipulated variable influence (controllability and stabilizability) and measurement variable information (observability and detectability). This notion of duality in both
frameworks will continue to occur throughout the text.
For expanded discussions of the material of this chapter, especially results concerning the continuous-time cases, appropriate references are Brockett [119], Kwakernaak &
Sivan [104], Balakrishnan [116] and Chen [117]. It should be noted that the controllability proof of this chapter was adapted from Graham and Rawlings [114] while the
stabilizability proof was adapted from Chen [117].
Exercises
4.1. Consider the following second order differential equation
x˙ = Ax where A= −−12 0 −1 and x(0) = 1 0
Determine an analytic expression for x(t) = [x1(t) x2(t)]∗. It will be helpful to
know that the eigenvalue/eigenvector pairs for A are as follows (you should verify
this by hand)
λ
1 = −1 and ϕ1 = 0 1 and λ2 = −2 and ϕ2 = 1 1
4.2. Consider the following state space model of a physical process x˙ = Ax, where
A = 1 3 0 −2. Determine the eigenvalues and eigenvectors of this process. Do
not use the MATLAB function ‘eig’. Is the process stable?
4.3. Repeat Exercise 4.2 with A= 1 5 0 −2
134 Chapter 4. Linear System Theory
4.4. Repeat Exercise 4.2 with A= p−43 p−23
4.5. Consider the following model of a mass spring system x˙ = Ax+B u; A= −0 1 3 0,
B = 10, where the first state of x is mass position, the second is mass velocity
and the manipulated variable, u, is applied force.
(i) Determine the eigenvalues of A(feel free to use the MATLAB function ‘eig’).
Is the open-loop system stable?
(ii) Convert this continuous-time model to discrete-time using the sample-andhold method and a sample period of 0.2.
(iii) Determine the eigenvalues of Ad. Verify that these eigenvalues correspond
to those of the continuous-time system.
(iv) Simulate the open-loop discrete-time system using an initial condition x0 =
1 0∗.
(v) Using the linear feedback uk = −Lxk with L = 0 0.2, determine the
eigenvalues of the closed-loop system: xk+1 = (Ad − Bd L)xk.
(vi) Simulate the closed-loop system. Make a plot comparing the open-loop and
closed-loop simulations.
4.6. Consider the following model of a mass spring system x˙ = Ax; y = C x; A =
−0 1 3 0, C = 1 1, where the first state of x is mass position, the second is
mass velocity and the output, y, is the sum of the two state variables.
(i) Determine the eigenvalues of A(feel free to use the MATLAB function ‘eig’).
Is the open-loop system stable?
(ii) Convert this continuous-time model to discrete-time using the sample-andhold method and a sample period of 0.2.
(iii) Determine the eigenvalues of Ad. Is the open-loop discrete-time system stable? Verify that these eigenvalues of the discrete-time system correspond to
those of the continuous-time system.
(iv) Simulate the open-loop discrete-time system using an initial condition x0 =
1 0∗. Make a plot of the output signal, yk.
(v) Using the gain K = 00.1, determine the eigenvalues of the error system,
ek+1 = (Ad −KC)ek, which is with associated the discrete-time state observer
xˆk+1 = Ad xˆk + K(yk − C xˆk).
(vi) Using the output signal, yk, and observer gain K = 00.1, simulate the
discrete-time state observer xˆk+1 = Ad xˆk + K(yk − C xˆk), using an initial
condition xˆ
0 = 0 1∗. Make a plot comparing the open-loop state signals
(from part iv) and the state estimate signals (of this part).
(vii) Make a plot to verify that a simulation using the error system, ek+1 = (Ad −
KC)ek, will be identical to the error signals calculated manually (i.e., ek =
xk − xˆk where xk and xˆk are from part vi).
4.7. Consider the following model of a mass spring system x˙ = Ax + b u; y = C x;
Exercises 135
A = −0 1 3 0, B = 10, C = 1 1, where the first state of x is mass position,
the second is mass velocity, the input, u, is applied force and the output, y, is the
sum of the two state variables.
(i) Convert this continuous-time model to discrete-time using the sample-andhold method and a sample period of 0.2. Determine the eigenvalues of Ad
(feel free to use the MATLAB function ‘eig’).
(ii) Using the linear feedback uk = −Lxk with L = 0 0.2, determine the
eigenvalues of the closed-loop system: xk+1 = (Ad − Bd L)xk. Using the gain
K = 00.1, determine the eigenvalues of the error system, ek+1 = (Ad −
KC)ek, associated the discrete-time state observer xˆk+1 = Ad xˆk + K(yk −
C xˆk).
(iii) Calculate the eigenvalues of the system matrix of the discrete-time version
of Equation (4.16) (i.e., with A and B replaced by Ad and Bd). Verify that
these eigenvalues are identical to those of part ii.
(iv) Calculate the eigenvalues of the system matrices of the discrete-time versions
of Equations (4.17) and (4.18). Verify that these eigenvalues are identical to
those of part iii.
(v) Simulate the discrete-time version of the system of Equation (4.16), using
initial conditions x
0 = 1 0∗ and xˆ0 = 0 1∗ to determine the signals
xk and xˆk. Calculate and plot ek = xk − xˆk to verify that it is tending toward
zero.
(vi) Simulate the error system ek+1 = (Ad − KC)ek, with initial condition e0 =
1 −1∗, and verify it gives the same result as part v.
4.8. Consider the following state space model of a physical process:
x˙ = Ax + B u, y = C x, where A= 2 1 0 −1 B = 1 0 0 1 C = 0 1
(i) Is the pair (A; B) stabilizable?
(ii) Is the pair (A; C) detectable?
4.9. Consider the following state space model of a physical process:
x˙ = Ax + B u, y = C x, where A= 1 3 0 −2 B = 1 0 C = 0 1 1 0
(i) Is the pair (A; B) stabilizable?
(ii) Is the pair (A; C) detectable?
4.10. You have been assigned the task of creating state observers for the following systems. The person previously in your position seems to remember that for one of
these systems, a state observer could not be implemented. Is she correct?
(i) x˙ = −03 1 −3 y = 0 1 x
(ii) xk+1 = 10 0 .5 1.5 xk yk = 1 0 xk
(iii) x˙ = −0 1 1 0 y = 1 0 0 1 x
136 Chapter 4. Linear System Theory
4.11. Consider the linear system x˙ = Ax + B u, with
A=

0 1 0
0 0 1
−3 −3 −1

You are given a choice of two actuators. Each result in the following B matrices
B
1 =

00 −
1

B
2 =

−1
1 −
1

Which of these would you choose? Why?
4.12. Consider the linear system
xk+1 =

1 −2 0
−3 −1 2
0 0 −2

xk +

1 0
0 1
0 0

uk
Is the system Stable? Controllable? Stabilizable?
4.13. Determine the abilities of the linear system associated with the following triples
(take note of the subscript notation for discrete-time systems). More specifically,
determine if the system is stable, completely controllable, completely observable,
stabilizable or detectable? (Feel free to use the MATLAB commands ‘orth’ and
‘null’)
(i) A= −11 0 −2 B = 0 1 C = 0 1
(ii) A= −11 0 −2 B = 10 C = 1 0
(iii) A= −11 0 −2 B = 1 1 C = 1 0 0 1
(iv) A=

−1 −2 0
−3 −1 2
0 0 −2

B =

1 0
0 1
0 0

C = 1 0 0
(v) A=

−1 −2 0
−3 −1 2
0 0 2

B =

1 0
0 1
0 0

C = 1 0 0 0 0 1
(vi) Ad =

1.1 −0.2 0
−0.3 0.9 0.2
0 0 0.8

B
d =

0.1 0
0 0.1
0 0

C = 1 0 0
4.14. Repeat the stabilizable and detectable parts of Exercise 4.7, by constructing the
controllable and observable canonical forms of the system.
4.15. Consider an isothermal continuously stirred tank reactor (CSTR) in which a reversible reaction is being carried out, 2A  B, where the forward and reverse
kinetic constants (ka and kb, respectively) are defined with respect to species B.
(i) Determine the nonlinear dynamic model for this system assuming the inlet concentration of species A is the manipulated variable. Other relevant
information: k
a = 0.05, kb = 0.01, F /V = 0.02 and CAin SSOP = 10 (all in SI
units).
Exercises 137
(ii) Under these operating conditions verify that the steady-state concentrations
are equal to CASSOP = 1.59 and CBSSOP = 4.21.
(iii) Determine the linearized dynamic model of the process.
(iv) Fill in the following table:
Is the linearized process Yes No Cannot be determined
Stable?
Controllable?
Stabilizable?
Observable?
Detectable?
4.16. Consider the matrix equality A∗P + PA+ I = 0 with
A= −01 12 −2
If the elements of the matrix P are denoted as
P = xx12 x x23
Solve the matrix equality without the aid of a computer. You should arrive at 3
linear equations that can easily be solved by hand. Verify your answer using the
MATLAB function ‘lyap’.
4.17. Consider the matrix equality A∗P + PA+ I = 0 with
A= −0 1 3 −2
If the elements of the matrix P are denoted as
P = xx1 2 xx2 3
Solve the matrix equality without the aid of a computer. You should arrive at 3
linear equations that can easily be solved by hand. Verify your answer using the
MATLAB function ‘lyap’.
4.18. A matrix A is denoted σ-stable if Re{λi(A)} < σ. Prove that A is σ-stable if and
only if there exists P > 0 such that A∗P + PA < 2σP
4.19. Prove the discrete-time version of the Lyapunov theorem (Theorem 4.4):
(i) If there exists P > 0 such that A∗d PAd −P < 0 then Ad is stable (i.e., |λi(Ad)| <
1).
(ii) If Ad is stable then there exists P > 0 such that A∗d PAd −P < 0. (Hint: Define
P as ∑∞k=0 A∗dkQAk d.)
138 Chapter 4. Linear System Theory
4.20. Prove Theorem 4.16.
4.21. Prove Theorem 4.17.
4.22. Prove Theorem 4.18.
4.23. Answer the following questions as either True or False
(i) If A∗ + A< 0, then A is stable.
(ii) If A is stable then A∗ + A< 0.
(iii) The linear system x˙ = Ax + u is completely controllable.
4.24. Consider the following system of differential equations describing a DC motor
L
f
d i
f
d t
= −R
f if + vf
L
a
di
a
d t
= −(Ra + Rint)ia − Kvωif + va
J
dω
d t
= −Bω + K
viaif + TL
where i
f and ia are the currents through the field and armature coils, respectively
and ω is the angular speed of the motor. These have nominal values of i f = 4 A,
i
a = 87.9121 A and ω = 150 rad/s. The manipulated variables are vf and va, the
voltages applied to the field and armature coils, with nominal values of v f = 100 V
and v
a = 589.956 V . The measurements are of the two state variable ia and ω.
The parameters of the motor are as follows: Lf = 50 H, Rf = 25 Ω, La = 2 H,
R
a = 0.1 Ω, Rint = 0.4 Ω, Kv = 0.91 V s/A, J = 5 N m, B = 0.3 N m s and
TL
= −275 N m.
(i) Determine the linearized dynamic model of the process.
(ii) Fill in the following table:
Is the linearized process Yes No Cannot be determined
Stable?
Controllable?
Stabilizable?
Observable?
Detectable?
4.25. Consider the furnace reactor process in Section 2.6.1 in Chapter 2. Assume no
disturbance. The measurements are of the two state variables T
F and TR. Fill in
the following table:
Exercises 139
Is the linearized process Yes No Cannot be determined
Stable?
Controllable?
Stabilizable?
Observable?
Detectable?
4.26. Consider the three masses system in Section 2.6.2 in Chapter 2. Assume no disturbance. The measurements are of the two state variables r
0 and r1. The nominal
value of state variables, manipulated variables, and the performance outputs are
snom = [0.2338 m 0.1073 m 0.03 m 0 m/s 0 m/s 0 m/s]∗, mnom = [−4500 N]
and qnom = [0 m/s2 0.1073 m 0 m/s 0 m/s2 0.0773 m −4500 N]∗. The system
is linearized around the nominal values. Fill in the following table:
Is the linearized process Yes No Cannot be determined
Stable?
Controllable?
Stabilizable?
Observable?
Detectable?
4.27. Consider the endothermic reactor system in Section 2.6.3 in Chapter 2. Assume
no disturbance. The process state, manipulated and performance output vectors
are s = [T1 CA CB T3 T4]∗, m = [Q] and q = [T3 Q]∗. The measurements are
of the two state variables T
1 and T3. The steady-state values of state variables are
s s s o p = [362.2 K 0.0154 kmol/m3 0.9846 kmol/m3 449.8 K 385.6 K]∗. The
system is linearized around the steady-state values. Fill in the following table:
Is the linearized process Yes No Cannot be determined
Stable?
Controllable?
Stabilizable?
Observable?
Detectable?
4.28. Consider the manufacturing process in Section 2.6.4 in Chapter 2. Assume no
140 Chapter 4. Linear System Theory
disturbance. The measurements are of the three state variables S
0, S1 and S2. Fill
in the following table:
Is the linearized process Yes No Cannot be determined
Stable?
Controllable?
Stabilizable?
Observable?
Detectable?
4.29. Consider the HVAC system in Section 2.6.5 in Chapter 2. Assume no disturbance. The process state, manipulated and performance output vectors are s =
[Tr oom Ts ol i d Cr oom]∗, m = [Fr c y Ff r es h]∗ and q = [Tr oom Cr oom Fr c y Ff r es h]∗.
The measurements are of the two state variables T
r oom and Cr oom. The steady-state
values are s s s o p = [26◦C 26◦C 400 p pm]∗ and ms s o p = [0.453 m3/s 0.0375 m3/s]∗.
The system is linearized around the steady-state values. Fill in the following table:
Is the linearized process Yes No Cannot be determined
Stable?
Controllable?
Stabilizable?
Observable?
Detectable?
4.30. Consider the vapor product reactor system in Section 2.6.6 in Chapter 2. Assume
no disturbance. The process state, manipulated and performance output vectors
are s = [V CA CB T Tj P]∗, m = [v vj Fg]∗ and q = [V CA T Tj P v vj Fg]∗.
The measurements are of the three state variables T , CB and P. The steady-state
values are s s s o p = [55.0 f t 3 0.1279 l b mol / f t3 0.3271 l b mol / f t3 620◦R
606.2◦R 460 l b f / f t2]∗ and ms s o p = [40 f t 3/h r 65.65 f t 3/h r 14.88 l b mol /
h r]∗. The system is linearized around the steady-state values. Fill in the following
table:
Exercises 141
Is the linearized process Yes No Cannot be determined
Stable?
Controllable?
Stabilizable?
Observable?
Detectable?
4.31. Consider the two CSTR process in Section 2.6.7 in Chapter 2. Assume no disturbance. The process state, manipulated and performance output vectors are
s = [CA,1 CB,1 T1 CA,2 CB,2 T2]∗, m = [F1 Fm Fc,1 Fc,2]∗ and q = [T1 T2 F1 +
F2
Tc
,1,out Tc,2,out F1 Fm CA,2]∗. The measurements are of the three state variables
T1
, CB,2 and T2. The steady-state values are ss s o p = [0.1142 kmol/m3 19.7384
kmol/m3 350.0 K 0.1727 kmol/m3 19.6952 kmol/m3 337.5 K]∗ and ms s o p =
[0.283 m3/s 0.229 m3/s 0.7 m3/s 0.7 m3/s]∗. The system is linearized around
the steady-state values. Fill in the following table:
Is the linearized process Yes No Cannot be determined
Stable?
Controllable?
Stabilizable?
Observable?
Detectable?
142 Chapter 4. Linear System Theory
Chapter 5
Stochastic Processes
143
144 Chapter 5. Stochastic Processes
Chapter 6
Linear Estimation
145
146 Chapter 6. Linear Estimation
Chapter 7
Linear Quadratic Optimal
Control
147
148 Chapter 7. Linear Quadratic Optimal Control
Chapter 8
Stochastic LQOC
149
150 Chapter 8. Stochastic LQOC
Chapter 9
Model Predictive Control
151
152 Chapter 9. Model Predictive Control
Part III
Economic Based Controller
Design
Chapter 10
Matrix Inequalities
155
156 Chapter 10. Matrix Inequalities
Chapter 11
Constrained Minimum
Variance Control
157
158 Chapter 11. Constrained Minimum Variance Control
Chapter 12
Hardware Selection and
the GBD
159
160 Chapter 12. Hardware Selection and the GBD
Chapter 13
Economic Linear Optimal
Control
161
162 Chapter 13. Economic Linear Optimal Control
Chapter 14
Economic MPC
163
164 Chapter 14. Economic MPC
Chapter 15
Controller Integrated
Process Design
165
166 Chapter 15. Controller Integrated Process Design
Bibliography
[1] D. E. SEBORG, T. F. EDGAR, D. A. MELLICHAMP, AND F. J. DOYLE, Process Dynamics and
Control - 3rd Ed, John Wiley & Sons, Hoboken, NJ, 2011. (Cited on pp. 7, 22, 58)
[2] N. A. NISHIDA, A. ICHIKAWA AND E. TAZAKI, Synthesis of optimal process systems under
uncertainty, Ind. Eng. Chem. Process Des. Dev., 13 (1974), pp. 209–214. (Cited on p. 21)
[3] I. E. GROSSMANN AND R. W. E. SARGENT, Optimum design of chemical plants with uncertain parameters, AIChE J., 24 (1978), pp. 1021–1028. (Cited on p. 21)
[4] E. POLAK AND A. SANGIOVANNI-VINCENTELLI, Theoretical and computational aspects of
the optimal design centering, tolerancing and tuning problem, IEEE Trans. Circuits Syst., CAS-
26 (1979), pp. 795–813. (Cited on p. 21)
[5] K. P. HALEMAANE AND I. E. GROSSMANN, Optimal process design under uncertainty,
AIChE J., 29 (1983), pp. 425–433. (Cited on p. 21)
[6] J. B. LASSERRE AND F. ROUBELLAT, Measuring decision flexibility in production planning,
IEEE Trans. Autom. Control, AC-30 (1985), pp. 447–452. (Cited on p. 21)
[7] A. K. SABOO, M. MORARI, AND D. C. WOODCOCK, Design of resilient processing plants
VIII. A resilience index for heat exchanger networks, Chem. Eng. Sci., 40 (1985), pp. 1553–
1565. (Cited on p. 21)
[8] R. E. SWANEY AND I. E. GROSSMANN, An Index for operational flexibility in chemical process
design part I: formulation and theory, AIChE J., 31 (1985), pp. 621–630. (Cited on p. 21)
[9] R. E. SWANEY AND I. E. GROSSMANN, An index for operational flexibility in chemical process
design part II: computational algorithms, AIChE J., 31 (1985), pp. 631–641. (Cited on p. 21)
[10] I. E. GROSSMANN AND C. A. FLOUDAS, Active constraint strategy for flexibility analysis in
chemical processes, Comp. & Chem. Eng., 11 (1987), pp. 675–693. (Cited on p. 21)
[11] C. G. RASPANTIA, J. A. BANDONI, AND L. T. BIEGLER, New strategies for flexibility analysis
and design under uncertainty, Comp. & Chem. Eng., 24 (2000), pp. 2193–2209. (Cited on
p. 21)
[12] G. M. OSTROVSKY, L. E. K. ACHENIE, Y. P. WANG, AND Y. M. VOLIN, A new algorithm
for computing process flexibility, Ind. Eng. Chem. Res., 39 (2000), pp. 2368–2377. (Cited on
p. 21)
[13] A. CHAKRABORTY AND A. A. LINNINGER, Plant-wide waste management. 2. decision making under uncertainty, Ind. Eng. Chem. Res., 42 (2003), pp. 357–369. (Cited on p. 21)
[14] I. BANERJEE AND M G. IERAPETRITOU, Feasibility evaluation of nonconvex systems using
shape reconstruction techniques, Ind. Eng. Chem. Res., 44 (2005), pp. 3638–3647. (Cited on
p. 21)
167
168 Bibliography
[15] A. MALCOLM, J. POLAN, L. ZHANG, B. A. OGUNNAIKE, AND A. A. LINNINGER, Integrating systems design and control using dynamic flexibility analysis, AIChE J., 53(2007), pp.
2048–2061. (Cited on p. 21)
[16] E. N. PISTIKOPOULOS AND I. E. GROSSMANN, Stochastic optimization of flexibility in
retrofit design of linear system, Comput. Chem. Eng., 12 (1988), pp. 1215–1227. (Cited on
p. 21)
[17] E. N. PISTIKOPOULOS AND T. A. MAZZUCHI, A novel flexibility analysis approach for processes with stochastic parameters, Comp. & Chem. Eng., 14 (1990), pp. 991–1000. (Cited on
p. 21)
[18] D. A. STRAUB AND I. E. GROSSMANN, Design optimization of stochastic flexibility, Comput.
Chem. Eng., 17 (1993), pp. 339–354. (Cited on p. 21)
[19] E. N. PISTIKOPOULOS AND M. IERAPETRITOU, Novel approach for optimal process design
under uncertainty, Comp. & Chem. Eng., 19 (1995), pp. 1089-1110. (Cited on p. 21)
[20] M. J. MOHIDEEN, J. D. PERKINS, AND E. N. PISTIKOPOULOS, Optimal design of dynamic
systems under uncertainty, AIChE J., 42 (1996), pp. 2251–2272. (Cited on p. 21)
[21] S. AHMED AND N. V. SAHINIDIS, Robust process planning under uncertainty, Ind. Eng.
Chem. Res., 37 (1998), pp. 1883–1892. (Cited on p. 21)
[22] W. C. ROONEY AND L. T. BIEGLER, Incorporating joint confidence regions into design under
uncertainty, Comp. & Chem. Eng., 23 (1999), pp. 1563–1575. (Cited on p. 21)
[23] V. BANSAL, J.D. PERKINS, AND E. N. PISTIKOPOULOS, Flexibility analysis and design using
a parametric programming framework, AIChE J., 48 (2002), pp. 2851–2868. (Cited on p. 21)
[24] A. CHARNES AND W. W. COOPER, Chance-constrained programming, Management Science,
6 (1959), pp. 73–79. (Cited on p. 21)
[25] L. B. MILLER AND H. WAGNER, Chance-constrained programming with joint constraints,
Operations Research, 13 (1965), pp. 930–945. (Cited on p. 21)
[26] S. URYASEV, Probabilistic Constrained Optimization: Methodology and Applications, Kluwer
Academic Publishers, Dordrecht, 2000. (Cited on p. 21)
[27] W. W. COOPER, H. DENG, Z. ZHANG, AND S. X. LI, Chance constrained programming
approaches to technical efficiencies and inefficiencies in stochastic data envelopment analysis, J.
Oper. Res. Soc., 53 (2002), pp. 1347–1356. (Cited on p. 21)
[28] R. HENRION AND W. ROMISCH ¨ , H¨older and lipschitz stability of solution sets in programs
with probabilistic constraints, Math. Prog., 100 (2004), pp. 589–611. (Cited on p. 21)
[29] A. NEMIROVSKI AND A. SHAPIRO, Convex approximations of chance constrained programming, SIAM J. Opt., 17 (2006), pp. 969–996. (Cited on p. 21)
[30] S. B. PETKOV AND C. MARANAS, Multiperiod planning and scheduling of multiproduct batch
plants under demand uncertainty, Ind. Eng. Chem. Res., 36 (1997), pp. 4864–4881. (Cited on
p. 21)
[31] S. B. PETKOV AND C. MARANAS, Quantitative assessment of uncertainty in the optimization
of metabolic pathways, Biotechnology & Bioengineering, 56 (1997), pp. 145–161. (Cited on
p. 21)
[32] A. T. SCHWARM AND M. NIKOLAOU, Chance-constrained model predictive control, AIChE
J., 45 (1999), pp. 1743–1752. (Cited on p. 21)
Bibliography 169
[33] P. LI, M. WENDT, AND G. WOZNY, Robust model predictive control under chance constraints,
Comp. & Chem. Eng., 24 (2000), pp. 829–834. (Cited on p. 21)
[34] P. LI, M. WENDT, AND G. WOZNY, A probabilistically constrained model predictive controller, Automatica, 38 (2002), pp. 1171–1176. (Cited on p. 21)
[35] P. LI, M. WENDT, AND G. WOZNY, Optimal planning for chemical engineering processes
under uncertain market conditions, Chem. Eng. & Tech., 27 (2004), pp. 641–651. (Cited on
p. 21)
[36] P. LI, H. ARELLANO-GARCIA, AND G. WOZNY, Chance constrained programming approach
to process optimization under uncertainty, Comp. & Chem. Eng., 32 (2008), pp. 25–45. (Cited
on p. 21)
[37] R. HENRION AND A. MOLLER ¨ , Optimization of a continuous distillation process under random inflow rate, Computers & Mathematics with App, 45 (2003), pp. 247–262. (Cited on
p. 21)
[38] M. MORARI, G. STEPHANOPOULOS, AND Y. ARKUN, Studies in the synthesis of control
structures for chemical processes, part I: Promulgation of the problem. Process decomposition and
the classification of the control task. Analysis of the optimizing control structures, AIChE J., 26
(1980), pp. 220–232. (Cited on p. 21)
[39] W. FISHER, M. F. DOHERTY AND J. M. DOUGLAS, The interface between design and control.
3. Selecting a set of controlled variables, Ind. Eng. Chem. Res., 27 (1988), pp. 611–615. (Cited
on p. 21)
[40] G. STEPHANOPOULOS AND C. NG, Perspectives on the synthesis of plant-wide control structures, J. Proc. Cont., 10 (2000), pp. 97–111. (Cited on p. 21)
[41] S. SKOGESTAD, Self-optimizing control: The missing link between steady-state optimization and
control, Comp. Chem. Eng., 24 (2000), pp. 569–575. (Cited on p. 21)
[42] S. SKOGESTAD, Near-optimal operation by self-optimizing control: From process control to
marathon running and business systems, Comp. Chem. Eng., 29 (2004), pp. 127–137. (Cited on p. 21)
[43] M. VAN DE WAL AND B. DE JAGER, Review of methods for input/output selection, Automatica, 37 (2001), pp. 487–510. (Cited on p. 21)
[44] J. D. WARD, D. A. MELLICHAMP, AND M. F. DOHERTY, Insight from economically optimal
steady-state operating policies for dynamic plantwide control, Ind. Eng. Chem. Res., 45 (2006),
pp. 1343–1354. (Cited on p. 21)
[45] D. MELLEFONT AND R. SARGENT, Selection of measurements for optimal feedback control,
Ind. Eng. Chem. Proc. Des. Dev., 17 (1978), pp. 549–552. (Cited on p. 21)
[46] T. J. HARRIS, J. F. MACGREGOR, AND J. D. WRIGHT, Optimal sensor location with an
application to a packed bed tubular reactor, AIChE J. 26 (1980), pp. 910–916. (Cited on p. 21)
[47] M. MORARI AND M. J. O’DOWD, Optimal sensor location in the presence of nonstationary
noise, Automatica, 16 (1980), pp. 463–480. (Cited on p. 21)
[48] M. MORARI AND G. STEPHANOPOULOS, Studies in the synthesis of control structures for
chemical processes, part III: Optimal selection of secondary measurements within the framework
of state estimation in the presence of persistent unknown disturbances, AIChE J., 26 (1980), pp.
247–260. (Cited on p. 21)
170 Bibliography
[49] J. ROMAGNOLI, J. ALVAREZ, AND G. STEPHANOPOLUS, Variable measurement structures
for process control, Int. J. Control, 33 (1981), pp. 269–289. (Cited on p. 21)
[50] J. H. LEE AND M. MORARI, Robust measurement selection, Automatica, 27 (1991), pp. 519–
527. (Cited on p. 21)
[51] M. HOVD AND S. SKOGESTAD, Procedure for regulatory control structure selection with application to the FCC process, AIChE J., 39 (1993), pp. 1938–1953. (Cited on p. 21)
[52] P. A. WISNEWSKI AND F. J. DOYLE, Control structure selection and model predictive control
of the Weyerhaeuser digester problem, J. Proc. Cont., 8 (1998), pp. 487–495. (Cited on p. 21)
[53] A. VAN DE WOUWER, N. POINT, S. PORTEMAN, AND M. REMY, An approach to the selection of optimal sensor locations in distributed parameter systems, J. Proc. Cont., 10 (2000), pp.
291–300. (Cited on p. 21)
[54] C. ANTONIADES AND P. D. CHRISTOFIDES, Integrating nonlinear output feedback control
and optimal actuator/sensor placement for transport-reaction processes, Chem. Eng. Sci., 56
(2001), pp. 4517–4535. (Cited on p. 21)
[55] K. R. MUSKE AND C. GEORGAKIS, A methodology for optimal sensor selection in chemical
processes, Proc. Am. Cont. Conf., (2002), pp. 4274–4278. (Cited on p. 21)
[56] A. A. ALONSO, I. G. KEVREKIDIS, J. R. BANGA, AND C.E. FROUZAKIS, Optimal sensor
location and reduced order observer design for distributed process systems, Comp. Chem. Eng.,
28 (2004), pp. 27–35. (Cited on p. 21)
[57] J. K. PENG AND D. J. CHMIELEWSKI, Covariance based hardware selection-part II: Equivalence results for the sensor, actuator and simultaneous selection problems, IEEE Trans. Cont. Sys.
Tech., 14 (2006), pp. 362–368. (Cited on p. 21)
[58] A. K. SINGH AND J. HAHN, Sensor location for stable nonlinear dynamic systems: Multiple
sensor case, Ind. Eng. Chem. Res., 45 (2006), pp. 3615–3623. (Cited on p. 21)
[59] A. ARMAOU AND M. A. DEMETRIOU, Optimal actuator/sensor placement for linear parabolic PDEs using spatial H2 norm, Chem. Eng. Sci., 61 (2006), pp. 7351–7367. (Cited on p. 21)
[60] J. H. LEE, R.D. BRAATZ, M. MORARI, AND A. PACKARD, Screening tools for robust control
structure selection, Automatica, 31 (1995), pp. 229–235. (Cited on p. 21)
[61] D. R. LEWIN, A simple tool for disturbance resiliency diagnosis and feedforward control design,
Comp. Chem. Eng., 20 (1996), pp. 13–25. (Cited on p. 21)
[62] Y. CAO AND D. ROSSITER, An input pre-screening technique for control structure selection,
Comp. Chem. Eng., 21 (1997), pp. 563–569. (Cited on p. 21)
[63] A. ZHENG AND R. MAHAJANAM, A quantitative controllability index, Ind. Eng. Chem.
Res., 38 (1999), pp. 999–1006. (Cited on p. 21)
[64] J. FIGUEROA, Economic performance of variable structure control: a case study, Comp. &
Chem. Eng., 24 (2000), pp. 1821–1827. (Cited on p. 21)
[65] D. R. VINSON AND C. GEORGAKIS, A new measure of process output controllability, J. Proc
Cont., 10 (2000), pp. 185–194. (Cited on p. 21)
[66] P. SEFERLIS AND J. GRIEVINK, Process design and control structure screening based on economic and static controllability criteria, Comp. & Chem. Eng., 25 (2001), pp. 177–188. (Cited
on p. 21)
Bibliography 171
[67] S. K. CHODAVARAPU AND A. ZHENG, A definition of steady-state plant-wide controllability,
Ind. Eng. Chem. Res., 41 (2002), pp. 4338–4345. (Cited on p. 21)
[68] C. GEORGAKIS, D. UZTURK, S. SUBRAMANIAN, AND D. R. VINSON, On the operability
of continuous processes, Cont. eng. Prac., 11 (2003), pp. 859–869. (Cited on p. 21)
[69] M. HOVD, D. L. MA, AND R.D. BRAATZ, On the computation of disturbance rejection measures, Ind. Eng. Chem. Res., 42 (2003), pp. 2183–2188. (Cited on p. 21)
[70] S. I. BIAGIOLA, N. GALVEZ, AND J.L. FIGUEROA, Performance criteria based on nonlinear
neasures, Comp. & Chem. Eng., 28 (2004), pp. 1799–1808. (Cited on p. 22)
[71] Y. CAO AND P. SAHA, Improved branch and bound method for control structure screening,
Chem. Eng. Sci., 60 (2005), pp. 1555–1564. (Cited on p. 22)
[72] L. T. NARRAWAY, J. D. PERKINS, AND G. W. BARTON, Interaction between Process Design
and Process Control: Economic analysis of Process dynamics, J. Proc. Cont., 1 (1991), pp. 243–
250. (Cited on p. 22)
[73] L. T. NARRAWAY AND J. D. PERKINS, Selection of process control structure based on linear
dynamic economics, Ind. Eng. Chem. Res., 32 (1993), pp. 2681–2692. (Cited on p. 22)
[74] L. T. NARRAWAY AND J. D. PERKINS, Selection of process control structure based on economics, Comp. Chem. Eng., 18 (1994), pp. 511–515. (Cited on p. 22)
[75] C. LOEBLEIN AND J. D. PERKINS, Economic analysis of different structures of on-line process
optimization systems, Comp. & Chem. Eng., 20 (1996), pp. S551–S556. (Cited on p. 22)
[76] C. LOEBLEIN AND J. D. PERKINS, Economic analysis of different structures of on-line process
optimization systems, Comp. & Chem. Eng., 22 (1998), pp. 1257–1269. (Cited on p. 22)
[77] C. LOEBLEIN AND J. D. PERKINS, Structural design for on-line process optimization: I. Dynamic economics of MPC, AIChE J., 45 (1999), pp. 1018–1029. (Cited on p. 22)
[78] C. LOEBLEIN AND J. D. PERKINS, Structural design for on-line process optimization: II. Application to a simulated FCC, AIChE J., 45 (1999), pp. 1030–1040. (Cited on p. 22)
[79] J. A. HEATH, I. K. KOOKOS, AND J. D. PERKINS, Process control structure selection based on
economics, AIChE J., 46 (2000), pp. 1998–2016. (Cited on p. 22)
[80] I. K. KOOKOS AND J. D. PERKINS, An algorithmic method for the selection of multivariable
process control structures, J. Proc. Cont., 12 (2002), pp. 85–99. (Cited on p. 22)
[81] P. BAHRI, J. BANDONI, G. BARTON AND J. ROMAGNOLI, Back-off calculations in optimizing control: a dynamic approach, Comp. & Chem. Eng., 19 (1995), pp. S699–S708. (Cited on
p. 22)
[82] J. YOUNG, C. SWARTZ, AND R. ROSS, On the effects of constraints, economics and uncertain
disturbances on dynamic operability assessment, Comp. & Chem. Eng., 20 (1996), pp. S667-
S682. (Cited on p. 22)
[83] P. BAHRI, J. BANDONI, AND J. ROMAGNOLI, Effect of disturbances in optimizing control:
Steady-state open-loop backoff problem, AIChE J., 42 (1996), pp. 983–994. (Cited on p. 22)
[84] J. FIGUEROA, P. BAHRI, J. BANDONI, AND J. ROMAGNOLI, Economic impact of disturbances and uncertain parameters in chemical processes - a dynamic back-off analysis, Comp. &
Chem. Eng., 20 (1996), pp. 453–461. (Cited on p. 22)
[85] J. CONTRERAS-DORDELLY AND T. MARLIN, Control design for increased profit, Comp. &
Chem. Eng., 24 (2000), pp. 267–272. (Cited on p. 22)
172 Bibliography
[86] Y. ZHANG AND J. FORBES, Extended design cost: a performance criterion for real-time optimization systems, Comp. & Chem. Eng., 24 (2000), pp. 1829–1824. (Cited on p. 22)
[87] J. FIGUEROA AND A. DESAGES, Dynamic ‘back-off’ analysis: use of piecewise linear approximations, Optim. Cont. Appl. Meth., 24 (2003), pp. 103–120. (Cited on p. 22)
[88] W. R. ROONEY AND L. T. BIEGLER, Optimal process design with model parameter uncertainty
and process variability, AIChE J., 49 (2003), pp. 438–449. (Cited on p. 22)
[89] M. ARBIZA, J. BANDONI, AND J. FIGUEROA, Use of back-off computation in multilevel MPC,
Lat. Am. App. Res., 33 (2003), pp. 251–256. (Cited on p. 22)
[90] J. YOUNG, R. BAKER, AND C. SWARTZ, Input saturation effects in optimizing control - inclusion within a simultaneous optimization framework, Comp. & Chem. Eng., 28 (2004), pp.
1347–1360. (Cited on p. 22)
[91] M. SOLIMAN, C. SWARTZ, AND R. BAKER, A mixed-integer formulation for back-off under
constrained predictive control, Comp. & Chem. Eng., 32 (2008), pp. 2409–2419. (Cited on
p. 22)
[92] D. H. VAN HESSEM, C. W. SCHERER, AND O. H. BOSGRA, LMI-based closed-loop economic
optimization of stochastic process operation under state and input constraints, Selected Topic in
Signals, Systems and Control, 12 (2001), pp. 31–38. (Cited on p. 22)
[93] K. MUSKE, Estimating the economic benefit from improved process control, Ind. Eng. Chem.
Res., 42 (2003), pp. 4535-4544. (Cited on p. 22)
[94] J. K. PENG, A. MANTHANWAR, AND D. J. CHMIELEWSKI, On the Tuning of Predictive
Controllers: The Minimum Back-off Operating Point Selection Problem, Ind. Eng. Chem. Res.,
44 (2005), pp. 7814–7822. (Cited on p. 22)
[95] K. H. LEE, B. HUANG, AND E. C. TAMAYO, Sensitivity analysis for selective constraint and
variability tuning in performance assessment of industrial MPC, Cont. Eng. Practice, 16 (2008),
pp. 1195–1215. (Cited on p. 22)
[96] S. AKANDE, B. HUANG, AND K. H. LEE, MPC constraint analysis-bayesian approach via a
continuous-valued profit function, Ind. Eng. Chem. Res., 48 (2009), pp. 3944–3954. (Cited on
p. 22)
[97] C. ZHAO, Y. ZHAO, H. SU, AND B. HUANG, Economic performance assessment of advanced
process control with LQG benchmarking, J. Proc. Contr., 19 (2009), pp. 557–569. (Cited on
p. 22)
[98] S. ENGELL, Feedback control for optimal process operation, J. Proc. Cont., 17 (2007), pp. 203–
219. (Cited on p. 22)
[99] J. B. RAWLINGS AND R. AMRIT, Optimizing process economic performance using model predictive control, Lecture Notes in Control and Information Sciences, 384 (2009), pp. 119–138.
(Cited on p. 22)
[100] J. B. RIGGS AND M. N. KARIM, Chemical and Bio-Process Control-3rd Ed., Ferret Publishing
Lubbock, TX, 2006. (Cited on p. 22)
[101] J. A. ROMAGNOLI AND A. PALAZOGLU, Introduction to Process Control, Taylor & Francis,
New York, NY, 2006. (Cited on p. 22)
[102] T. EDGAR, Control and operations: when does controllability equal profitability?, Comp. &
Chem. Eng., 29 (2004), pp. 41-49. (Cited on p. 22)
Bibliography 173
[103] M. BHUSHAN AND R. RENGASWAMY, Design of sensor network based on the signed directed
graph of the process for efficient fault diagnosis Ind. Eng. Chem. Res., 39 (2000), pp. 999–1019.
(Cited on p. 56)
[104] H. KWAKERNAAK AND R. SIVAN, Linear Optimal Control Systems, John Wiley & Sons,
New York, NY, 1972. (Cited on pp. 58, 123, 133)
[105] R. F. STENGEL, Stochastic Optimal Control, John Wiley & Sons, New York, NY, 1986.
(Cited on p. 58)
[106] J. B. BURL, Linear Optimal Control, Addison-Wesley, Menlo Park, CA, 1999. (Cited on
p. 58)
[107] G. STEPHANOPOULOS, Chemical Process Control, Prentice Hall, Upper Saddle River, NJ,
1984. (Cited on p. 58)
[108] B. A. OGUNNAIKE AND W. H. RAY, Process Dynamics, Modeling, and Control, Oxford
Univ Press, New York, NY, 1994. (Cited on p. 58)
[109] B. BEQUETTE, Process Control: Modeling, Design, and Simulation, Prentice Hall, Upper
Saddle River, NJ, 2003. (Cited on p. 58)
[110] J. A. ROMAGNOLI AND A. PALAZOGLU, Introduction to Process Control 2nd Ed., CRC
Press, Boca Raton, FL, 2012. (Cited on p. 58)
[111] D. G. LUENBURGER, Optimization by Vector Space Methods, John Wiley & Sons, New
York, NY, 1969. (Cited on p. 104)
[112] N. I. AKHIEZER AND I. M. GLAZMAN, Theory of Linear Operators in Hilbert Space, Dover,
New York, NY, 1993. (Cited on p. 104)
[113] L. DEBNATH AND P. MIKUSINSKI, Introduction to Hilbert Spaces with Applications, Academic Press, Boston, MA, 1990. (Cited on p. 104)
[114] M. D. GRAHAM AND J. B. RAWLINGS, Modeling and Analysis Principles for Chemical and
Biological Engineers, Nob Hill Publishing, Madison, WI, 2013. (Cited on pp. 101, 104, 133)
[115] S. I. GROSSMAN, Multivariable Calculus, Linear Algebra, and Differential Equations 2nd Ed.,
Harcourt Brace Jovanovich Publishers, San Diego, CA, 1986. (Cited on p. 104)
[116] A. V. BALAKRISHNAN, State Space Theory of Systems 2nd Ed., Optimization Software, New
York, NY, 1988. (Cited on pp. 104, 133)
[117] C.-T. CHEN, Linear System Theory and Design 3rd Ed., Oxford University Press, New York,
NY, 1989. (Cited on pp. 104, 123, 133)
[118] H. ANTON, Elementary Linear Algebra 8th Ed., John Wiley & Sons, New York, NY, 2000.
(Cited on p. 104)
[119] R. W. BROCKETT, Finite Dimensional Linear Systems, John Wiley & Sons, New York, NY,
1970. (Cited on p. 133)
[120] G. E. DULLERD AND F. PAGANINI, A Course in Robust Control Theory − A Convex Approach, Springer-Verlag, New York, NY, 2000. (Not cited)
[121] A. V. BALAKRISHNAN, Kalman Filtering Theory, Optimization Software, Inc. New York,
NY, 1987. (Not cited)
[122] J. BENDAT AND A. PIERSOL, Random data: analysis and measurement procedures, John
Wiley & Sons, New York, NY, 1986. (Not cited)
174 Bibliography
[123] T. SODERSTROM AND P. STOICA, System Identification, Prentice Hall International, London, UK, 1989. (Not cited)
[124] L. LJUNG AND T. GLAD, Modeling of Dynamic Systems, rentice Hall, Englewood Cliffs, NJ,
1994. (Not cited)
[125] W. E. LARIMORE, Automated Multivariable System Identification and Industrial Applications,
Proc. Am. Control Conf., (1999), pp. 1148-1162. (Not cited)
[126] Y. ZHU, Multivariable System Identification for Process Control, Elsevier Science Ltd, Oxford,
UK, 2001 (Not cited)
[127] S. J. QIN, An overview of subspace identification, Comp. Chem. Eng., 30 (2006), pp. 1502-
1513. (Not cited)
[128] T. P. MCGARTY, Stochastic Systems and State Estimation, John Wiley & Sons, New York,
NY, 1973. (Not cited)
[129] A. PAPOULIS, Random Variables, and Stochastic Processes 3rd Ed., McGraw-Hill, New York,
NY, 1991. (Not cited)
[130] R. E. KALMAN, A new approach to linear filtering and prediction problems, J. Basic Eng.
Trans. ASME Series D, 82 (1960), pp. 35–45. (Not cited)
[131] A. H. JAZWINSKI, Stochastic Processes and Filtering Theory, Academic Press, New York, NY,
1970. (Not cited)
[132] A. GELB, Applied Optimal Estimation, MIT Press, Cambridge, MA, 1974. (Not cited)
[133] B. D. O. ANDERSON AND J. B. MOORE,Optimal Filtering, Prentice Hall, Englewood Cliffs, NJ, 1979. (Not cited)
[134] H. L. VAN TREES, Detection, Estimation, and Modulation Theory: Part I, John Wiley &
Sons, New York, NY, 1968. (Not cited)
[135] R. E. KALMAN, Contributions to the Theory of Optimal Control, Bol. Soc. Mat. Mexicana, 5
(1960), pp. 102–119. (Not cited)
[136] M. ATHANS AND P. L. FALB, Optimal Control, An Introduction to the Theory and its Applications, McGraw Hill Co, New York, NY, 1966. (Not cited)
[137] D. KIRK, Optimal Control Theory: An Introduction, Prentice Hall, Englewood Cliffs, NJ,
1970. (Not cited)
[138] D. L. RUSSELL, Mathematics of Finite-dimensional Control Systems: Theory and Design, Marcel Dekker Inc., New York, NY, 1979. (Not cited)
[139] B. D. O. ANDERSON AND J. B. MOORE, Optimal Control: Linear Quadratic Methods,
Prentice Hall, Englewood Cliffs, NJ, 1989. (Not cited)
[140] R. E. BELLMAN AND R. E. KALABA, Dynamic Programming and Modern Control Theory,
Academic Press, New York, NY, 1965. (Not cited)
[141] S. E. DREYFUS, Dynamic Programming and the Calculus of Variations, Rand Corporation,
Santa Monica, CA, 1965. (Not cited)
[142] K. J. ASTROM, Introduction to Stochastic Control Theory, Academic Press, New York, NY,
1970. (Not cited)
[143] H. KUSHNER Introduction to Stochastic Control, Holt, Rinehart and Winston, New York,
NY, 1971. (Not cited)
Bibliography 175
[144] J. L. SPEYER AND W. H. CHUNG, Stochastic Processes, Estimation, and Control, SIAM,
Philadelphia, PA, 2008. (Not cited)
[145] A. BEMPORAD, M. MORARI, V. DUA, AND E.N. PISTIKOPOULOS, The Explicit Linear
Quadratic Regulator for Constrained Systems, Automatica, 38(1) (2002), pp. 3-20. (Not cited)
[146] E. G. GILBERT AND K. T. TAN, Linear Systems with State and Control Constraints: The
Theory and Application of Maximal Output Admissible Sets, IEEE Trans. Aut. Con., 36 (1991),
pp. 1008-1020. (Not cited)
[147] D. CHMIELEWSKI AND V. MANOUSIOUTHAKIS, On constrained infinite-time linear
quadratic optimal control, IEEE Trans. Syst. & Cont. Lett., 29 (1996), pp. 121–129. (Not
cited)
[148] D. CHMIELEWSKI AND V. MANOUSIOUTHAKIS, On Constrained Infinite-time Linear
Quadratic Optimal Control with Stochastic Disturbances, J. Proc Cont., 15(4) (2005), pp. 383-
391. (Not cited)
[149] A. ZHENG AND M. MORARI, Stability of Model Predicitve Control with Mixed Constraints,
IEEE Transaction on Automatic Control, 40(10) (1995), pp. 1818-1823. (Not cited)
[150] C. CUTLER AND B. RAMAKER, Dynamic matrix control−a computer control algorithm, in
Proc. Joint Aut. Cont. Conf., San Francisco, CA, 1980. (Not cited)
[151] J. B. FROISY, Model Predictive Control: Past, Present and Future, SA Trans., 33 (1994), pp.
235–243. (Not cited)
[152] S. J. QIN AND T. A. BADGWELL, A Survey of Industrial Model Predictive Control Technology,
Control Engineering Practice, 11(7) (2003), pp. 733–764. (Not cited)
[153] M. SZNAIER AND M. J. DAMBORG, Heuristically Enhanced Feedback Control of Constrained
Discrete-Time Linear Systems, Automatica, 26 (1990), pp. 521–532. (Not cited)
[154] J. B. RAWLINGS AND K. R. MUSKE, The Stability of Constrained Receding Horizon Control,
IEEE Trans. Aut. Con., 38 (1993), pp. 1512–1516. (Not cited)
[155] P. O. M. SCOKAERT AND J. B. RAWLINGS, Constrained linear quadratic regulation, IEEE
Trans Aut. Cont., 43(8) (1998), pp. 1163-1169. (Not cited)
[156] C. E. GARCIA, D. M. PRETT, AND M. MORARI, Model Predictive Control: Theory and
Practice, Automatica, 25(3) (1989), pp. 335-348. (Not cited)
[157] J. B. RAWLINGS, Tutorial: Model predictive control technology, in Proc American Control
Conference, (1999), pp. 662-676. (Not cited)
[158] J. B. RAWLINGS, Tutorial Overview of Model Predictive Control, IEEE Control Systems
Magazine, 20(3) (2000), pp. 38-52. (Not cited)
[159] D. Q. MAYNE, J. B. RAWLINGS, C. V. RAO, AND P. O. M. SCOKAERT, Constrained Model
Predictive Control: Stability and Optimality, Automatica, 36 (2000), pp. 789–814. (Not cited)
[160] E. F. CAMACHO AND C. BORDONS, Model Predictive Control 2nd ed., Springer-Verlag,
London, 2004. (Not cited)
[161] J. B. RAWLINGS AND D. Q. MAYNE, Model Predictive Control: Theory and Design, Nob
Hill Publishing, Madison, WI, 2009. (Not cited)
[162] S. BOYD, V. BALAKRISHNAN, E. FERON, AND L. EL GHAOUI, Control system analysis and
synthesis via linear matrix inequalities, In Proceedings of the American Control Conference;
IEEE Press: Piscataway, NJ, (1993), pp. 2147. (Not cited)
176 Bibliography
[163] L. VANDENBERGHE AND S. BOYD, Semidefinite Programming, SIAM Review, 38 (1996),
pp. 49-95. (Not cited)
[164] S. BENSON, Parallel computing on semidefinite programs, Technical report ANL/MCS-P939-
0302, Mathematics and Computer Science Division, Argonne National Laboratory. (Not
cited)
[165] B. BORCHERS AND J. YOUNG, Implementation of a primal-dual method for SDP on a shared
memory parallel architecture, Comp. Optim. Appl., 37 (2007) pp. 355-369. (Not cited)
[166] K. FUJISAWA, M. KOJIMA, AND K. NAKATA, Exploiting sparsity in primal-dual interiorpoint methods for semidefinite programming, Math. Programming, 79(1-3, Ser B) (1997) pp.
235-253. (Not cited)
[167] M. YAMASHITA, K. FUJISAWA, AND M. KOJIMA, SDPARA: SemiDefinite Programming
Algorithm paRAllel version, Parallel Comput., 29 (2003) pp. 1053-1067. (Not cited)
[168] S. BOYD AND L. VANDENBERGHE, Convex Optimization, Cambridge University Press,
2004, available at http://www.stanford.edu/ boyd/cvxbook/ (Not cited)
[169] S. BOYD, L.E. GHAOUI, E. FERON, AND V. BALAKRISHNAN, Linear Matrix Inequalities
in System and Control Theory, SIAM, Philadelphia, PA, 1994. (Not cited)
[170] R.E. SKELTON, T. IWASAKI, AND K. GRIGORIADIS, A Unified Algebraic Approach to Linear
Control Design, Taylor & Francis, Bristol, PA, 1998. (Not cited)
[171] D.J. CHMIELEWSKI AND A.M. MANTHANWAR, On the tuning of predictive controllers:
Inverse optimality and the minimum variance covariance constrained control problem, Ind. Eng.
Chem. Res., 43 (2004) pp. 7807-7814. (Not cited)
[172] R. E. KALMAN, When is a linear control system optimal?, Trans. ASME J. Basic Eng. 51
(1964). (Not cited)
[173] B. P. OMELL AND D. J. CHMIELEWSKI, On the tuning of predictive controllers: impact of
disturbances, constraints and feedback structure, AIChE J., 60 (2014), pp. 3473–3489. (Not
cited)
[174] F. XU, K. H. LEE, AND B. HUANG, Monitoring control performance via structured closedloop response subject to output variance / covariance upper bound, Journal of Process Control,
16 (2006), pp. 971–984. (Not cited)
[175] F. XU, B. HUANG, AND S. AKANDE, Performance assessment of model predictive control for
variability and constraint tuning, Industrial and Engineering Chemistry Research, 46 (2007),
pp. 1208–1219. (Not cited)
[176] M. J. BAGAJEWICZ, Design and retrofit of sensor networks in process plants, AIChE J., 43(9)
(1997), pp. 2300–2306. (Not cited)
[177] M. J. BAGAJEWICZ, Process Plant Instrumentation: Design and Upgrade, Technomic Publishing, Lancaster, PA, 2001. (Not cited)
[178] D. J. CHMIELEWSKI, T. PALMER, AND V.I. MANOUSIOUTHAKIS, On the theory of optimal
sensor placement, AIChE J., 48(5) (2002), pp. 1001–1012. (Not cited)
[179] D. J. CHMIELEWSKI AND J-K. PENG, Covariance-based hardware selection − part I: Globally
optimal actuator selection, IEEE Trans. Cont. Sys. Tech., 14(2) (2006), pp. 355–361. (Not cited)
[180] S. K. AHMED, J-K. PENG, AND D.J. CHMIELEWSKI, Covariance-based hardware selection
− part III: Distributed parameter systems, AIChE J., 58(9) (2012), pp. 2705–2713. (Not cited)
Bibliography 177
[181] J. ZHANG, X. WANG, AND D.J. CHMIELEWSKI, Covariance-based hardware selection −
part IV: Solution using the generalized Benders decomposition, AIChE J., 62(10) (2016), pp. 3628–3638. (Not cited)
[182] A. M. GEOFFRION, Generalized Benders decomposition, J. Optimization Theory Applic.,
10 (1972), pp. 237–260. (Not cited)
[183] J. F. BENDERS, Partitioning procedures for solving mixed variable programming problems,
Num. Math, 4 (1962), pp. 238–252. (Not cited)
[184] C. A. FLOUDAS, A. AGGARWAL, AND A.R. CIRIC, Global optimum search for nonconvex
NLP and MINLP problems, Comp. Chem. Eng., 13(10) (1989), pp. 1117–1132. (Not cited)
[185] M. J. BAGAJEWICZ AND V. I. MANOUSIOUTHAKIS, On the generalized Benders decomposition, Comp. Chem. Eng., 15(10) (1991), pp. 691–700. (Not cited)
178 Bibliography